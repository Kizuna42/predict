---
description:
globs:
alwaysApply: true
---
# üìä Python Data Analysis & Visualization Guidelines

---

## 1. Core Principles

- Prioritize **readability** and **reproducibility** in all workflows.
- Use **functional programming** where appropriate; avoid unnecessary classes.
- Favor **vectorized operations** with `pandas`/`numpy` over explicit loops.
- Follow **PEP 8** style conventions.
- Use **descriptive variable names** that reflect the data they contain.

---

## 2. Data Ingestion & Validation

- Always start with **data quality checks**: nulls, dtypes, value ranges.
- Use `try-except` blocks for I/O operations (e.g., reading files).
- Convert low-cardinality string columns to `CategoricalDtype` when appropriate.

```python
df = pd.read_csv("data.csv")
df["region"] = df["region"].astype("category")



‚∏ª

3. Data Manipulation (pandas)
	‚Ä¢	Use method chaining for step-by-step transformations.
	‚Ä¢	Prefer loc, iloc, query, and assign for clear data selection and transformation.
	‚Ä¢	Use groupby().agg() for efficient aggregation.

summary = (
    df
    .query("year >= 2020")
    .groupby("region")["sales"]
    .agg(["mean", "sum"])
    .reset_index()
)



‚∏ª

4. Handling Missing and Invalid Data
	‚Ä¢	Handle missing values with dropna(), fillna(), or flagging based on context.
	‚Ä¢	Validate value ranges with assert or between().

assert df["price"].between(0, 10000).all(), "Invalid price values detected"



‚∏ª

5. Visualization (matplotlib / seaborn)
	‚Ä¢	Use %matplotlib inline at the start of Jupyter notebooks.
	‚Ä¢	Always include axis labels, titles, and legends.
	‚Ä¢	Prefer colorblind-friendly palettes (e.g., "colorblind" in seaborn).

import seaborn as sns
import matplotlib.pyplot as plt

def plot_sales_by_region(data):
    sns.set_theme(style="whitegrid", palette="colorblind")
    plt.figure(figsize=(8, 4))
    sns.barplot(x="region", y="sales", data=data)
    plt.title("Sales by Region")
    plt.xlabel("Region")
    plt.ylabel("Sales")
    plt.tight_layout()



‚∏ª

6. Jupyter Notebook Best Practices
	‚Ä¢	Use markdown cells to divide sections clearly (# Section Name).
	‚Ä¢	Keep code cells modular and focused on one task.
	‚Ä¢	Example magics: %matplotlib inline, %timeit, %load_ext autoreload.

‚∏ª

7. Performance Optimization
	‚Ä¢	Prefer vectorized computations via pandas/numpy.
	‚Ä¢	Use dask or chunking for large datasets.
	‚Ä¢	Use df.memory_usage(deep=True) to monitor memory usage.
	‚Ä¢	Profile slow sections using %time, %%timeit, or cProfile.

‚∏ª

8. Dependencies
	‚Ä¢	Core: pandas, numpy, matplotlib, seaborn
	‚Ä¢	Optional: scikit-learn (ML/preprocessing), dask (scalability)
	‚Ä¢	Use requirements.txt or poetry for dependency versioning.

‚∏ª

9. Automation via Makefile
	‚Ä¢	Use a Makefile to simplify routine commands:

# Makefile
install:
	pip install -r requirements.txt

start:
	jupyter notebook

clean:
	find . -name "*.pyc" -delete

	‚Ä¢	Typical usage:
	‚Ä¢	make install: Install dependencies.
	‚Ä¢	make start: Launch Jupyter Notebook.
	‚Ä¢	make clean: Remove cache files.

‚∏ª

10. Documentation in README
	‚Ä¢	Include a comprehensive README.md that covers:
	‚Ä¢	Project overview and purpose
	‚Ä¢	Data source(s)
	‚Ä¢	How to run analysis via Makefile
	‚Ä¢	Environment setup instructions
	‚Ä¢	Assumptions and limitations

Example:

## üîß How to Use

```bash
make install   # Install required packages
make start     # Launch Jupyter Notebook

üìÅ Project Structure
	‚Ä¢	notebooks/ ‚Äì Jupyter Notebooks
	‚Ä¢	data/ ‚Äì Raw and processed data
	‚Ä¢	scripts/ ‚Äì Reusable data processing modules
	‚Ä¢	Makefile ‚Äì Workflow automation

---
