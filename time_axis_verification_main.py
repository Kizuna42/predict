#!/usr/bin/env python
# coding: utf-8

"""
æ™‚é–“è»¸æ•´åˆæ€§æ¤œè¨¼ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
äºˆæ¸¬å€¤ã¨å®Ÿæ¸¬å€¤ã®æ™‚é–“è»¸å¯¾å¿œé–¢ä¿‚ã‚’è©³ç´°ã«æ¤œè¨¼
"""

import pandas as pd
import numpy as np
import os
import pickle
import warnings
warnings.filterwarnings('ignore')

# è¨­å®šã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.config import HORIZONS, OUTPUT_DIR

# æ™‚é–“è»¸æ¤œè¨¼æ©Ÿèƒ½ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.diagnostics.time_axis_verification import (
    verify_time_axis_alignment,
    run_comprehensive_time_axis_verification
)

# ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.data.preprocessing import prepare_time_features


def load_original_data():
    """
    å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’èª­ã¿è¾¼ã‚€
    """
    print("å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’èª­ã¿è¾¼ã¿ä¸­...")

    try:
        df = pd.read_csv('AllDayData.csv')
        print(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {df.shape[0]}è¡Œ x {df.shape[1]}åˆ—")

        # æ™‚é–“ç‰¹å¾´é‡ã®æº–å‚™
        df = prepare_time_features(df)

        return df

    except Exception as e:
        print(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def load_model_results():
    """
    ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«çµæœã‚’èª­ã¿è¾¼ã‚€
    """
    print("ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«çµæœã‚’èª­ã¿è¾¼ã¿ä¸­...")

    # çµæœãƒ‡ã‚£ã‚¯ã‚·ãƒ§ãƒŠãƒªã®åˆæœŸåŒ–
    results = {}

    # ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ç¢ºèª
    models_dir = "models"
    if not os.path.exists(models_dir):
        print(f"ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{models_dir}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return None

    # ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    model_files = [f for f in os.listdir(models_dir) if f.endswith('.pkl')]

    if not model_files:
        print("ã‚¨ãƒ©ãƒ¼: ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return None

    # ã‚¾ãƒ¼ãƒ³ã¨ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã®çµ„ã¿åˆã‚ã›ã‚’æŠ½å‡º
    zone_horizon_combinations = set()
    for file in model_files:
        if 'zone_' in file and 'horizon_' in file:
            parts = file.replace('.pkl', '').split('_')
            zone_idx = parts.index('zone') + 1
            horizon_idx = parts.index('horizon') + 1

            if zone_idx < len(parts) and horizon_idx < len(parts):
                try:
                    zone = int(parts[zone_idx])
                    horizon = int(parts[horizon_idx])
                    zone_horizon_combinations.add((zone, horizon))
                except ValueError:
                    continue

    print(f"æ¤œå‡ºã•ã‚ŒãŸã‚¾ãƒ¼ãƒ³ãƒ»ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³çµ„ã¿åˆã‚ã›: {len(zone_horizon_combinations)}å€‹")

    # å„çµ„ã¿åˆã‚ã›ã«ã¤ã„ã¦ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    for zone, horizon in zone_horizon_combinations:
        if zone not in results:
            results[zone] = {}

        # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿
        model_file = f"model_zone_{zone}_horizon_{horizon}.pkl"
        features_file = f"features_zone_{zone}_horizon_{horizon}.pkl"

        model_path = os.path.join(models_dir, model_file)
        features_path = os.path.join(models_dir, features_file)

        if os.path.exists(model_path) and os.path.exists(features_path):
            try:
                with open(model_path, 'rb') as f:
                    model = pickle.load(f)

                with open(features_path, 'rb') as f:
                    features = pickle.load(f)

                # ç‰¹å¾´é‡é‡è¦åº¦ã®å–å¾—
                if hasattr(model, 'feature_importances_'):
                    feature_importance = pd.DataFrame({
                        'feature': features,
                        'importance': model.feature_importances_
                    }).sort_values('importance', ascending=False)
                else:
                    # ç‰¹å¾´é‡é‡è¦åº¦ãŒå–å¾—ã§ããªã„å ´åˆã¯ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
                    feature_importance = pd.DataFrame({
                        'feature': features,
                        'importance': [1.0] * len(features)
                    })

                results[zone][horizon] = {
                    'model': model,
                    'selected_features': features,
                    'feature_importance': feature_importance
                }

                print(f"ã‚¾ãƒ¼ãƒ³ {zone}, ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ {horizon}åˆ†: ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†")

            except Exception as e:
                print(f"ã‚¾ãƒ¼ãƒ³ {zone}, ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ {horizon}åˆ†: èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ - {e}")

    return results


def create_mock_test_data(original_df, zone, horizon):
    """
    ãƒ†ã‚¹ãƒˆç”¨ã®ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
    å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ä¿å­˜ã•ã‚ŒãŸãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
    """
    # æœ€æ–°1000ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨
    test_data = original_df.iloc[-1000:].copy()

    # ç›®çš„å¤‰æ•°ã®ä½œæˆï¼ˆã‚·ãƒ•ãƒˆå‡¦ç†ï¼‰
    temp_col = f'sens_temp_{zone}'
    if temp_col in test_data.columns:
        # æ™‚é–“é–“éš”ã®æ¨å®š
        time_diff = test_data.index.to_series().diff().dropna().value_counts().index[0]
        shift_periods = int(horizon / time_diff.total_seconds() * 60)

        # ç›®çš„å¤‰æ•°ã®ä½œæˆ
        target_col = f'sens_temp_{zone}_future_{horizon}'
        test_data[target_col] = test_data[temp_col].shift(-shift_periods)

        # test_yã®ä½œæˆ
        test_y = test_data[target_col].dropna()

        # äºˆæ¸¬å€¤ã®ä½œæˆï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ä¿å­˜ã•ã‚ŒãŸäºˆæ¸¬çµæœã‚’ä½¿ç”¨ï¼‰
        # ã“ã“ã§ã¯å…ƒã®å€¤ã«å°ã•ãªãƒã‚¤ã‚ºã‚’åŠ ãˆãŸã‚‚ã®ã‚’äºˆæ¸¬å€¤ã¨ã™ã‚‹
        test_predictions = test_y.values + np.random.normal(0, 0.5, len(test_y))

        return test_data, test_y, test_predictions

    return None, None, None


def run_time_axis_verification(target_zones=None, target_horizons=None):
    """
    æ™‚é–“è»¸æ•´åˆæ€§æ¤œè¨¼ã®å®Ÿè¡Œ

    Parameters:
    -----------
    target_zones : list, optional
        æ¤œè¨¼å¯¾è±¡ã®ã‚¾ãƒ¼ãƒ³ç•ªå·ã®ãƒªã‚¹ãƒˆ
    target_horizons : list, optional
        æ¤œè¨¼å¯¾è±¡ã®äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰ã®ãƒªã‚¹ãƒˆ
    """
    print("=" * 80)
    print("ğŸ• æ™‚é–“è»¸æ•´åˆæ€§æ¤œè¨¼")
    print("=" * 80)

    # å¯¾è±¡ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã®è¨­å®š
    if target_horizons is None:
        target_horizons = HORIZONS

    print(f"æ¤œè¨¼å¯¾è±¡ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³: {target_horizons}")

    # å…ƒãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    original_df = load_original_data()
    if original_df is None:
        print("ã‚¨ãƒ©ãƒ¼: å…ƒãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return

    # ãƒ¢ãƒ‡ãƒ«çµæœã®èª­ã¿è¾¼ã¿
    model_results = load_model_results()
    if model_results is None:
        print("ã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«çµæœã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return

    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    verification_dir = os.path.join(OUTPUT_DIR, "time_axis_verification")
    os.makedirs(verification_dir, exist_ok=True)

    # æ¤œè¨¼ç”¨ã®results_dictã‚’ä½œæˆ
    verification_results_dict = {}

    # åˆ©ç”¨å¯èƒ½ãªã‚¾ãƒ¼ãƒ³ã®ç¢ºèª
    available_zones = list(model_results.keys())
    if target_zones:
        available_zones = [z for z in target_zones if z in available_zones]

    print(f"æ¤œè¨¼å¯¾è±¡ã‚¾ãƒ¼ãƒ³: {available_zones}")

    # å„ã‚¾ãƒ¼ãƒ³ãƒ»ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã«ã¤ã„ã¦æ¤œè¨¼ã‚’å®Ÿè¡Œ
    for zone in available_zones:
        verification_results_dict[zone] = {}

        for horizon in target_horizons:
            if horizon not in model_results[zone]:
                continue

            print(f"\n{'='*50}")
            print(f"ã‚¾ãƒ¼ãƒ³ {zone} - {horizon}åˆ†äºˆæ¸¬ã®æ¤œè¨¼")
            print(f"{'='*50}")

            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ä½œæˆï¼ˆå®Ÿéš›ã®å®Ÿè£…ã§ã¯ä¿å­˜ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
            test_data, test_y, test_predictions = create_mock_test_data(
                original_df, zone, horizon
            )

            if test_data is None or test_y is None or test_predictions is None:
                print(f"è­¦å‘Š: ã‚¾ãƒ¼ãƒ³ {zone} ã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
                continue

            # æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
            verification_results_dict[zone][horizon] = {
                'test_data': test_data,
                'test_y': test_y,
                'test_predictions': test_predictions,
                'feature_importance': model_results[zone][horizon]['feature_importance']
            }

            # å€‹åˆ¥æ¤œè¨¼ã®å®Ÿè¡Œ
            try:
                verification_result = verify_time_axis_alignment(
                    df=original_df,
                    zone=zone,
                    horizon=horizon,
                    test_predictions=test_predictions,
                    test_y=test_y,
                    test_data=test_data,
                    save_dir=verification_dir
                )

                # çµæœã®è¡¨ç¤º
                print(f"\nğŸ“Š æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼:")
                print(f"  ãƒ‡ãƒ¼ã‚¿æ§‹é€ : {'âœ…' if verification_result['data_structure_analysis']['original_data_available'] else 'âŒ'}")
                print(f"  ã‚·ãƒ•ãƒˆæ­£ç¢ºæ€§: {'âœ…' if verification_result['time_axis_mapping'].get('shift_verification', {}).get('is_correct_shift', False) else 'âŒ'}")
                print(f"  ãƒ‡ãƒ¼ã‚¿é•·æ•´åˆæ€§: {'âœ…' if verification_result['alignment_verification']['data_length_match'] else 'âŒ'}")
                print(f"  å¯è¦–åŒ–ãƒ‡ãƒ¢: {'âœ…' if verification_result['visualization_correctness']['demonstration_created'] else 'âŒ'}")

                if verification_result['recommendations']:
                    print(f"\nğŸ’¡ æ¨å¥¨äº‹é …:")
                    for rec in verification_result['recommendations'][:3]:  # ä¸Šä½3ã¤ã®ã¿è¡¨ç¤º
                        print(f"  - {rec}")

            except Exception as e:
                print(f"æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
                continue

    # åŒ…æ‹¬çš„æ¤œè¨¼ã®å®Ÿè¡Œ
    if verification_results_dict:
        print(f"\n{'='*80}")
        print("ğŸ” åŒ…æ‹¬çš„æ™‚é–“è»¸æ•´åˆæ€§æ¤œè¨¼")
        print(f"{'='*80}")

        try:
            comprehensive_verification = run_comprehensive_time_axis_verification(
                results_dict=verification_results_dict,
                original_df=original_df,
                save_dir=verification_dir
            )

            # çµæœã®ä¿å­˜
            import json
            verification_report_path = os.path.join(verification_dir, 'time_axis_verification_report.json')
            with open(verification_report_path, 'w', encoding='utf-8') as f:
                json.dump(comprehensive_verification, f, ensure_ascii=False, indent=2, default=str)

            print(f"\nğŸ“ æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {verification_report_path}")

        except Exception as e:
            print(f"åŒ…æ‹¬çš„æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")

    print(f"\n{'='*80}")
    print("æ™‚é–“è»¸æ•´åˆæ€§æ¤œè¨¼å®Œäº†")
    print(f"çµæœã¯ {verification_dir} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸ")
    print(f"{'='*80}")


def print_verification_summary():
    """
    æ¤œè¨¼é …ç›®ã®ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º
    """
    print("\n" + "="*80)
    print("ğŸ• æ™‚é–“è»¸æ•´åˆæ€§æ¤œè¨¼ - æ¤œè¨¼é …ç›®")
    print("="*80)

    print("\nğŸ” æ¤œè¨¼å†…å®¹:")
    print("1. ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®åˆ†æ")
    print("   - å…ƒã®æ¸©åº¦ãƒ‡ãƒ¼ã‚¿ã®åˆ©ç”¨å¯èƒ½æ€§")
    print("   - ç›®çš„å¤‰æ•°ï¼ˆã‚·ãƒ•ãƒˆæ¸ˆã¿ï¼‰ã®ç¢ºèª")
    print("   - test_yã®å‡ºæ‰€ã®ç‰¹å®š")

    print("\n2. æ™‚é–“è»¸ãƒãƒƒãƒ”ãƒ³ã‚°ã®åˆ†æ")
    print("   - å…¥åŠ›ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¨äºˆæ¸¬å¯¾è±¡ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®å¯¾å¿œ")
    print("   - ã‚·ãƒ•ãƒˆå‡¦ç†ã®æ­£ç¢ºæ€§æ¤œè¨¼")
    print("   - ç›¸é–¢åˆ†æã«ã‚ˆã‚‹æ¤œè¨¼")

    print("\n3. äºˆæ¸¬å€¤ã¨å®Ÿæ¸¬å€¤ã®æ•´åˆæ€§æ¤œè¨¼")
    print("   - ãƒ‡ãƒ¼ã‚¿é•·ã®ä¸€è‡´ç¢ºèª")
    print("   - ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®æ•´åˆæ€§")
    print("   - å€¤ã®ç¯„å›²ã®ä¸€è²«æ€§")

    print("\n4. å¯è¦–åŒ–ã®æ­£ç¢ºæ€§æ¤œè¨¼")
    print("   - æ­£ã—ã„æ™‚é–“è»¸è¡¨ç¤ºæ–¹æ³•ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("   - é–“é•ã£ãŸè¡¨ç¤ºæ–¹æ³•ã¨ã®æ¯”è¼ƒ")
    print("   - å®Ÿéš›ã®æœªæ¥å€¤ã¨ã®æ¯”è¼ƒæ¤œè¨¼")

    print("\nğŸ“Š å‡ºåŠ›ã•ã‚Œã‚‹æ¤œè¨¼çµæœ:")
    print("- å„ã‚¾ãƒ¼ãƒ³ãƒ»ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³åˆ¥ã®è©³ç´°æ¤œè¨¼çµæœ")
    print("- æ™‚é–“è»¸è¡¨ç¤ºã®æ­£èª¤æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ")
    print("- åŒ…æ‹¬çš„æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆï¼ˆJSONå½¢å¼ï¼‰")
    print("- å…·ä½“çš„ãªä¿®æ­£æ¨å¥¨äº‹é …")

    print("\nâ“ è§£æ±ºã•ã‚Œã‚‹ç–‘å•:")
    print("- äºˆæ¸¬å€¤ã‚’ãã®ã¾ã¾ãƒ—ãƒ­ãƒƒãƒˆã—ã¦ã‚ˆã„ã‹ï¼Ÿ")
    print("- å®Ÿæ¸¬å€¤ã¨ã¯ä½•ã‚’æŒ‡ã™ã®ã‹ï¼Ÿ")
    print("- äºˆæ¸¬å€¤ã¨å®Ÿæ¸¬å€¤ãŒåŒã˜æ™‚é–“è»¸ã§ãƒ—ãƒ­ãƒƒãƒˆã•ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description='æ™‚é–“è»¸æ•´åˆæ€§æ¤œè¨¼')
    parser.add_argument('--zones', type=int, nargs='+',
                       help='æ¤œè¨¼å¯¾è±¡ã®ã‚¾ãƒ¼ãƒ³ç•ªå·')
    parser.add_argument('--horizons', type=int, nargs='+',
                       help='æ¤œè¨¼å¯¾è±¡ã®äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰')
    parser.add_argument('--summary', action='store_true',
                       help='æ¤œè¨¼é …ç›®ã®ã‚µãƒãƒªãƒ¼ã®ã¿ã‚’è¡¨ç¤º')

    args = parser.parse_args()

    if args.summary:
        print_verification_summary()
    else:
        run_time_axis_verification(
            target_zones=args.zones,
            target_horizons=args.horizons
        )
