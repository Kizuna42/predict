#!/usr/bin/env python
# coding: utf-8

"""
ç´°ã‹ã„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é–¾å€¤æœ€é©åŒ–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æ®µéšçš„æœ€é©åŒ–ã«ã‚ˆã‚Šæœ€é©ãªãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é–¾å€¤ã‚’è¦‹ã¤ã‘ã¾ã™
"""

import pandas as pd
import numpy as np
import warnings
from pathlib import Path
import json
import time
import sys
import os

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

warnings.filterwarnings('ignore')

# è¨­å®šã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.config import SMOOTHING_WINDOWS, FEATURE_SELECTION_THRESHOLD, TEST_SIZE

# ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†é–¢æ•°ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.data.preprocessing import (
    filter_temperature_outliers,
    create_temperature_difference_targets,
    prepare_time_features,
    get_time_based_train_test_split,
    filter_high_value_targets
)

# ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°é–¢æ•°ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.data.feature_engineering import create_difference_prediction_pipeline

# ãƒ¢ãƒ‡ãƒ«è¨“ç·´é–¢æ•°ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.models.training import train_temperature_difference_model

# è©•ä¾¡é–¢æ•°ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.models.evaluation import evaluate_temperature_difference_model


def test_filtering_threshold(df, zone, horizon, percentile, time_diff_seconds):
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«é–¾å€¤ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œã—ã€æ€§èƒ½ã‚’è©•ä¾¡

    Parameters:
    -----------
    df : DataFrame
        å‰å‡¦ç†æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿
    zone : int
        å¯¾è±¡ã‚¾ãƒ¼ãƒ³
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³
    percentile : float
        ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«
    time_diff_seconds : float
        ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°é–“éš”

    Returns:
    --------
    dict
        è©•ä¾¡çµæœ
    """
    try:
        print(f"\\nğŸ” {percentile:.1f}%ileãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆä¸­...")

        # å·®åˆ†äºˆæ¸¬ç”¨ç›®çš„å¤‰æ•°ã®ä½œæˆ
        df_with_diff_targets = create_temperature_difference_targets(
            df, [zone], [horizon], pd.Timedelta(seconds=time_diff_seconds)
        )

        # å·®åˆ†äºˆæ¸¬å°‚ç”¨ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
        df_processed, selected_features, feature_info = create_difference_prediction_pipeline(
            df=df_with_diff_targets,
            zone_nums=[zone],
            horizons_minutes=[horizon],
            time_diff_seconds=time_diff_seconds,
            smoothing_window=SMOOTHING_WINDOWS[0] if SMOOTHING_WINDOWS else 5,
            feature_selection_threshold=FEATURE_SELECTION_THRESHOLD
        )

        diff_target_col = f'temp_diff_{zone}_future_{horizon}'
        if diff_target_col not in df_processed.columns:
            return {'error': f'ç›®çš„å¤‰æ•° {diff_target_col} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“'}

        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        feature_cols = [col for col in selected_features if col in df_processed.columns]
        valid_data = df_processed.dropna(subset=[diff_target_col] + feature_cols)

        if len(valid_data) < 100:
            return {'error': f'æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ ({len(valid_data)}è¡Œ)'}

        # é«˜å€¤ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        abs_diff_col = f'abs_temp_diff_{zone}_future_{horizon}'
        valid_data[abs_diff_col] = valid_data[diff_target_col].abs()

        filtered_data, filter_info = filter_high_value_targets(
            valid_data, [abs_diff_col], percentile=percentile
        )

        if len(filtered_data) < 50:
            return {'error': f'ãƒ•ã‚£ãƒ«ã‚¿å¾Œã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ ({len(filtered_data)}è¡Œ)'}

        # æ™‚ç³»åˆ—åˆ†å‰²
        train_df, test_df = get_time_based_train_test_split(filtered_data, test_size=TEST_SIZE)

        X_train = train_df[feature_cols]
        y_train_diff = train_df[diff_target_col]
        X_test = test_df[feature_cols]
        y_test_diff = test_df[diff_target_col]

        if len(X_train) < 30 or len(X_test) < 15:
            return {'error': f'åˆ†å‰²å¾Œã®ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ (train: {len(X_train)}, test: {len(X_test)})'}

        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        start_time = time.time()
        diff_model = train_temperature_difference_model(X_train, y_train_diff)
        training_time = time.time() - start_time

        # äºˆæ¸¬
        y_pred_diff = diff_model.predict(X_test)

        # è©•ä¾¡
        current_temps_test = test_df[f'sens_temp_{zone}']
        diff_metrics = evaluate_temperature_difference_model(
            y_test_diff, y_pred_diff, current_temps_test
        )

        # çµæœã®æ•´ç†
        result = {
            'percentile': percentile,
            'original_data_count': len(valid_data),
            'filtered_data_count': len(filtered_data),
            'data_reduction_rate': (len(valid_data) - len(filtered_data)) / len(valid_data) * 100,
            'train_count': len(X_train),
            'test_count': len(X_test),
            'training_time': training_time,
            'threshold_value': filter_info['thresholds'][abs_diff_col],
            'diff_rmse': diff_metrics['diff_rmse'],
            'diff_mae': diff_metrics['diff_mae'],
            'direction_accuracy': diff_metrics['direction_accuracy'],
            'restoration_rmse': diff_metrics.get('restoration_rmse', np.nan),
            'restoration_mae': diff_metrics.get('restoration_mae', np.nan),
            'restoration_r2': diff_metrics.get('restoration_r2', np.nan),
            'error': None
        }

        print(f"âœ… {percentile:.1f}%ileå®Œäº†: RMSE={result['restoration_rmse']:.4f}, RÂ²={result['restoration_r2']:.4f}")
        return result

    except Exception as e:
        print(f"âŒ {percentile:.1f}%ileã‚¨ãƒ©ãƒ¼: {e}")
        return {
            'percentile': percentile,
            'error': str(e),
            'diff_rmse': np.nan,
            'restoration_rmse': np.nan,
            'restoration_r2': np.nan
        }


def optimize_filtering_threshold(zone=1, horizon=15):
    """
    æ®µéšçš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é–¾å€¤æœ€é©åŒ–ã‚’å®Ÿè¡Œ

    Parameters:
    -----------
    zone : int
        å¯¾è±¡ã‚¾ãƒ¼ãƒ³
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³

    Returns:
    --------
    dict
        æœ€é©åŒ–çµæœ
    """
    print("ğŸ”¥ æ®µéšçš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°é–¾å€¤æœ€é©åŒ–é–‹å§‹")
    print(f"å¯¾è±¡: ã‚¾ãƒ¼ãƒ³{zone}, äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³{horizon}åˆ†")

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    data_path = project_root / "AllDayData.csv"
    print(f"\\nãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­: {data_path}")

    df = pd.read_csv(data_path)
    time_diff_seconds = pd.to_datetime(df['datetime']).diff().dt.total_seconds().median()

    # åŸºæœ¬å‰å‡¦ç†
    df = filter_temperature_outliers(df)
    df = prepare_time_features(df)

    all_results = []

    # ã‚¹ãƒ†ãƒƒãƒ—1: ç²—ã„æ¢ç´¢ï¼ˆ20-60%ã€5%åˆ»ã¿ï¼‰
    print("\\nğŸ” ã‚¹ãƒ†ãƒƒãƒ—1: ç²—ã„æ¢ç´¢ï¼ˆ20-60%ã€5%åˆ»ã¿ï¼‰")
    coarse_percentiles = np.arange(20, 65, 5)
    coarse_results = []

    for percentile in coarse_percentiles:
        result = test_filtering_threshold(df, zone, horizon, percentile, time_diff_seconds)
        coarse_results.append(result)
        all_results.append(result)

    # ç²—ã„æ¢ç´¢ã§ã®æœ€è‰¯çµæœã‚’ç‰¹å®š
    valid_coarse = [r for r in coarse_results if r.get('error') is None]
    if not valid_coarse:
        print("âŒ ç²—ã„æ¢ç´¢ã§æœ‰åŠ¹ãªçµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        return {'error': 'ç²—ã„æ¢ç´¢å¤±æ•—', 'all_results': all_results}

    best_coarse = min(valid_coarse, key=lambda x: x['restoration_rmse'])
    best_percentile = best_coarse['percentile']
    print(f"\\nğŸ¯ ç²—ã„æ¢ç´¢ã§ã®æœ€è‰¯: {best_percentile}%ile (RMSE: {best_coarse['restoration_rmse']:.4f})")

    # ã‚¹ãƒ†ãƒƒãƒ—2: ä¸­ç¨‹åº¦æ¢ç´¢ï¼ˆæœ€è‰¯çµæœå‘¨è¾ºã€2%åˆ»ã¿ï¼‰
    print(f"\\nğŸ” ã‚¹ãƒ†ãƒƒãƒ—2: ä¸­ç¨‹åº¦æ¢ç´¢ï¼ˆ{best_percentile}%ileå‘¨è¾ºã€2%åˆ»ã¿ï¼‰")
    medium_range = np.arange(max(20, best_percentile - 6), min(65, best_percentile + 8), 2)
    medium_results = []

    for percentile in medium_range:
        if percentile not in [r['percentile'] for r in coarse_results]:  # æ—¢ã«å®Ÿè¡Œæ¸ˆã¿ã‚’ã‚¹ã‚­ãƒƒãƒ—
            result = test_filtering_threshold(df, zone, horizon, percentile, time_diff_seconds)
            medium_results.append(result)
            all_results.append(result)

    # ä¸­ç¨‹åº¦æ¢ç´¢ã§ã®æœ€è‰¯çµæœã‚’ç‰¹å®š
    all_valid = [r for r in all_results if r.get('error') is None]
    best_medium = min(all_valid, key=lambda x: x['restoration_rmse'])
    best_percentile = best_medium['percentile']
    print(f"\\nğŸ¯ ä¸­ç¨‹åº¦æ¢ç´¢ã§ã®æœ€è‰¯: {best_percentile}%ile (RMSE: {best_medium['restoration_rmse']:.4f})")

    # ã‚¹ãƒ†ãƒƒãƒ—3: ç´°ã‹ã„æ¢ç´¢ï¼ˆæœ€è‰¯çµæœå‘¨è¾ºã€0.5%åˆ»ã¿ï¼‰
    print(f"\\nğŸ” ã‚¹ãƒ†ãƒƒãƒ—3: ç´°ã‹ã„æ¢ç´¢ï¼ˆ{best_percentile}%ileå‘¨è¾ºã€0.5%åˆ»ã¿ï¼‰")
    fine_range = np.arange(max(20, best_percentile - 2), min(65, best_percentile + 2.5), 0.5)
    fine_results = []

    for percentile in fine_range:
        if percentile not in [r['percentile'] for r in all_results]:  # æ—¢ã«å®Ÿè¡Œæ¸ˆã¿ã‚’ã‚¹ã‚­ãƒƒãƒ—
            result = test_filtering_threshold(df, zone, horizon, percentile, time_diff_seconds)
            fine_results.append(result)
            all_results.append(result)

    # æœ€çµ‚çš„ãªæœ€è‰¯çµæœã‚’ç‰¹å®š
    final_valid = [r for r in all_results if r.get('error') is None]
    if not final_valid:
        print("âŒ æœ‰åŠ¹ãªçµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        return {'error': 'æœ€é©åŒ–å¤±æ•—', 'all_results': all_results}

    best_result = min(final_valid, key=lambda x: x['restoration_rmse'])

    # çµæœã‚µãƒãƒªãƒ¼
    print("\\n" + "="*80)
    print("ğŸ‰ æœ€é©åŒ–å®Œäº†ï¼")
    print("="*80)
    print(f"æœ€é©ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«: {best_result['percentile']:.1f}%ile")
    print(f"å¾©å…ƒæ¸©åº¦RMSE: {best_result['restoration_rmse']:.4f}â„ƒ")
    print(f"å¾©å…ƒæ¸©åº¦RÂ²: {best_result['restoration_r2']:.4f}")
    print(f"æ–¹å‘ç²¾åº¦: {best_result['direction_accuracy']:.1f}%")
    print(f"ãƒ‡ãƒ¼ã‚¿å‰Šæ¸›ç‡: {best_result['data_reduction_rate']:.1f}%")
    print(f"ãƒ•ã‚£ãƒ«ã‚¿å¾Œãƒ‡ãƒ¼ã‚¿æ•°: {best_result['filtered_data_count']:,}è¡Œ")

    # çµæœã‚’ä¿å­˜
    output_dir = project_root / "Output"
    output_dir.mkdir(exist_ok=True)

    results_file = output_dir / f"filtering_optimization_zone{zone}_horizon{horizon}.json"
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump({
            'best_result': best_result,
            'all_results': all_results,
            'optimization_summary': {
                'zone': zone,
                'horizon': horizon,
                'total_tests': len(all_results),
                'best_percentile': best_result['percentile'],
                'best_rmse': best_result['restoration_rmse'],
                'best_r2': best_result['restoration_r2']
            }
        }, f, indent=2, ensure_ascii=False)

    print(f"\\nçµæœã‚’ä¿å­˜: {results_file}")

    return {
        'best_result': best_result,
        'all_results': all_results,
        'optimization_summary': {
            'zone': zone,
            'horizon': horizon,
            'total_tests': len(all_results),
            'best_percentile': best_result['percentile'],
            'best_rmse': best_result['restoration_rmse'],
            'best_r2': best_result['restoration_r2']
        }
    }


if __name__ == "__main__":
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®ãƒ‘ãƒ¼ã‚¹
    zone = int(sys.argv[1]) if len(sys.argv) > 1 else 1
    horizon = int(sys.argv[2]) if len(sys.argv) > 2 else 15

    # æœ€é©åŒ–å®Ÿè¡Œ
    results = optimize_filtering_threshold(zone, horizon)

    if 'error' not in results:
        print("\\nâœ… æœ€é©åŒ–ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
    else:
        print(f"\\nâŒ æœ€é©åŒ–ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {results['error']}")
