#!/usr/bin/env python
# coding: utf-8

"""
ç©ºèª¿ã‚·ã‚¹ãƒ†ãƒ å®¤å†…æ¸©åº¦äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«é–‹ç™º
ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã«ã‚ˆã‚‹å®Ÿè£…
"""

import pandas as pd
import numpy as np
import os
import pickle
import warnings
import argparse
warnings.filterwarnings('ignore')

# è¨­å®šã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.config import (
    HORIZONS, SMOOTHING_WINDOWS, L_ZONES, M_ZONES, R_ZONES,
    MODELS_DIR, OUTPUT_DIR, TEST_SIZE, FEATURE_SELECTION_THRESHOLD
)

# ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†é–¢æ•°ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.data.preprocessing import (
    filter_temperature_outliers,
    apply_smoothing_to_sensors,
    create_future_targets,
    prepare_time_features,
    get_time_based_train_test_split
)

# ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°é–¢æ•°ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.data.feature_engineering import (
    create_physics_based_features,
    create_future_explanatory_features,
    create_thermo_state_features,
    select_important_features,
    create_polynomial_features,
    create_optimized_features_pipeline,
    select_important_features_enhanced
)

# ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–¢æ•°ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.models.training import (
    train_physics_guided_model,
    save_model_and_features
)

# ãƒ¢ãƒ‡ãƒ«è©•ä¾¡é–¢æ•°ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.models.evaluation import (
    calculate_metrics,
    print_metrics,
    analyze_feature_importance,
    print_lag_dependency_warning
)

# å¯è¦–åŒ–é–¢æ•°ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.utils.visualization import (
    create_comprehensive_analysis_report,
    print_analysis_summary
)

# ç°¡ç´ åŒ–ã•ã‚ŒãŸå¯è¦–åŒ–æ©Ÿèƒ½ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.utils.basic_plots import (
    plot_feature_importance
)

from src.utils.advanced_visualization import (
    plot_corrected_time_series_by_horizon,
    plot_ultra_detailed_minute_analysis
)

# è¨ºæ–­æ©Ÿèƒ½ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.diagnostics import (
    analyze_lag_dependency,
    detect_lag_following_pattern,
    validate_prediction_timing,
    analyze_feature_patterns,
    calculate_comprehensive_metrics
)


def main(test_mode=False, target_zones=None, target_horizons=None):
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°

    Parameters:
    -----------
    test_mode : bool
        ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã™ã‚‹ã‹ã©ã†ã‹
    target_zones : list of int, optional
        å‡¦ç†å¯¾è±¡ã®ã‚¾ãƒ¼ãƒ³ç•ªå·ã®ãƒªã‚¹ãƒˆï¼ˆNone ã®å ´åˆã¯å…¨ã¦ã®ã‚¾ãƒ¼ãƒ³ï¼‰
    target_horizons : list of int, optional
        å‡¦ç†å¯¾è±¡ã®äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰ã®ãƒªã‚¹ãƒˆï¼ˆNone ã®å ´åˆã¯å…¨ã¦ã®ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼‰
    """
    print("# ç©ºèª¿ã‚·ã‚¹ãƒ†ãƒ å®¤å†…æ¸©åº¦äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«é–‹ç™º")
    if test_mode:
        print(f"[ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰] å¯¾è±¡ã‚¾ãƒ¼ãƒ³: {target_zones}, å¯¾è±¡ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³: {target_horizons}")

    print("## ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†")
    try:
        df = pd.read_csv('AllDayData.csv')
        print(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {df.shape[0]}è¡Œ x {df.shape[1]}åˆ—")
    except Exception as e:
        print(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return

    missing_values = df.isnull().sum()
    missing_percent = (missing_values / len(df)) * 100

    missing_df = pd.DataFrame({
        'æ¬ æå€¤æ•°': missing_values,
        'æ¬ æç‡(%)': missing_percent
    })

    print("\næ¬ æå€¤ã®çŠ¶æ³:")
    missing_cols = missing_df[missing_df['æ¬ æå€¤æ•°'] > 0].sort_values('æ¬ æå€¤æ•°', ascending=False)
    if len(missing_cols) > 0:
        print(missing_cols)
    else:
        print("æ¬ æå€¤ã¯ã‚ã‚Šã¾ã›ã‚“")

    print("\n## æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†")

    # æ™‚é–“ç‰¹å¾´é‡ã®è¿½åŠ 
    df = prepare_time_features(df)

    # æ¸©åº¦ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã®æ¦‚è¦ã‚’ç¢ºèª
    temp_cols = [col for col in df.columns if 'sens_temp' in col]
    print(f"\næ¸©åº¦ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã®åˆ—: {len(temp_cols)}å€‹")

    # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°é–“éš”ã®ç¢ºèª
    time_diff = df.index.to_series().diff().dropna().value_counts().index[0]
    print(f"ãƒ‡ãƒ¼ã‚¿ã®æ™‚é–“é–“éš”: {time_diff}")

    # å®Ÿéš›ã®ã‚¾ãƒ¼ãƒ³ç•ªå·ã‚’æŠ½å‡º
    existing_zones = sorted([int(col.split('_')[2]) for col in temp_cols if 'future' not in col])
    print(f"æ¤œå‡ºã•ã‚ŒãŸã‚¾ãƒ¼ãƒ³: {existing_zones}")

    # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯å¯¾è±¡ã‚¾ãƒ¼ãƒ³ã‚’çµã‚Šè¾¼ã‚€
    if test_mode and target_zones:
        target_zones = [z for z in target_zones if z in existing_zones]
        if not target_zones:
            print("è­¦å‘Š: æŒ‡å®šã•ã‚ŒãŸã‚¾ãƒ¼ãƒ³ãŒå­˜åœ¨ã—ã¾ã›ã‚“ã€‚å…¨ã¦ã®ã‚¾ãƒ¼ãƒ³ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            target_zones = existing_zones
        else:
            existing_zones = target_zones
            print(f"æŒ‡å®šã•ã‚ŒãŸã‚¾ãƒ¼ãƒ³ã‚’ä½¿ç”¨ã—ã¾ã™: {existing_zones}")

    # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã®å ´åˆã¯å¯¾è±¡ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã‚’çµã‚Šè¾¼ã‚€
    actual_horizons = HORIZONS
    if test_mode and target_horizons:
        target_horizons = [h for h in target_horizons if h in HORIZONS]
        if not target_horizons:
            print("è­¦å‘Š: æŒ‡å®šã•ã‚ŒãŸãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ãŒè¨­å®šã«å­˜åœ¨ã—ã¾ã›ã‚“ã€‚å…¨ã¦ã®ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
        else:
            actual_horizons = target_horizons
            print(f"æŒ‡å®šã•ã‚ŒãŸãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã‚’ä½¿ç”¨ã—ã¾ã™: {actual_horizons}")

    # AC_temp_* åˆ—ã‚’å‰Šé™¤
    ac_temp_cols = [col for col in df.columns if 'AC_temp_' in col]
    if ac_temp_cols:
        df = df.drop(columns=ac_temp_cols)
        print(f"\n{len(ac_temp_cols)}å€‹ã®AC_temp_åˆ—ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")

    # é›»åŠ›ç³»çµ±ãƒ‡ãƒ¼ã‚¿ï¼ˆL, M, Rï¼‰ã‚’å‰Šé™¤
    power_cols = [col for col in df.columns if col in ['L', 'M', 'R']]
    if power_cols:
        df = df.drop(columns=power_cols)
        print(f"{len(power_cols)}å€‹ã®é›»åŠ›ç³»çµ±ãƒ‡ãƒ¼ã‚¿åˆ—ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")

    # ä¸è¦ãªæ™‚é–“ç‰¹å¾´é‡ã‚’å‰Šé™¤ï¼ˆday_of_week, is_weekendç­‰ï¼‰
    # å¿…è¦ãªã®ã¯hourã®ã¿
    time_cols_to_remove = [col for col in df.columns if col in ['day_of_week', 'is_weekend', 'day_of_year']]
    if time_cols_to_remove:
        df = df.drop(columns=time_cols_to_remove)
        print(f"{len(time_cols_to_remove)}å€‹ã®ä¸è¦ãªæ™‚é–“ç‰¹å¾´é‡ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")

    print("\n## ç›®çš„å¤‰æ•°ã®ä½œæˆï¼ˆå°†æ¥æ¸©åº¦ã®äºˆæ¸¬ï¼‰")

    # ç›®çš„å¤‰æ•°ã®ä½œæˆ
    df_with_targets = create_future_targets(df, existing_zones, actual_horizons, time_diff)
    print(f"ç›®çš„å¤‰æ•°ã‚’è¿½åŠ ã—ãŸãƒ‡ãƒ¼ã‚¿ã‚·ã‚§ã‚¤ãƒ—: {df_with_targets.shape}")

    # å¤–ã‚Œå€¤å‡¦ç†ã®å®Ÿè¡Œ
    df_with_targets = filter_temperature_outliers(df_with_targets)

    print("\n## æœ€é©åŒ–ã•ã‚ŒãŸç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°")
    # æ–°ã—ã„çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–¢æ•°ã‚’ä½¿ç”¨
    time_diff_seconds_val = time_diff.total_seconds()
    df_processed, selected_features, feature_info = create_optimized_features_pipeline(
        df=df_with_targets,
        zone_nums=existing_zones,
        horizons_minutes=actual_horizons,
        time_diff_seconds=time_diff_seconds_val,
        is_prediction_mode=False,  # å­¦ç¿’æ™‚
        smoothing_window=5,
        feature_selection_threshold='20%'  # ã‚ˆã‚Šå¤šãã®ç‰¹å¾´é‡ã‚’ä¿æŒ
    )

    # ä½œæˆã•ã‚ŒãŸç‰¹å¾´é‡ã®è©³ç´°æƒ…å ±ã‚’è¡¨ç¤º
    print(f"\nä½œæˆã•ã‚ŒãŸç‰¹å¾´é‡ã®è©³ç´°:")
    for category, features in feature_info.items():
        if category != 'total_features':
            print(f"  - {category}: {len(features)}å€‹")
            # é‡è¦ã‚«ãƒ†ã‚´ãƒªã®å ´åˆã¯ç‰¹å¾´é‡åã‚‚è¡¨ç¤º
            if category in ['thermo_features', 'future_features'] and len(features) <= 10:
                for feature in features[:5]:  # æœ€åˆã®5å€‹ã®ã¿è¡¨ç¤º
                    print(f"    Â· {feature}")
                if len(features) > 5:
                    print(f"    Â· ... ä»–{len(features)-5}å€‹")

    print(f"\nçµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ä½œæˆã•ã‚ŒãŸç‰¹å¾´é‡ç·æ•°: {len(selected_features)}å€‹")

    # æ™‚é–“ç‰¹å¾´é‡ã‚’è¿½åŠ 
    if 'hour' not in selected_features and 'hour' in df_processed.columns:
        selected_features.append('hour')
        print("æ™‚é–“ç‰¹å¾´é‡ 'hour' ã‚’è¿½åŠ ã—ã¾ã—ãŸ")

    # å¤šé …å¼ç‰¹å¾´é‡ã®ãƒ™ãƒ¼ã‚¹ç‰¹å¾´é‡è¨­å®šï¼ˆé‡è¦ç‰¹å¾´é‡ã‹ã‚‰é¸æŠï¼‰
    poly_base_features = []
    for feature in selected_features:
        # é‡è¦ãªåŸºæœ¬ç‰¹å¾´é‡ã®ã¿ã‚’å¤šé …å¼ç‰¹å¾´é‡ã®ãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ä½¿ç”¨
        if any(pattern in feature for pattern in [
            'thermo_state', 'atmospheric', 'solar', 'AC_valid',
            'smoothed', 'temp_diff'
        ]) and 'future' not in feature:  # æœªæ¥ç‰¹å¾´é‡ã¯é™¤å¤–
            poly_base_features.append(feature)

    # å¤šé …å¼ç‰¹å¾´é‡ã®ãƒ™ãƒ¼ã‚¹æ•°ã‚’åˆ¶é™ï¼ˆè¨ˆç®—æ™‚é–“ã¨ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’è€ƒæ…®ï¼‰
    poly_base_features = poly_base_features[:15]  # æœ€å¤§15å€‹ã«åˆ¶é™
    print(f"å¤šé …å¼ç‰¹å¾´é‡ã®ãƒ™ãƒ¼ã‚¹ç‰¹å¾´: {len(poly_base_features)}å€‹")

    # æœ€çµ‚çš„ãªç‰¹å¾´é‡ãƒªã‚¹ãƒˆ
    feature_cols = selected_features
    print(f"æœ€çµ‚ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ: {len(feature_cols)}å€‹")

    # ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨è©•ä¾¡ã®ãƒ«ãƒ¼ãƒ—
    results = {}

    for zone in existing_zones:
        zone_results = {}

        for horizon in actual_horizons:
            print(f"\n### ã‚¾ãƒ¼ãƒ³{zone}ã®{horizon}åˆ†å¾Œäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«")
            target_col = f'sens_temp_{zone}_future_{horizon}'

            if target_col not in df_processed.columns:
                print(f"è­¦å‘Š: ç›®çš„å¤‰æ•° {target_col} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã“ã®ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                continue

            # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°/ãƒ†ã‚¹ãƒˆåˆ†å‰²
            train_df, test_df = get_time_based_train_test_split(df_processed, test_size=TEST_SIZE)

            # ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°ã®æº–å‚™
            available_feature_cols = [col for col in feature_cols if col in train_df.columns]
            train_X = train_df[available_feature_cols].copy()
            train_y = train_df[target_col]
            test_X = test_df[available_feature_cols].copy()
            test_y = test_df[target_col]

            # æ¬ æå€¤å‡¦ç†
            train_X = train_X.fillna(method='ffill').fillna(method='bfill')
            test_X = test_X.fillna(method='ffill').fillna(method='bfill')

            # å¤šé …å¼ç‰¹å¾´é‡ã®ç”Ÿæˆ
            train_X_poly, test_X_poly, poly_features = create_polynomial_features(
                train_X, test_X, poly_base_features, degree=2
            )
            print(f"å¤šé …å¼ç‰¹å¾´é‡ã‚’{len(poly_features)}å€‹è¿½åŠ ã—ã¾ã—ãŸ")

            # æ”¹è‰¯ã•ã‚ŒãŸç‰¹å¾´é‡é¸æŠã‚’ä½¿ç”¨
            train_X_selected, test_X_selected, final_selected_features = select_important_features_enhanced(
                train_X_poly, train_y, test_X_poly,
                available_feature_cols + poly_features,
                threshold=FEATURE_SELECTION_THRESHOLD
            )

            # ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
            model = train_physics_guided_model(train_X_selected, train_y)

            # ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
            train_predictions = model.predict(train_X_selected)
            test_predictions = model.predict(test_X_selected)

            # è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—
            train_metrics = calculate_metrics(train_y, train_predictions)
            test_metrics = calculate_metrics(test_y, test_predictions)

            # çµæœã‚’è¡¨ç¤º
            print(f"\nãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®è©•ä¾¡:")
            print_metrics(train_metrics)
            print(f"\nãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®è©•ä¾¡:")
            print_metrics(test_metrics)

            # ç‰¹å¾´é‡é‡è¦åº¦ã®åˆ†æ
            importance_df = analyze_feature_importance(model, final_selected_features)
            print("\nç‰¹å¾´é‡é‡è¦åº¦ (ä¸Šä½10):")
            print(importance_df.head(10))

            # ãƒ©ã‚°ä¾å­˜æ€§åˆ†æï¼ˆæ–°ã—ã„è¨ºæ–­æ©Ÿèƒ½ã‚’ä½¿ç”¨ï¼‰
            # ä¸Šå¸ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã«å¾“ã„ã€ã‚¾ãƒ¼ãƒ³ã®ç³»çµ±ï¼ˆL/M/Rï¼‰ã‚’ç‰¹å®š
            zone_system = 'L' if zone in L_ZONES else ('M' if zone in M_ZONES else 'R')

            # æ–°ã—ã„è¨ºæ–­æ©Ÿèƒ½ã‚’ä½¿ç”¨
            from src.diagnostics.lag_analysis import analyze_lag_dependency as new_analyze_lag_dependency
            lag_dependency = new_analyze_lag_dependency(importance_df, zone, horizon, zone_system)
            print("\nLAGç‰¹å¾´é‡ã¸ã®ä¾å­˜åº¦:")
            print(lag_dependency)

            # LAGä¾å­˜åº¦è­¦å‘Šã®è¡¨ç¤ºï¼ˆä¾å­˜åº¦ãŒé«˜ã„å ´åˆã¯è­¦å‘Šã‚’è¡¨ç¤ºï¼‰
            print_lag_dependency_warning(lag_dependency, threshold=30.0, zone=zone, horizon=horizon)

            # ãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å¾´é‡æƒ…å ±ã‚’ä¿å­˜
            model_path, features_path = save_model_and_features(model, final_selected_features, zone, horizon)

            zone_results[horizon] = {
                'model': model,
                'selected_features': final_selected_features,
                'train_metrics': train_metrics,
                'test_metrics': test_metrics,
                'feature_importance': importance_df,
                'lag_dependency': lag_dependency,
                'model_path': model_path,
                'features_path': features_path,
                'test_data': test_df,
                'test_y': test_y,
                'test_predictions': test_predictions
            }

        results[zone] = zone_results
    print("\n## ğŸ“Š åŒ…æ‹¬çš„åˆ†æãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ")

    # æ–°ã—ã„çµ±åˆåˆ†æã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’ä½¿ç”¨
    comprehensive_report = create_comprehensive_analysis_report(
        results_dict=results,
        horizons=actual_horizons,
        save_dir=OUTPUT_DIR,
        save=True
    )

    # åˆ†æã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º
    print_analysis_summary(comprehensive_report)

    print("\n## ã™ã¹ã¦ã®ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã¨åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")
    print(f"çµæœã¯ {OUTPUT_DIR} ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™")

    return results


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='å®¤å†…æ¸©åº¦äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°')
    parser.add_argument('--test', action='store_true', help='ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œï¼ˆã‚µãƒ–ã‚»ãƒƒãƒˆã®ãƒ‡ãƒ¼ã‚¿ã¨ã‚¾ãƒ¼ãƒ³ã§å‡¦ç†ï¼‰')
    parser.add_argument('--zones', type=int, nargs='+', help='å‡¦ç†å¯¾è±¡ã®ã‚¾ãƒ¼ãƒ³ç•ªå·')
    parser.add_argument('--horizons', type=int, nargs='+', help='å‡¦ç†å¯¾è±¡ã®äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰')
    args = parser.parse_args()
    main(
        test_mode=args.test,
        target_zones=args.zones,
        target_horizons=args.horizons
    )
