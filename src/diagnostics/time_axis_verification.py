#!/usr/bin/env python
# coding: utf-8

"""
æ™‚é–“è»¸æ•´åˆæ€§æ¤œè¨¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
äºˆæ¸¬å€¤ã¨å®Ÿæ¸¬å€¤ã®æ™‚é–“è»¸å¯¾å¿œé–¢ä¿‚ã‚’è©³ç´°ã«æ¤œè¨¼
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from typing import Dict, Any, Tuple, List
import warnings
warnings.filterwarnings('ignore')


def verify_time_axis_alignment(df: pd.DataFrame,
                              zone: int,
                              horizon: int,
                              test_predictions: np.ndarray,
                              test_y: pd.Series,
                              test_data: pd.DataFrame,
                              save_dir: str = None) -> Dict[str, Any]:
    """
    æ™‚é–“è»¸æ•´åˆæ€§ã®è©³ç´°æ¤œè¨¼

    Parameters:
    -----------
    df : pd.DataFrame
        å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆç›®çš„å¤‰æ•°ä½œæˆå‰ï¼‰
    zone : int
        ã‚¾ãƒ¼ãƒ³ç•ªå·
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰
    test_predictions : np.ndarray
        äºˆæ¸¬å€¤
    test_y : pd.Series
        ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç›®çš„å¤‰æ•°ï¼ˆã‚·ãƒ•ãƒˆæ¸ˆã¿ï¼‰
    test_data : pd.DataFrame
        ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    save_dir : str, optional
        çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

    Returns:
    --------
    dict
        æ¤œè¨¼çµæœ
    """

    verification_results = {
        'zone': zone,
        'horizon': horizon,
        'data_structure_analysis': {},
        'time_axis_mapping': {},
        'alignment_verification': {},
        'visualization_correctness': {},
        'recommendations': []
    }

    print(f"\n{'='*60}")
    print(f"ã‚¾ãƒ¼ãƒ³ {zone} - {horizon}åˆ†äºˆæ¸¬ã®æ™‚é–“è»¸æ•´åˆæ€§æ¤œè¨¼")
    print(f"{'='*60}")

    # 1. ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®åˆ†æ
    verification_results['data_structure_analysis'] = _analyze_data_structure(
        df, zone, horizon, test_y, test_data
    )

    # 2. æ™‚é–“è»¸ãƒãƒƒãƒ”ãƒ³ã‚°ã®åˆ†æ
    verification_results['time_axis_mapping'] = _analyze_time_axis_mapping(
        test_data, test_y, horizon
    )

    # 3. æ•´åˆæ€§ã®æ¤œè¨¼
    verification_results['alignment_verification'] = _verify_alignment(
        test_data, test_y, test_predictions, horizon
    )

    # 4. å¯è¦–åŒ–ã®æ­£ç¢ºæ€§æ¤œè¨¼
    verification_results['visualization_correctness'] = _verify_visualization_correctness(
        test_data, test_y, test_predictions, zone, horizon, save_dir
    )

    # 5. æ¨å¥¨äº‹é …ã®ç”Ÿæˆ
    verification_results['recommendations'] = _generate_time_axis_recommendations(
        verification_results
    )

    return verification_results


def _analyze_data_structure(df: pd.DataFrame,
                           zone: int,
                           horizon: int,
                           test_y: pd.Series,
                           test_data: pd.DataFrame) -> Dict[str, Any]:
    """
    ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®è©³ç´°åˆ†æ
    """
    print("\nğŸ” 1. ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®åˆ†æ")

    analysis = {
        'original_temp_column': f'sens_temp_{zone}',
        'target_column': f'sens_temp_{zone}_future_{horizon}',
        'original_data_available': False,
        'target_data_available': False,
        'test_y_source': 'unknown',
        'time_index_info': {}
    }

    # å…ƒã®æ¸©åº¦åˆ—ã®ç¢ºèª
    original_col = f'sens_temp_{zone}'
    if original_col in df.columns:
        analysis['original_data_available'] = True
        print(f"âœ… å…ƒã®æ¸©åº¦ãƒ‡ãƒ¼ã‚¿åˆ—ãŒåˆ©ç”¨å¯èƒ½: {original_col}")
    else:
        print(f"âŒ å…ƒã®æ¸©åº¦ãƒ‡ãƒ¼ã‚¿åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {original_col}")

    # ç›®çš„å¤‰æ•°åˆ—ã®ç¢ºèª
    target_col = f'sens_temp_{zone}_future_{horizon}'
    if target_col in test_data.columns:
        analysis['target_data_available'] = True
        print(f"âœ… ç›®çš„å¤‰æ•°åˆ—ãŒåˆ©ç”¨å¯èƒ½: {target_col}")

        # test_yã®å‡ºæ‰€ã‚’ç¢ºèª
        if isinstance(test_y, pd.Series) and test_y.name == target_col:
            analysis['test_y_source'] = 'target_column'
            print(f"âœ… test_yã¯ç›®çš„å¤‰æ•°åˆ— {target_col} ã‹ã‚‰å–å¾—")
        else:
            analysis['test_y_source'] = 'other'
            print(f"âš ï¸ test_yã®å‡ºæ‰€ãŒä¸æ˜: {test_y.name if hasattr(test_y, 'name') else 'unnamed'}")
    else:
        print(f"âŒ ç›®çš„å¤‰æ•°åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {target_col}")

    # æ™‚é–“ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æƒ…å ±
    analysis['time_index_info'] = {
        'test_data_start': test_data.index.min(),
        'test_data_end': test_data.index.max(),
        'test_data_length': len(test_data),
        'test_y_length': len(test_y),
        'time_interval': _estimate_time_interval(test_data.index)
    }

    print(f"ğŸ“… ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æœŸé–“: {analysis['time_index_info']['test_data_start']} ï½ {analysis['time_index_info']['test_data_end']}")
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿é•·: test_data={analysis['time_index_info']['test_data_length']}, test_y={analysis['time_index_info']['test_y_length']}")
    print(f"â±ï¸ æ¨å®šæ™‚é–“é–“éš”: {analysis['time_index_info']['time_interval']}")

    return analysis


def _analyze_time_axis_mapping(test_data: pd.DataFrame,
                              test_y: pd.Series,
                              horizon: int) -> Dict[str, Any]:
    """
    æ™‚é–“è»¸ãƒãƒƒãƒ”ãƒ³ã‚°ã®è©³ç´°åˆ†æ
    """
    print("\nğŸ• 2. æ™‚é–“è»¸ãƒãƒƒãƒ”ãƒ³ã‚°ã®åˆ†æ")

    mapping_analysis = {
        'input_timestamps': [],
        'target_timestamps': [],
        'expected_prediction_timestamps': [],
        'shift_verification': {},
        'mapping_examples': []
    }

    # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
    valid_indices = test_y.dropna().index

    if len(valid_indices) > 0:
        # ã‚µãƒ³ãƒ—ãƒ«ã¨ã—ã¦æœ€åˆã®5ã¤ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’åˆ†æ
        sample_indices = valid_indices[:5]

        print(f"ğŸ“‹ ã‚µãƒ³ãƒ—ãƒ«åˆ†æï¼ˆæœ€åˆã®5ã¤ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼‰:")

        for i, timestamp in enumerate(sample_indices):
            # å…¥åŠ›ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
            input_time = timestamp

            # æœŸå¾…ã•ã‚Œã‚‹äºˆæ¸¬ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆå…¥åŠ›æ™‚åˆ» + horizonï¼‰
            expected_pred_time = timestamp + pd.Timedelta(minutes=horizon)

            # å®Ÿéš›ã®ç›®çš„å¤‰æ•°ã®å€¤ï¼ˆã“ã‚Œã¯æ—¢ã«ã‚·ãƒ•ãƒˆæ¸ˆã¿ï¼‰
            target_value = test_y.loc[timestamp]

            mapping_example = {
                'input_timestamp': input_time,
                'expected_prediction_timestamp': expected_pred_time,
                'target_value': target_value,
                'explanation': f"å…¥åŠ›æ™‚åˆ» {input_time} â†’ äºˆæ¸¬å¯¾è±¡æ™‚åˆ» {expected_pred_time}"
            }

            mapping_analysis['mapping_examples'].append(mapping_example)

            print(f"  {i+1}. å…¥åŠ›: {input_time} â†’ äºˆæ¸¬å¯¾è±¡: {expected_pred_time} (å€¤: {target_value:.2f})")

        # ã‚·ãƒ•ãƒˆæ¤œè¨¼
        mapping_analysis['shift_verification'] = _verify_shift_correctness(
            test_data, test_y, horizon
        )

    return mapping_analysis


def _verify_shift_correctness(test_data: pd.DataFrame,
                             test_y: pd.Series,
                             horizon: int) -> Dict[str, Any]:
    """
    ã‚·ãƒ•ãƒˆã®æ­£ç¢ºæ€§ã‚’æ¤œè¨¼
    """
    print("\nğŸ”„ ã‚·ãƒ•ãƒˆæ¤œè¨¼:")

    shift_verification = {
        'is_correct_shift': False,
        'detected_shift_minutes': 0,
        'verification_method': 'correlation_analysis',
        'details': {}
    }

    # å…ƒã®æ¸©åº¦ãƒ‡ãƒ¼ã‚¿ã‚’æ¢ã™
    temp_cols = [col for col in test_data.columns if 'sens_temp' in col and 'future' not in col]

    if temp_cols:
        original_col = temp_cols[0]  # æœ€åˆã®æ¸©åº¦åˆ—ã‚’ä½¿ç”¨
        original_temp = test_data[original_col].dropna()

        # å…±é€šã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å–å¾—
        common_timestamps = original_temp.index.intersection(test_y.index)

        if len(common_timestamps) > 50:
            # ç›¸é–¢åˆ†æã«ã‚ˆã‚‹æ¤œè¨¼
            correlations = {}

            for shift_min in range(0, horizon + 20, 5):  # 0åˆ†ã‹ã‚‰ horizon+20åˆ†ã¾ã§5åˆ†åˆ»ã¿
                try:
                    # å…ƒãƒ‡ãƒ¼ã‚¿ã‚’shift_minåˆ†å¾Œã«ã‚·ãƒ•ãƒˆ
                    shifted_original = original_temp.shift(-shift_min // 5)  # 5åˆ†é–“éš”ã¨ä»®å®š

                    # å…±é€šã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã§ç›¸é–¢ã‚’è¨ˆç®—
                    common_idx = shifted_original.index.intersection(test_y.index)
                    if len(common_idx) > 10:
                        corr = np.corrcoef(
                            shifted_original.loc[common_idx].values,
                            test_y.loc[common_idx].values
                        )[0, 1]

                        if not np.isnan(corr):
                            correlations[shift_min] = corr

                except Exception as e:
                    continue

            if correlations:
                # æœ€é«˜ç›¸é–¢ã®ã‚·ãƒ•ãƒˆé‡ã‚’ç‰¹å®š
                best_shift = max(correlations.keys(), key=lambda k: abs(correlations[k]))
                best_corr = correlations[best_shift]

                shift_verification['detected_shift_minutes'] = best_shift
                shift_verification['is_correct_shift'] = abs(best_shift - horizon) <= 5  # 5åˆ†ã®èª¤å·®è¨±å®¹
                shift_verification['details'] = {
                    'best_correlation': best_corr,
                    'expected_shift': horizon,
                    'detected_shift': best_shift,
                    'all_correlations': correlations
                }

                print(f"  æœŸå¾…ã‚·ãƒ•ãƒˆ: {horizon}åˆ†")
                print(f"  æ¤œå‡ºã‚·ãƒ•ãƒˆ: {best_shift}åˆ†")
                print(f"  æœ€é«˜ç›¸é–¢: {best_corr:.3f}")
                print(f"  ã‚·ãƒ•ãƒˆæ­£ç¢ºæ€§: {'âœ… æ­£ç¢º' if shift_verification['is_correct_shift'] else 'âŒ ä¸æ­£ç¢º'}")

    return shift_verification


def _verify_alignment(test_data: pd.DataFrame,
                     test_y: pd.Series,
                     test_predictions: np.ndarray,
                     horizon: int) -> Dict[str, Any]:
    """
    äºˆæ¸¬å€¤ã¨å®Ÿæ¸¬å€¤ã®æ•´åˆæ€§æ¤œè¨¼
    """
    print("\nğŸ¯ 3. äºˆæ¸¬å€¤ã¨å®Ÿæ¸¬å€¤ã®æ•´åˆæ€§æ¤œè¨¼")

    alignment_verification = {
        'data_length_match': False,
        'timestamp_alignment': False,
        'value_range_consistency': False,
        'details': {}
    }

    # ãƒ‡ãƒ¼ã‚¿é•·ã®ç¢ºèª
    pred_length = len(test_predictions)
    target_length = len(test_y)

    alignment_verification['data_length_match'] = pred_length == target_length
    print(f"ğŸ“ ãƒ‡ãƒ¼ã‚¿é•·: äºˆæ¸¬å€¤={pred_length}, å®Ÿæ¸¬å€¤={target_length} {'âœ…' if alignment_verification['data_length_match'] else 'âŒ'}")

    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®æ•´åˆæ€§
    if hasattr(test_y, 'index'):
        alignment_verification['timestamp_alignment'] = True
        print(f"ğŸ“… ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ•´åˆæ€§: âœ… test_yã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚ã‚Š")
    else:
        print(f"ğŸ“… ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ•´åˆæ€§: âŒ test_yã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãªã—")

    # å€¤ã®ç¯„å›²ã®ä¸€è²«æ€§
    if len(test_predictions) > 0 and len(test_y) > 0:
        pred_range = (np.min(test_predictions), np.max(test_predictions))
        target_range = (np.min(test_y), np.max(test_y))

        range_diff = abs((pred_range[1] - pred_range[0]) - (target_range[1] - target_range[0]))
        alignment_verification['value_range_consistency'] = range_diff < 10  # 10åº¦ä»¥å†…ã®å·®

        alignment_verification['details'] = {
            'prediction_range': pred_range,
            'target_range': target_range,
            'range_difference': range_diff
        }

        print(f"ğŸ“Š å€¤ã®ç¯„å›²: äºˆæ¸¬å€¤={pred_range[0]:.1f}ï½{pred_range[1]:.1f}, å®Ÿæ¸¬å€¤={target_range[0]:.1f}ï½{target_range[1]:.1f}")
        print(f"ğŸ“Š ç¯„å›²ä¸€è²«æ€§: {'âœ…' if alignment_verification['value_range_consistency'] else 'âŒ'}")

    return alignment_verification


def _verify_visualization_correctness(test_data: pd.DataFrame,
                                    test_y: pd.Series,
                                    test_predictions: np.ndarray,
                                    zone: int,
                                    horizon: int,
                                    save_dir: str = None) -> Dict[str, Any]:
    """
    å¯è¦–åŒ–ã®æ­£ç¢ºæ€§æ¤œè¨¼ã¨ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    """
    print("\nğŸ“ˆ 4. å¯è¦–åŒ–ã®æ­£ç¢ºæ€§æ¤œè¨¼")

    visualization_verification = {
        'correct_plotting_method': 'demonstrated',
        'common_mistakes': [],
        'demonstration_created': False
    }

    try:
        # å¯è¦–åŒ–ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ä½œæˆ
        fig = _create_time_axis_demonstration(
            test_data, test_y, test_predictions, zone, horizon, save_dir
        )

        if fig is not None:
            visualization_verification['demonstration_created'] = True
            print("âœ… æ™‚é–“è»¸ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆå®Œäº†")

    except Exception as e:
        print(f"âŒ å¯è¦–åŒ–ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")

    # ä¸€èˆ¬çš„ãªé–“é•ã„ã®ç‰¹å®š
    common_mistakes = [
        "äºˆæ¸¬å€¤ã‚’å…¥åŠ›ã¨åŒã˜ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§ãƒ—ãƒ­ãƒƒãƒˆ",
        "ç›®çš„å¤‰æ•°ï¼ˆã‚·ãƒ•ãƒˆæ¸ˆã¿ï¼‰ã‚’å…ƒã®æ™‚é–“è»¸ã§ãƒ—ãƒ­ãƒƒãƒˆ",
        "äºˆæ¸¬å€¤ã®æ™‚é–“è»¸ã‚’èª¿æ•´ã›ãšã«ãã®ã¾ã¾ãƒ—ãƒ­ãƒƒãƒˆ"
    ]

    visualization_verification['common_mistakes'] = common_mistakes

    print("âš ï¸ ä¸€èˆ¬çš„ãªå¯è¦–åŒ–ã®é–“é•ã„:")
    for mistake in common_mistakes:
        print(f"  - {mistake}")

    return visualization_verification


def _create_time_axis_demonstration(test_data: pd.DataFrame,
                                  test_y: pd.Series,
                                  test_predictions: np.ndarray,
                                  zone: int,
                                  horizon: int,
                                  save_dir: str = None) -> plt.Figure:
    """
    æ™‚é–“è»¸ã®æ­£ã—ã„è¡¨ç¤ºæ–¹æ³•ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    """
    from ..utils.font_config import get_font_properties

    # ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
    font_prop = get_font_properties()

    # ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
    valid_indices = test_y.dropna().index
    if len(valid_indices) == 0:
        return None

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®é¸æŠï¼ˆæœ€æ–°100ãƒã‚¤ãƒ³ãƒˆï¼‰
    sample_size = min(100, len(valid_indices))
    sample_indices = valid_indices[-sample_size:]

    # ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
    input_timestamps = sample_indices
    actual_values = test_y.loc[sample_indices].values
    predicted_values = test_predictions[-sample_size:] if len(test_predictions) >= sample_size else test_predictions

    # æ­£ã—ã„äºˆæ¸¬ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®è¨ˆç®—
    correct_prediction_timestamps = input_timestamps + pd.Timedelta(minutes=horizon)

    # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
    fig, axes = plt.subplots(3, 1, figsize=(16, 12))

    # 1. é–“é•ã£ãŸè¡¨ç¤ºæ–¹æ³•
    axes[0].plot(input_timestamps, actual_values, 'b-', linewidth=2, label='å®Ÿæ¸¬å€¤', alpha=0.8)
    axes[0].plot(input_timestamps, predicted_values, 'r--', linewidth=2, label='äºˆæ¸¬å€¤ï¼ˆé–“é•ã£ãŸæ™‚é–“è»¸ï¼‰', alpha=0.8)
    axes[0].set_title(f'âŒ é–“é•ã£ãŸè¡¨ç¤ºæ–¹æ³•: äºˆæ¸¬å€¤ãŒå…¥åŠ›ã¨åŒã˜æ™‚åˆ»ã«è¡¨ç¤º',
                     fontproperties=font_prop, fontsize=14, color='red', fontweight='bold')
    axes[0].set_ylabel('æ¸©åº¦ (Â°C)', fontproperties=font_prop)
    axes[0].legend(prop=font_prop)
    axes[0].grid(True, alpha=0.3)

    # 2. æ­£ã—ã„è¡¨ç¤ºæ–¹æ³•
    axes[1].plot(input_timestamps, actual_values, 'b-', linewidth=2, label='å®Ÿæ¸¬å€¤ï¼ˆå…¥åŠ›æ™‚åˆ»ï¼‰', alpha=0.8)
    axes[1].plot(correct_prediction_timestamps, predicted_values, 'r--', linewidth=2,
                label=f'äºˆæ¸¬å€¤ï¼ˆæ­£ã—ã„æ™‚é–“è»¸: +{horizon}åˆ†ï¼‰', alpha=0.8)
    axes[1].set_title(f'âœ… æ­£ã—ã„è¡¨ç¤ºæ–¹æ³•: äºˆæ¸¬å€¤ãŒæœªæ¥ã®æ™‚åˆ»ï¼ˆ+{horizon}åˆ†ï¼‰ã«è¡¨ç¤º',
                     fontproperties=font_prop, fontsize=14, color='green', fontweight='bold')
    axes[1].set_ylabel('æ¸©åº¦ (Â°C)', fontproperties=font_prop)
    axes[1].legend(prop=font_prop)
    axes[1].grid(True, alpha=0.3)

    # 3. æ¯”è¼ƒç”¨ï¼šå®Ÿæ¸¬å€¤ã®æœªæ¥å€¤ã¨ã®æ¯”è¼ƒ
    future_actual_timestamps = input_timestamps + pd.Timedelta(minutes=horizon)

    # æœªæ¥ã®å®Ÿæ¸¬å€¤ã‚’å–å¾—ï¼ˆåˆ©ç”¨å¯èƒ½ãªå ´åˆï¼‰
    future_actual_values = []
    for ts in future_actual_timestamps:
        if ts in test_y.index:
            future_actual_values.append(test_y.loc[ts])
        else:
            future_actual_values.append(np.nan)

    future_actual_values = np.array(future_actual_values)
    valid_future = ~np.isnan(future_actual_values)

    if np.sum(valid_future) > 0:
        axes[2].plot(future_actual_timestamps[valid_future], future_actual_values[valid_future],
                    'g-', linewidth=2, label=f'å®Ÿæ¸¬å€¤ï¼ˆ+{horizon}åˆ†å¾Œï¼‰', alpha=0.8)
        axes[2].plot(correct_prediction_timestamps[valid_future], predicted_values[valid_future],
                    'r--', linewidth=2, label=f'äºˆæ¸¬å€¤ï¼ˆ+{horizon}åˆ†å¾Œï¼‰', alpha=0.8)
        axes[2].set_title(f'ğŸ“Š æ¯”è¼ƒæ¤œè¨¼: äºˆæ¸¬å€¤ vs å®Ÿéš›ã®{horizon}åˆ†å¾Œã®å®Ÿæ¸¬å€¤',
                         fontproperties=font_prop, fontsize=14, color='blue', fontweight='bold')
    else:
        axes[2].text(0.5, 0.5, f'{horizon}åˆ†å¾Œã®å®Ÿæ¸¬å€¤ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³',
                    transform=axes[2].transAxes, ha='center', va='center',
                    fontproperties=font_prop, fontsize=12)
        axes[2].set_title(f'ğŸ“Š æ¯”è¼ƒæ¤œè¨¼: ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚è¡¨ç¤ºä¸å¯',
                         fontproperties=font_prop, fontsize=14, color='orange')

    axes[2].set_xlabel('æ—¥æ™‚', fontproperties=font_prop)
    axes[2].set_ylabel('æ¸©åº¦ (Â°C)', fontproperties=font_prop)
    axes[2].legend(prop=font_prop)
    axes[2].grid(True, alpha=0.3)

    # Xè»¸ã®æ›¸å¼è¨­å®š
    for ax in axes:
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d\n%H:%M'))
        ax.tick_params(axis='x', rotation=45)

    plt.tight_layout()

    # ä¿å­˜
    if save_dir:
        import os
        os.makedirs(save_dir, exist_ok=True)
        save_path = os.path.join(save_dir, f'time_axis_verification_zone_{zone}_horizon_{horizon}.png')
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"ğŸ“ æ™‚é–“è»¸æ¤œè¨¼ãƒ—ãƒ­ãƒƒãƒˆä¿å­˜: {save_path}")

    return fig


def _generate_time_axis_recommendations(verification_results: Dict[str, Any]) -> List[str]:
    """
    æ™‚é–“è»¸ã«é–¢ã™ã‚‹æ¨å¥¨äº‹é …ã®ç”Ÿæˆ
    """
    recommendations = []

    # ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®å•é¡Œ
    data_analysis = verification_results['data_structure_analysis']
    if not data_analysis['original_data_available']:
        recommendations.append("å…ƒã®æ¸©åº¦ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    if not data_analysis['target_data_available']:
        recommendations.append("ç›®çš„å¤‰æ•°ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    # ã‚·ãƒ•ãƒˆã®å•é¡Œ
    mapping_analysis = verification_results['time_axis_mapping']
    if 'shift_verification' in mapping_analysis:
        shift_verification = mapping_analysis['shift_verification']
        if not shift_verification['is_correct_shift']:
            recommendations.append(
                f"ã‚·ãƒ•ãƒˆãŒä¸æ­£ç¢ºã§ã™ã€‚æœŸå¾…å€¤: {verification_results['horizon']}åˆ†, "
                f"æ¤œå‡ºå€¤: {shift_verification['detected_shift_minutes']}åˆ†"
            )

    # æ•´åˆæ€§ã®å•é¡Œ
    alignment = verification_results['alignment_verification']
    if not alignment['data_length_match']:
        recommendations.append("äºˆæ¸¬å€¤ã¨å®Ÿæ¸¬å€¤ã®ãƒ‡ãƒ¼ã‚¿é•·ãŒä¸€è‡´ã—ã¾ã›ã‚“ã€‚")

    if not alignment['timestamp_alignment']:
        recommendations.append("ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®æ•´åˆæ€§ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚")

    # å¯è¦–åŒ–ã®æ¨å¥¨äº‹é …
    recommendations.extend([
        "âœ… æ­£ã—ã„å¯è¦–åŒ–æ–¹æ³•: äºˆæ¸¬å€¤ã¯ã€Œå…¥åŠ›æ™‚åˆ» + äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã€ã§ãƒ—ãƒ­ãƒƒãƒˆã—ã¦ãã ã•ã„",
        "âœ… å®Ÿæ¸¬å€¤ã¯ç›®çš„å¤‰æ•°ï¼ˆã‚·ãƒ•ãƒˆæ¸ˆã¿ï¼‰ã§ã¯ãªãã€å¯¾å¿œã™ã‚‹æœªæ¥æ™‚åˆ»ã®å®Ÿæ¸¬å€¤ã¨æ¯”è¼ƒã—ã¦ãã ã•ã„",
        "âœ… æ™‚é–“è»¸ã®ãƒ©ãƒ™ãƒ«ã‚’æ˜ç¢ºã«ã—ã¦ã€ã©ã®æ™‚åˆ»ã®å€¤ã‹ã‚’æ˜ç¤ºã—ã¦ãã ã•ã„"
    ])

    return recommendations


def _estimate_time_interval(time_index: pd.DatetimeIndex) -> str:
    """
    æ™‚é–“é–“éš”ã®æ¨å®š
    """
    if len(time_index) < 2:
        return "ä¸æ˜"

    intervals = time_index[1:] - time_index[:-1]
    most_common_interval = intervals.value_counts().index[0]

    return str(most_common_interval)


def run_comprehensive_time_axis_verification(results_dict: Dict,
                                           original_df: pd.DataFrame,
                                           save_dir: str = None) -> Dict[str, Any]:
    """
    å…¨ã‚¾ãƒ¼ãƒ³ãƒ»ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã®æ™‚é–“è»¸æ¤œè¨¼ã‚’å®Ÿè¡Œ

    Parameters:
    -----------
    results_dict : dict
        ãƒ¢ãƒ‡ãƒ«çµæœè¾æ›¸
    original_df : pd.DataFrame
        å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    save_dir : str, optional
        çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

    Returns:
    --------
    dict
        æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼
    """
    print("\n" + "="*80)
    print("ğŸ• åŒ…æ‹¬çš„æ™‚é–“è»¸æ•´åˆæ€§æ¤œè¨¼")
    print("="*80)

    verification_summary = {
        'total_verifications': 0,
        'correct_alignments': 0,
        'incorrect_alignments': 0,
        'zone_horizon_results': {},
        'common_issues': [],
        'overall_recommendations': []
    }

    for zone, zone_results in results_dict.items():
        for horizon, horizon_results in zone_results.items():
            # å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
            required_keys = ['test_data', 'test_y', 'test_predictions']
            if not all(k in horizon_results for k in required_keys):
                continue

            verification_summary['total_verifications'] += 1

            # å€‹åˆ¥æ¤œè¨¼ã®å®Ÿè¡Œ
            verification_result = verify_time_axis_alignment(
                df=original_df,
                zone=zone,
                horizon=horizon,
                test_predictions=horizon_results['test_predictions'],
                test_y=horizon_results['test_y'],
                test_data=horizon_results['test_data'],
                save_dir=save_dir
            )

            verification_summary['zone_horizon_results'][f'zone_{zone}_horizon_{horizon}'] = verification_result

            # æ•´åˆæ€§ã®åˆ¤å®š
            alignment_ok = (
                verification_result['alignment_verification']['data_length_match'] and
                verification_result['alignment_verification']['timestamp_alignment']
            )

            if alignment_ok:
                verification_summary['correct_alignments'] += 1
            else:
                verification_summary['incorrect_alignments'] += 1

    # å…±é€šå•é¡Œã®ç‰¹å®š
    verification_summary['common_issues'] = _identify_common_time_axis_issues(
        verification_summary['zone_horizon_results']
    )

    # å…¨ä½“çš„ãªæ¨å¥¨äº‹é …
    verification_summary['overall_recommendations'] = _generate_overall_time_axis_recommendations(
        verification_summary
    )

    # ã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º
    print(f"\nğŸ“Š æ¤œè¨¼ã‚µãƒãƒªãƒ¼:")
    print(f"  ç·æ¤œè¨¼æ•°: {verification_summary['total_verifications']}")
    print(f"  æ­£ã—ã„æ•´åˆæ€§: {verification_summary['correct_alignments']}")
    print(f"  å•é¡Œã®ã‚ã‚‹æ•´åˆæ€§: {verification_summary['incorrect_alignments']}")

    if verification_summary['overall_recommendations']:
        print(f"\nğŸ’¡ å…¨ä½“çš„ãªæ¨å¥¨äº‹é …:")
        for rec in verification_summary['overall_recommendations']:
            print(f"  - {rec}")

    return verification_summary


def _identify_common_time_axis_issues(zone_horizon_results: Dict) -> List[str]:
    """
    å…±é€šã®æ™‚é–“è»¸å•é¡Œã‚’ç‰¹å®š
    """
    issues = []
    total_results = len(zone_horizon_results)

    if total_results == 0:
        return issues

    # å„å•é¡Œã®å‡ºç¾é »åº¦ã‚’è¨ˆç®—
    shift_issues = 0
    alignment_issues = 0
    data_length_issues = 0

    for result in zone_horizon_results.values():
        if 'shift_verification' in result['time_axis_mapping']:
            if not result['time_axis_mapping']['shift_verification']['is_correct_shift']:
                shift_issues += 1

        if not result['alignment_verification']['data_length_match']:
            data_length_issues += 1

        if not result['alignment_verification']['timestamp_alignment']:
            alignment_issues += 1

    # 50%ä»¥ä¸Šã§ç™ºç”Ÿã—ã¦ã„ã‚‹å•é¡Œã‚’å…±é€šå•é¡Œã¨ã™ã‚‹
    if shift_issues / total_results >= 0.5:
        issues.append(f"ã‚·ãƒ•ãƒˆå‡¦ç†ã®å•é¡ŒãŒ{shift_issues}/{total_results}ã®ã‚±ãƒ¼ã‚¹ã§æ¤œå‡ºã•ã‚Œã¾ã—ãŸ")

    if data_length_issues / total_results >= 0.5:
        issues.append(f"ãƒ‡ãƒ¼ã‚¿é•·ã®ä¸æ•´åˆãŒ{data_length_issues}/{total_results}ã®ã‚±ãƒ¼ã‚¹ã§æ¤œå‡ºã•ã‚Œã¾ã—ãŸ")

    if alignment_issues / total_results >= 0.5:
        issues.append(f"ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ•´åˆæ€§ã®å•é¡ŒãŒ{alignment_issues}/{total_results}ã®ã‚±ãƒ¼ã‚¹ã§æ¤œå‡ºã•ã‚Œã¾ã—ãŸ")

    return issues


def _generate_overall_time_axis_recommendations(verification_summary: Dict) -> List[str]:
    """
    å…¨ä½“çš„ãªæ™‚é–“è»¸æ¨å¥¨äº‹é …ã®ç”Ÿæˆ
    """
    recommendations = []

    total = verification_summary['total_verifications']
    incorrect = verification_summary['incorrect_alignments']

    if total == 0:
        recommendations.append("æ¤œè¨¼å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return recommendations

    if incorrect / total > 0.5:
        recommendations.append(
            "âš ï¸ 50%ä»¥ä¸Šã®ã‚±ãƒ¼ã‚¹ã§æ™‚é–“è»¸ã®å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®è¦‹ç›´ã—ãŒå¿…è¦ã§ã™ã€‚"
        )

    if verification_summary['common_issues']:
        recommendations.append(
            "ğŸ”§ å…±é€šå•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ä»¥ä¸‹ã®ç‚¹ã‚’é‡ç‚¹çš„ã«ä¿®æ­£ã—ã¦ãã ã•ã„ï¼š"
        )
        recommendations.extend([f"  - {issue}" for issue in verification_summary['common_issues']])

    # åŸºæœ¬çš„ãªæ¨å¥¨äº‹é …
    recommendations.extend([
        "ğŸ“ˆ å¯è¦–åŒ–æ™‚ã¯å¿…ãšäºˆæ¸¬å€¤ã‚’ã€Œå…¥åŠ›æ™‚åˆ» + äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã€ã§ãƒ—ãƒ­ãƒƒãƒˆã—ã¦ãã ã•ã„",
        "ğŸ” å®Ÿæ¸¬å€¤ã¨ã®æ¯”è¼ƒã¯åŒã˜æ™‚åˆ»ã®å€¤åŒå£«ã§è¡Œã£ã¦ãã ã•ã„",
        "ğŸ“ ãƒ—ãƒ­ãƒƒãƒˆã«ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®èª¬æ˜ã‚’æ˜è¨˜ã—ã¦ãã ã•ã„"
    ])

    return recommendations
