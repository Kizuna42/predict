#!/usr/bin/env python
# coding: utf-8

"""
å¯è¦–åŒ–çµ±åˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
å„ç¨®å¯è¦–åŒ–æ©Ÿèƒ½ã®çµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æä¾›
"""

# åŸºæœ¬çš„ãªå¯è¦–åŒ–æ©Ÿèƒ½ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from .basic_plots import (
    plot_feature_importance
)

# é«˜åº¦ãªå¯è¦–åŒ–æ©Ÿèƒ½ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from .advanced_visualization import (
    plot_corrected_time_series_by_horizon,
    plot_ultra_detailed_minute_analysis
)

# è¨ºæ–­æ©Ÿèƒ½ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ..diagnostics import (
    analyze_lag_dependency,
    detect_lag_following_pattern,
    validate_prediction_timing,
    create_correct_prediction_timestamps,
    analyze_feature_patterns,
    calculate_comprehensive_metrics
)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
from typing import Dict, Any, List, Optional


def create_detailed_analysis_for_zone(results_dict: Dict, zone: int, horizon: int,
                                    save_dir: Optional[str] = None, save: bool = True) -> Dict[str, Any]:
    """
    ç‰¹å®šã‚¾ãƒ¼ãƒ³ã®è©³ç´°åˆ†æã‚’å®Ÿè¡Œï¼ˆç°¡ç´ åŒ–ç‰ˆï¼‰

    Parameters:
    -----------
    results_dict : dict
        çµæœè¾æ›¸
    zone : int
        ã‚¾ãƒ¼ãƒ³ç•ªå·
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰
    save_dir : str, optional
        ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    save : bool, optional
        ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã™ã‚‹ã‹

    Returns:
    --------
    dict
        è©³ç´°åˆ†æçµæœ
    """
    analysis_results = {
        'zone': zone,
        'horizon': horizon,
        'analysis_completed': False,
        'error_message': None
    }

    try:
        # ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        zone_results = results_dict.get(zone, {})
        horizon_results = zone_results.get(horizon, {})

        if not horizon_results:
            analysis_results['error_message'] = f"ã‚¾ãƒ¼ãƒ³ {zone}, ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ {horizon} ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            return analysis_results

        # å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
        required_keys = ['test_data', 'test_y', 'test_predictions', 'feature_importance']
        missing_keys = [key for key in required_keys if key not in horizon_results]

        if missing_keys:
            analysis_results['error_message'] = f"å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing_keys}"
            return analysis_results

        # ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        test_df = horizon_results['test_data']
        test_y = horizon_results['test_y']
        test_predictions = horizon_results['test_predictions']
        feature_importance = horizon_results['feature_importance']

        # LAGä¾å­˜åº¦åˆ†æ
        zone_system = zone_results.get('system', 'Unknown')
        lag_dependency = analyze_lag_dependency(feature_importance, zone, horizon, zone_system)
        analysis_results['lag_dependency'] = lag_dependency

        # ç‰¹å¾´é‡ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
        feature_patterns = analyze_feature_patterns(feature_importance, zone, horizon)
        analysis_results['feature_patterns'] = feature_patterns

        # æ€§èƒ½æŒ‡æ¨™è¨ˆç®—
        performance_metrics = calculate_comprehensive_metrics(test_y.values, test_predictions, zone, horizon)
        analysis_results['performance_metrics'] = performance_metrics

        # æ™‚é–“è»¸æ¤œè¨¼
        if isinstance(test_df, pd.DataFrame) and hasattr(test_df, 'index'):
            timestamps = test_df.index
            time_validation = validate_prediction_timing(timestamps, test_y.values, test_predictions, horizon, zone)
            analysis_results['time_validation'] = time_validation

            # å¾Œè¿½ã„ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡º
            lag_following = detect_lag_following_pattern(timestamps, test_y.values, test_predictions, horizon)
            analysis_results['lag_following'] = lag_following

        # å¯è¦–åŒ–ã®ç”Ÿæˆï¼ˆç°¡ç´ åŒ–ï¼šç‰¹å¾´é‡é‡è¦åº¦ã®ã¿ï¼‰
        if save_dir:
            # ç‰¹å¾´é‡é‡è¦åº¦ãƒ—ãƒ­ãƒƒãƒˆ
            plot_feature_importance(feature_importance, zone, horizon, save_dir, save=save)

        analysis_results['analysis_completed'] = True

    except Exception as e:
        analysis_results['error_message'] = f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"

    return analysis_results


def create_comprehensive_analysis_report(results_dict: Dict, horizons: List[int],
                                       save_dir: Optional[str] = None, save: bool = True) -> Dict[str, Any]:
    """
    åŒ…æ‹¬çš„ãªåˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆï¼ˆç°¡ç´ åŒ–ç‰ˆï¼‰

    Parameters:
    -----------
    results_dict : dict
        çµæœè¾æ›¸
    horizons : list
        åˆ†æå¯¾è±¡ã®ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ãƒªã‚¹ãƒˆ
    save_dir : str, optional
        ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    save : bool, optional
        ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã™ã‚‹ã‹

    Returns:
    --------
    dict
        åŒ…æ‹¬çš„åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
    """
    report = {
        'analysis_timestamp': pd.Timestamp.now(),
        'horizons_analyzed': horizons,
        'zones_analyzed': list(results_dict.keys()),
        'summary': {},
        'detailed_results': {},
        'recommendations': []
    }

    try:
        # å„ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã®åˆ†æ
        for horizon in horizons:
            print(f"\nğŸ” {horizon}åˆ†äºˆæ¸¬ã®åˆ†æã‚’é–‹å§‹...")

            # 1. æ™‚é–“è»¸ä¿®æ­£æ¸ˆã¿æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆï¼ˆå…¨ã‚¾ãƒ¼ãƒ³ï¼‰
            print(f"ğŸ“Š {horizon}åˆ†äºˆæ¸¬ã®æ™‚é–“è»¸ä¿®æ­£æ¸ˆã¿æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆã‚’ç”Ÿæˆä¸­...")
            plot_corrected_time_series_by_horizon(results_dict, horizon, save_dir, save=save)

            # 2. è¶…é«˜è§£åƒåº¦åˆ†åˆ»ã¿å¯è¦–åŒ–ï¼ˆè¤‡æ•°ã®æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
            print(f"ğŸ” {horizon}åˆ†äºˆæ¸¬ã®è¶…é«˜è§£åƒåº¦åˆ†åˆ»ã¿åˆ†æã‚’é–‹å§‹...")
            ultra_detailed_figures = plot_ultra_detailed_minute_analysis(
                results_dict, horizon, save_dir, save=save
            )

            # ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³åˆ¥ã®è©³ç´°åˆ†æï¼ˆç‰¹å¾´é‡é‡è¦åº¦ã®ã¿ï¼‰
            horizon_analysis = {}
            for zone in results_dict.keys():
                zone_analysis = create_detailed_analysis_for_zone(results_dict, zone, horizon, save_dir, save)
                if zone_analysis['analysis_completed']:
                    horizon_analysis[zone] = zone_analysis

            report['detailed_results'][horizon] = horizon_analysis

        # å…¨ä½“ã‚µãƒãƒªãƒ¼ã®ç”Ÿæˆ
        from ..diagnostics.performance_metrics import generate_performance_summary
        from ..diagnostics.lag_analysis import calculate_lag_dependency_summary
        from ..diagnostics.time_validation import generate_time_validation_report
        from ..diagnostics.feature_analysis import generate_feature_analysis_report

        # æ€§èƒ½ã‚µãƒãƒªãƒ¼
        performance_summary = generate_performance_summary(results_dict, horizons)
        report['summary']['performance'] = performance_summary

        # LAGä¾å­˜åº¦ã‚µãƒãƒªãƒ¼
        lag_summary = calculate_lag_dependency_summary(results_dict)
        report['summary']['lag_dependency'] = lag_summary

        # æ™‚é–“è»¸æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ
        time_validation_report = generate_time_validation_report(results_dict, horizons)
        report['summary']['time_validation'] = time_validation_report

        # ç‰¹å¾´é‡åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
        feature_analysis_report = generate_feature_analysis_report(results_dict, horizons)
        report['summary']['feature_analysis'] = feature_analysis_report

        # çµ±åˆæ¨å¥¨äº‹é …ã®ç”Ÿæˆ
        report['recommendations'] = _generate_integrated_recommendations(report['summary'])

        print(f"\nâœ… åŒ…æ‹¬çš„åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸ")
        print(f"ğŸ“Š åˆ†æå¯¾è±¡: {len(horizons)}ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ Ã— {len(results_dict)}ã‚¾ãƒ¼ãƒ³")
        print(f"ğŸ’¾ çµæœä¿å­˜å…ˆ: {save_dir if save_dir else 'ä¿å­˜ãªã—'}")

    except Exception as e:
        report['error'] = f"åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")

    return report


def _generate_integrated_recommendations(summary: Dict[str, Any]) -> List[str]:
    """
    çµ±åˆæ¨å¥¨äº‹é …ã‚’ç”Ÿæˆï¼ˆå†…éƒ¨é–¢æ•°ï¼‰
    """
    recommendations = []

    # æ€§èƒ½ã«åŸºã¥ãæ¨å¥¨äº‹é …
    performance = summary.get('performance', {})
    if performance.get('recommendations'):
        recommendations.extend(performance['recommendations'])

    # LAGä¾å­˜åº¦ã«åŸºã¥ãæ¨å¥¨äº‹é …
    lag_dependency = summary.get('lag_dependency', {})
    if lag_dependency.get('high_lag_models'):
        recommendations.append(
            f"é«˜LAGä¾å­˜åº¦ãƒ¢ãƒ‡ãƒ«ãŒ{len(lag_dependency['high_lag_models'])}å€‹æ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚å„ªå…ˆçš„ã«æ”¹å–„ã—ã¦ãã ã•ã„ã€‚"
        )

    # æ™‚é–“è»¸ã«åŸºã¥ãæ¨å¥¨äº‹é …
    time_validation = summary.get('time_validation', {})
    if time_validation.get('recommendations'):
        recommendations.extend(time_validation['recommendations'])

    # ç‰¹å¾´é‡åˆ†æã«åŸºã¥ãæ¨å¥¨äº‹é …
    feature_analysis = summary.get('feature_analysis', {})
    if feature_analysis.get('recommendations'):
        recommendations.extend(feature_analysis['recommendations'])

    # é‡è¤‡ã‚’é™¤å»
    unique_recommendations = list(dict.fromkeys(recommendations))

    return unique_recommendations


def print_analysis_summary(report: Dict[str, Any]) -> None:
    """
    åˆ†æã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º

    Parameters:
    -----------
    report : dict
        åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
    """
    print("\n" + "="*80)
    print("ğŸ“Š åŒ…æ‹¬çš„åˆ†æã‚µãƒãƒªãƒ¼")
    print("="*80)

    # åŸºæœ¬æƒ…å ±
    print(f"ğŸ• åˆ†æå®Ÿè¡Œæ™‚åˆ»: {report.get('analysis_timestamp', 'Unknown')}")
    print(f"ğŸ¯ åˆ†æå¯¾è±¡: {len(report.get('horizons_analyzed', []))}ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ Ã— {len(report.get('zones_analyzed', []))}ã‚¾ãƒ¼ãƒ³")

    # æ€§èƒ½ã‚µãƒãƒªãƒ¼
    performance = report.get('summary', {}).get('performance', {})
    if performance:
        overall_stats = performance.get('overall_statistics', {})
        r2_stats = overall_stats.get('r2_statistics', {})
        if r2_stats:
            print(f"\nğŸ“ˆ å…¨ä½“æ€§èƒ½:")
            print(f"   å¹³å‡RÂ²: {r2_stats.get('mean', 0):.3f} (Â±{r2_stats.get('std', 0):.3f})")
            print(f"   RÂ²ç¯„å›²: {r2_stats.get('min', 0):.3f} - {r2_stats.get('max', 0):.3f}")

    # LAGä¾å­˜åº¦ã‚µãƒãƒªãƒ¼
    lag_summary = report.get('summary', {}).get('lag_dependency', {})
    if lag_summary:
        print(f"\nâš ï¸ LAGä¾å­˜åº¦åˆ†æ:")
        print(f"   é«˜ä¾å­˜åº¦ãƒ¢ãƒ‡ãƒ«: {len(lag_summary.get('high_lag_models', []))}å€‹")
        print(f"   ä¸­ä¾å­˜åº¦ãƒ¢ãƒ‡ãƒ«: {len(lag_summary.get('medium_lag_models', []))}å€‹")
        print(f"   ä½ä¾å­˜åº¦ãƒ¢ãƒ‡ãƒ«: {len(lag_summary.get('low_lag_models', []))}å€‹")
        print(f"   å¹³å‡ä¾å­˜åº¦: {lag_summary.get('average_lag_dependency', 0):.1f}%")

    # æ™‚é–“è»¸æ¤œè¨¼ã‚µãƒãƒªãƒ¼
    time_validation = report.get('summary', {}).get('time_validation', {})
    if time_validation:
        overall_summary = time_validation.get('overall_summary', {})
        if overall_summary:
            print(f"\nğŸ• æ™‚é–“è»¸æ¤œè¨¼:")
            print(f"   æ­£ç¢ºãªæ™‚é–“è»¸: {overall_summary.get('average_correct_ratio', 0)*100:.1f}%")
            print(f"   æ¤œè¨¼æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«: {overall_summary.get('total_models_checked', 0)}å€‹")

    # æ¨å¥¨äº‹é …
    recommendations = report.get('recommendations', [])
    if recommendations:
        print(f"\nğŸ’¡ ä¸»è¦æ¨å¥¨äº‹é …:")
        for i, rec in enumerate(recommendations[:5], 1):  # ä¸Šä½5ã¤ã‚’è¡¨ç¤º
            print(f"   {i}. {rec}")

    print("\n" + "="*80)


# å…¬é–‹APIï¼ˆç°¡ç´ åŒ–ï¼‰
__all__ = [
    # åŸºæœ¬ãƒ—ãƒ­ãƒƒãƒˆ
    'plot_feature_importance',

    # é«˜åº¦ãªå¯è¦–åŒ–
    'plot_corrected_time_series_by_horizon',
    'plot_ultra_detailed_minute_analysis',

    # çµ±åˆåˆ†æ
    'create_detailed_analysis_for_zone',
    'create_comprehensive_analysis_report',
    'print_analysis_summary',

    # è¨ºæ–­æ©Ÿèƒ½
    'analyze_lag_dependency',
    'detect_lag_following_pattern',
    'validate_prediction_timing',
    'create_correct_prediction_timestamps',
    'analyze_feature_patterns',
    'calculate_comprehensive_metrics'
]
