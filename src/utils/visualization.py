#!/usr/bin/env python
# coding: utf-8

"""
å¯è¦–åŒ–ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
æ¸©åº¦äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®çµæœã‚’å¯è¦–åŒ–ã™ã‚‹ãŸã‚ã®é–¢æ•°ã‚’æä¾›
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.dates as mdates
import matplotlib.font_manager as fm
import math
import os
from src.config import OUTPUT_DIR
from sklearn.metrics import r2_score
import warnings


# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã®å¼·åŒ–
def setup_japanese_font():
    """
    æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®šã‚’è¡Œã†ï¼ˆå¼·åŒ–ç‰ˆï¼‰
    """
    # åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’æ¤œç´¢ï¼ˆå„ªå…ˆé †ä½ä»˜ãï¼‰
    japanese_fonts = [
        'Hiragino Sans',
        'Hiragino Kaku Gothic Pro',
        'Yu Gothic',
        'Meiryo',
        'IPAexGothic',
        'IPAGothic',
        'MS Gothic',
        'Takao Gothic',
        'VL Gothic',
        'Noto Sans CJK JP'
    ]

    # ã‚·ã‚¹ãƒ†ãƒ ã§åˆ©ç”¨å¯èƒ½ãªãƒ•ã‚©ãƒ³ãƒˆä¸€è¦§ã‚’å–å¾—
    available_fonts = [f.name for f in fm.fontManager.ttflist]

    # åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’è¦‹ã¤ã‘ã‚‹
    selected_font = None
    for font in japanese_fonts:
        if font in available_fonts:
            selected_font = font
            break

    # ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’å¼·åˆ¶çš„ã«é©ç”¨
    if selected_font:
        plt.rcParams['font.family'] = [selected_font]
        plt.rcParams['font.sans-serif'] = [selected_font] + japanese_fonts
        print(f"æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š: {selected_font}")
    else:
        # macOSã®å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        import platform
        if platform.system() == 'Darwin':  # macOS
            plt.rcParams['font.family'] = ['Hiragino Sans']
            plt.rcParams['font.sans-serif'] = ['Hiragino Sans', 'Arial Unicode MS']
            print("macOSç”¨ãƒ•ã‚©ãƒ³ãƒˆè¨­å®š: Hiragino Sans")
        else:
            # ãã®ä»–ã®ã‚·ã‚¹ãƒ†ãƒ ç”¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            plt.rcParams['font.family'] = ['DejaVu Sans']
            plt.rcParams['font.sans-serif'] = japanese_fonts + ['DejaVu Sans', 'Arial']
            print("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®šã‚’ä½¿ç”¨")

    # é‡è¦ãªè¨­å®šã‚’å¼·åˆ¶é©ç”¨
    plt.rcParams['axes.unicode_minus'] = False
    plt.rcParams['figure.autolayout'] = True

    # è¨­å®šç¢ºèªã®ãŸã‚ã®ãƒ†ã‚¹ãƒˆ
    try:
        fig, ax = plt.subplots(figsize=(1, 1))
        ax.text(0.5, 0.5, 'ãƒ†ã‚¹ãƒˆ', fontsize=12)
        plt.close(fig)
        print("âœ… æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šãƒ†ã‚¹ãƒˆæˆåŠŸ")
    except Exception as e:
        print(f"âš ï¸ ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šãƒ†ã‚¹ãƒˆã§è­¦å‘Š: {e}")

# ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã‚’å®Ÿè¡Œ
setup_japanese_font()

# ã‚°ãƒ©ãƒ•è¨­å®š
sns.set_theme(style="whitegrid", palette="colorblind")

# è¿½åŠ ã®matplotlibè¨­å®š
plt.rcParams.update({
    'font.size': 10,
    'axes.titlesize': 12,
    'axes.labelsize': 11,
    'xtick.labelsize': 9,
    'ytick.labelsize': 9,
    'legend.fontsize': 10,
    'figure.titlesize': 14
})


def plot_feature_importance(feature_importance, zone, horizon, save_dir=None, top_n=15, save=True):
    """
    Plot feature importance

    Parameters:
    -----------
    feature_importance : DataFrame
        DataFrame containing features and their importance values
    zone : int
        Zone number
    horizon : int
        Prediction horizon (minutes)
    save_dir : str, optional
        Directory to save the graph
    top_n : int, optional
        Number of features to display
    save : bool, optional
        Whether to save the graph

    Returns:
    --------
    matplotlib.figure.Figure
        Figure object of the plot
    """
    # Sort by importance in descending order
    importance_sorted = feature_importance.sort_values('importance', ascending=False)

    # Extract top N features
    top_features = importance_sorted.head(top_n)

    # Create plot
    fig, ax = plt.subplots(figsize=(12, 8))
    sns.barplot(x='importance', y='feature', data=top_features, ax=ax)

    ax.set_title(f'Zone {zone} - Feature Importance for {horizon}-min Prediction (Top {top_n})', fontsize=14)
    ax.set_xlabel('Importance', fontsize=12)
    ax.set_ylabel('Feature', fontsize=12)

    # Save graph
    if save and save_dir:
        output_path = os.path.join(save_dir, f'feature_importance_zone_{zone}_horizon_{horizon}.png')
        plt.savefig(output_path, dpi=150)
        print(f"Feature importance graph saved: {output_path}")

    return fig


def plot_scatter_actual_vs_predicted(actual, predicted, zone, horizon, save_dir=None, save=True):
    """
    Generate scatter plot of actual vs predicted values

    Parameters:
    -----------
    actual : Series
        Actual values
    predicted : array-like
        Predicted values
    zone : int
        Zone number
    horizon : int
        Prediction horizon (minutes)
    save_dir : str, optional
        Directory to save the graph
    save : bool, optional
        Whether to save the graph

    Returns:
    --------
    matplotlib.figure.Figure
        Figure object of the plot
    """
    # Create scatter plot
    fig, ax = plt.subplots(figsize=(10, 6))

    # Filter out NaN values
    valid_indices = ~(pd.isna(actual) | pd.isna(predicted))
    actual_valid = actual[valid_indices]
    predicted_valid = predicted[valid_indices]

    # Scatter plot
    ax.scatter(actual_valid, predicted_valid, alpha=0.5)

    # Add ideal prediction line (y=x)
    min_val = min(actual_valid.min(), predicted_valid.min())
    max_val = max(actual_valid.max(), predicted_valid.max())
    ax.plot([min_val, max_val], [min_val, max_val], 'r--')

    # Axis labels and title
    ax.set_xlabel('Actual', fontsize=12)
    ax.set_ylabel('Predicted', fontsize=12)
    ax.set_title(f'Zone {zone} - Temperature Prediction for {horizon}-min Horizon (Scatter Plot)', fontsize=14)

    # Calculate and display RÂ²
    r2 = r2_score(actual_valid, predicted_valid)
    ax.text(0.05, 0.95, f'RÂ² = {r2:.4f}', transform=ax.transAxes,
            verticalalignment='top', fontsize=12)

    # Grid lines
    ax.grid(True, linestyle='--', alpha=0.6)

    # Save graph
    if save and save_dir:
        output_path = os.path.join(save_dir, f'scatter_zone_{zone}_horizon_{horizon}.png')
        plt.savefig(output_path, dpi=150)
        print(f"Scatter plot saved: {output_path}")

    return fig


def plot_scatter_actual_vs_predicted_by_horizon(results_dict, horizon, save_dir=None, save=True):
    """
    Generate subplots of scatter plots for all zones at a specific horizon

    Parameters:
    -----------
    results_dict : dict
        Dictionary containing results for each zone
    horizon : int
        Prediction horizon (minutes)
    save_dir : str, optional
        Directory to save the graph
    save : bool, optional
        Whether to save the graph

    Returns:
    --------
    matplotlib.figure.Figure
        Figure object of the plot
    """
    # Collect zones with data for the prediction horizon
    zones_with_data = []
    for zone, zone_results in results_dict.items():
        if horizon in zone_results:
            zones_with_data.append(zone)

    if not zones_with_data:
        print(f"Warning: No data available for {horizon}-min prediction. Skipping.")
        return None

    # Calculate number of rows and columns for subplots
    n_zones = len(zones_with_data)
    n_cols = min(3, n_zones)  # Limit to maximum 3 columns
    n_rows = math.ceil(n_zones / n_cols)

    # Create subplots
    fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 4, n_rows * 4), squeeze=False)
    axs = axs.flatten()

    for i, zone in enumerate(sorted(zones_with_data)):
        zone_results = results_dict.get(zone, {})
        horizon_results = zone_results.get(horizon, {})

        # Helper function to get data from results
        def get_data_from_results(results, key_pairs):
            """Helper function to retrieve data from results dictionary based on key pairs"""
            for actual_key, pred_key in key_pairs:
                if actual_key in results and pred_key in results:
                    return results[actual_key], results[pred_key]
            return None, None

        # Try different key combinations
        key_pairs = [
            ('test_y', 'test_predictions'),
            ('y_test', 'y_pred'),
            ('actual', 'predicted'),
            ('train_y', 'train_predictions'),
            ('y_train', 'y_train_pred')
        ]

        actual, predicted = get_data_from_results(horizon_results, key_pairs)

        if actual is None or predicted is None:
            print(f"Zone {zone}, Horizon {horizon}: Data not found. Available keys: {list(horizon_results.keys())}")
            axs[i].text(0.5, 0.5, 'No data',
                      ha='center', va='center', transform=axs[i].transAxes)
            continue

        # Filter out NaN values and infinities
        try:
            valid_indices = ~(pd.isna(actual) | pd.isna(predicted) |
                             np.isinf(actual) | np.isinf(predicted))

            if isinstance(actual, pd.Series):
                actual_valid = actual[valid_indices]
            else:
                actual_valid = np.array(actual)[valid_indices]

            if isinstance(predicted, pd.Series):
                predicted_valid = predicted[valid_indices]
            else:
                predicted_valid = np.array(predicted)[valid_indices]
        except Exception as e:
            print(f"Error processing data for Zone {zone}: {e}")
            axs[i].text(0.5, 0.5, f'Data processing error: {str(e)[:30]}...',
                      ha='center', va='center', transform=axs[i].transAxes)
            continue

        if len(actual_valid) == 0:
            axs[i].text(0.5, 0.5, 'No valid data',
                      ha='center', va='center', transform=axs[i].transAxes)
            continue

        # Scatter plot
        axs[i].scatter(actual_valid, predicted_valid, alpha=0.5)

        # Add ideal prediction line (y=x)
        try:
            min_val = min(np.min(actual_valid), np.min(predicted_valid))
            max_val = max(np.max(actual_valid), np.max(predicted_valid))
            axs[i].plot([min_val, max_val], [min_val, max_val], 'r--')

            # Calculate and display RÂ²
            r2 = r2_score(actual_valid, predicted_valid)
            axs[i].text(0.05, 0.95, f'RÂ² = {r2:.4f}', transform=axs[i].transAxes,
                      verticalalignment='top', fontsize=12)
        except Exception as e:
            print(f"Error calculating RÂ² for zone {zone}: {e}")
            axs[i].text(0.05, 0.95, "RÂ² calculation error", transform=axs[i].transAxes,
                      verticalalignment='top', fontsize=12)

        # Title and grid
        axs[i].set_title(f'Zone {zone}')
        axs[i].set_xlabel('Actual')
        axs[i].set_ylabel('Predicted')
        axs[i].grid(True, linestyle='--', alpha=0.6)

    # Hide unused subplots
    for j in range(n_zones, len(axs)):
        fig.delaxes(axs[j])

    # Overall title
    fig.suptitle(f'Actual vs Predicted for {horizon}-min Horizon', fontsize=16)
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])

    # Save graph
    if save and save_dir:
        output_path = os.path.join(save_dir, f'scatter_all_zones_horizon_{horizon}.png')
        plt.savefig(output_path, dpi=150)
        print(f"Scatter plot for all zones saved: {output_path}")

    return fig


def plot_time_series(timestamps, actual, predicted, zone, horizon, save_dir=None, points=100, save=True):
    """
    Create time series plot of temperature data and predictions

    Parameters:
    -----------
    timestamps : array-like
        Timestamps for the time series
    actual : Series
        Actual values
    predicted : array-like
        Predicted values
    zone : int
        Zone number
    horizon : int
        Prediction horizon (minutes)
    save_dir : str, optional
        Directory to save the graph
    points : int, optional
        Maximum number of data points to plot
    save : bool, optional
        Whether to save the graph

    Returns:
    --------
    matplotlib.figure.Figure
        Figure object of the plot
    """
    # Filter out NaN values
    valid_indices = ~(pd.isna(actual) | pd.isna(predicted))
    timestamps_valid = timestamps[valid_indices]
    actual_valid = actual[valid_indices]
    predicted_valid = predicted[valid_indices]

    # Sample data if there are too many points
    sample_size = min(len(timestamps_valid), points)
    if len(timestamps_valid) > sample_size:
        # Sample from endpoints
        step = len(timestamps_valid) // sample_size
        indices = list(range(0, len(timestamps_valid), step))[:sample_size]

        # Sample data
        if isinstance(timestamps_valid, pd.DatetimeIndex):
            timestamps_sample = timestamps_valid[indices]
        else:
            timestamps_sample = timestamps_valid.iloc[indices] if hasattr(timestamps_valid, 'iloc') else timestamps_valid[indices]

        actual_sample = actual_valid.iloc[indices] if hasattr(actual_valid, 'iloc') else actual_valid[indices]
        predicted_sample = predicted_valid[indices] if hasattr(predicted_valid, 'iloc') else predicted_valid[indices]
    else:
        timestamps_sample = timestamps_valid
        actual_sample = actual_valid
        predicted_sample = predicted_valid

    # Create time series plot
    fig, ax = plt.subplots(figsize=(12, 6))

    # Plot actual and predicted values
    ax.plot(timestamps_sample, actual_sample, 'b-', label='Actual')
    ax.plot(timestamps_sample, predicted_sample, 'r--', label='Predicted')

    # Format x-axis
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d\n%H:%M'))
    plt.xticks(rotation=45)

    # Axis labels and title
    ax.set_xlabel('Date/Time', fontsize=12)
    ax.set_ylabel('Temperature (Â°C)', fontsize=12)
    ax.set_title(f'Zone {zone} - Temperature Prediction for {horizon}-min Horizon (Time Series)', fontsize=14)

    # Grid and legend
    ax.grid(True, linestyle='--', alpha=0.6)
    ax.legend()

    # Adjust layout
    plt.tight_layout()

    # Save graph
    if save and save_dir:
        output_path = os.path.join(save_dir, f'timeseries_zone_{zone}_horizon_{horizon}.png')
        plt.savefig(output_path, dpi=150)
        print(f"Time series plot saved: {output_path}")

    return fig


def plot_time_series_by_horizon(results_dict, horizon, save_dir=None, points=100, save=True):
    """
    Generate subplots of time series data for all zones at a specific horizon

    Parameters:
    -----------
    results_dict : dict
        Dictionary containing results for each zone
    horizon : int
        Prediction horizon (minutes)
    save_dir : str, optional
        Directory to save the graph
    points : int, optional
        Maximum number of data points to plot
    save : bool, optional
        Whether to save the graph

    Returns:
    --------
    matplotlib.figure.Figure
        Figure object of the plot
    """
    # Collect zones with data for the prediction horizon
    zones_with_data = []
    for zone, zone_results in results_dict.items():
        if horizon in zone_results:
            zones_with_data.append(zone)

    if not zones_with_data:
        print(f"Warning: No data available for {horizon}-min prediction. Skipping.")
        return None

    # Calculate number of rows and columns for subplots
    n_zones = len(zones_with_data)
    n_cols = min(3, n_zones)  # Limit to maximum 3 columns
    n_rows = math.ceil(n_zones / n_cols)

    # Create subplots
    fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 5, n_rows * 3), squeeze=False)
    axs = axs.flatten()

    for i, zone in enumerate(sorted(zones_with_data)):
        zone_results = results_dict.get(zone, {})
        horizon_results = zone_results.get(horizon, {})

        # Try different methods to get time series data
        timestamps = None
        actual = None
        predicted = None

        # Method 1: Use test_data, test_y, test_predictions
        if all(k in horizon_results for k in ['test_data', 'test_y', 'test_predictions']):
            test_df = horizon_results['test_data']
            if isinstance(test_df, pd.DataFrame) and hasattr(test_df, 'index'):
                timestamps = test_df.index
                actual = horizon_results['test_y']
                predicted = horizon_results['test_predictions']
                print(f"Zone {zone}: ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ - timestamps: {len(timestamps)}, actual: {len(actual)}, predicted: {len(predicted)}")

        # Method 2: Use y_test, y_pred and find DataFrame with time series index
        elif all(k in horizon_results for k in ['y_test', 'y_pred']):
            actual = horizon_results['y_test']
            predicted = horizon_results['y_pred']

            # Look for DataFrame with datetime index
            for key, value in horizon_results.items():
                if isinstance(value, pd.DataFrame) and hasattr(value, 'index') and isinstance(value.index, pd.DatetimeIndex):
                    timestamps = value.index
                    break

        # Method 3: Look for timestamp keys
        if timestamps is None:
            for key in ['test_timestamps', 'timestamps', 'time_index', 'date_index']:
                if key in horizon_results:
                    timestamps = horizon_results[key]
                    break

        # Generate dummy timestamps if none found
        if timestamps is None:
            if actual is not None:
                length = len(actual)
                timestamps = pd.date_range(start='2023-01-01', periods=length, freq='1min')
                print(f"No time index found for Zone {zone}, generating dummy index")
            else:
                # No data found
                print(f"No data found for Zone {zone}, Horizon {horizon}")
                axs[i].text(0.5, 0.5, 'No data',
                           ha='center', va='center', transform=axs[i].transAxes)
                continue

        # Check for missing actual/predicted data
        if actual is None or predicted is None:
            # Try different key patterns
            key_pairs = [
                ('test_y', 'test_predictions'),
                ('y_test', 'y_pred'),
                ('actual', 'predicted'),
                ('train_y', 'train_predictions')
            ]

            for actual_key, pred_key in key_pairs:
                if actual_key in horizon_results and pred_key in horizon_results:
                    actual = horizon_results[actual_key]
                    predicted = horizon_results[pred_key]
                    break

        if actual is None or predicted is None:
            print(f"Data keys not found for Zone {zone}, Horizon {horizon}. Available keys: {list(horizon_results.keys())}")
            axs[i].text(0.5, 0.5, 'No data',
                       ha='center', va='center', transform=axs[i].transAxes)
            continue

        # Check and fix length mismatches
        try:
            min_length = min(len(timestamps), len(actual), len(predicted))
            if len(timestamps) > min_length:
                timestamps = timestamps[:min_length]
            if len(actual) > min_length:
                actual = actual[:min_length]
            if len(predicted) > min_length:
                predicted = predicted[:min_length]
        except Exception as e:
            print(f"Error adjusting data lengths for Zone {zone}: {e}")

        # Filter out NaN values and invalid values
        try:
            valid_indices = ~(pd.isna(actual) | pd.isna(predicted) |
                              np.isinf(actual) | np.isinf(predicted))

            timestamps_valid = timestamps[valid_indices]

            if isinstance(actual, pd.Series):
                actual_valid = actual[valid_indices]
            else:
                actual_valid = np.array(actual)[valid_indices]

            if isinstance(predicted, pd.Series):
                predicted_valid = predicted[valid_indices]
            else:
                predicted_valid = np.array(predicted)[valid_indices]
        except Exception as e:
            print(f"Error processing data for Zone {zone}: {e}")
            axs[i].text(0.5, 0.5, f'Data processing error: {str(e)[:30]}...',
                       ha='center', va='center', transform=axs[i].transAxes)
            continue

        if len(actual_valid) == 0 or len(timestamps_valid) == 0:
            axs[i].text(0.5, 0.5, 'No valid data',
                       ha='center', va='center', transform=axs[i].transAxes)
            continue

        # Sample data if there are too many points
        sample_size = min(len(timestamps_valid), points)
        if len(timestamps_valid) > sample_size:
            try:
                # Sample indices including endpoints
                indices = np.linspace(0, len(timestamps_valid) - 1, sample_size, dtype=int)

                # Sample data
                timestamps_sample = timestamps_valid[indices]
                actual_sample = actual_valid[indices]
                predicted_sample = predicted_valid[indices]
            except Exception as e:
                print(f"Error sampling data for Zone {zone}: {e}")
                # Use all data if error occurs
                timestamps_sample = timestamps_valid
                actual_sample = actual_valid
                predicted_sample = predicted_valid
        else:
            timestamps_sample = timestamps_valid
            actual_sample = actual_valid
            predicted_sample = predicted_valid

        # Plot actual and predicted values
        try:
            axs[i].plot(timestamps_sample, actual_sample, 'b-', label='Actual')
            axs[i].plot(timestamps_sample, predicted_sample, 'r--', label='Predicted')

            # Format x-axis
            if isinstance(timestamps_sample, pd.DatetimeIndex) or isinstance(timestamps_sample[0], (pd.Timestamp, np.datetime64)):
                axs[i].xaxis.set_major_formatter(mdates.DateFormatter('%m/%d\n%H:%M'))
                axs[i].tick_params(axis='x', rotation=45)
        except Exception as e:
            print(f"Error plotting data for Zone {zone}: {e}")
            axs[i].text(0.5, 0.5, f'Plot error: {str(e)[:30]}...',
                       ha='center', va='center', transform=axs[i].transAxes)
            continue

        # Title and grid
        axs[i].set_title(f'Zone {zone}')
        axs[i].set_ylabel('Temperature (Â°C)')
        axs[i].grid(True, linestyle='--', alpha=0.6)
        axs[i].legend(loc='upper right')

    # Hide unused subplots
    for j in range(n_zones, len(axs)):
        fig.delaxes(axs[j])

    # Overall title
    fig.suptitle(f'Time Series Data for {horizon}-min Horizon', fontsize=16)
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])

    # Save graph
    if save and save_dir:
        output_path = os.path.join(save_dir, f'timeseries_all_zones_horizon_{horizon}.png')
        plt.savefig(output_path, dpi=150)
        print(f"Time series plot for all zones saved: {output_path}")

    return fig


def plot_lag_dependency_analysis(lag_dependency, zone=None, horizon=None, save_dir=None):
    """
    Visualize LAG dependency analysis results
    Note: Graph output is disabled

    Parameters:
    -----------
    lag_dependency : dict
        Dictionary containing LAG dependency analysis results
    zone : int, optional
        Zone number
    horizon : int, optional
        Prediction horizon (minutes)
    save_dir : str, optional
        Directory path to save graphs

    Returns:
    --------
    list
        List of Figure objects (empty list as output is disabled)
    """
    # Graph saving is disabled
    save = False

    # Return empty dummy list (no output)
    print("LAG dependency visualization output is disabled")
    return []


def plot_physical_validity_analysis(results_dict, horizon, save=True):
    """
    Visualize physical validity analysis results

    Parameters:
    -----------
    results_dict : dict
        Dictionary containing results for each zone
    horizon : int
        Prediction horizon (minutes)
    save : bool, optional
        Whether to save the graph

    Returns:
    --------
    matplotlib.figure.Figure
        Figure object of the plot
    """
    # Collect zones with data for the prediction horizon
    zones_with_data = []
    for zone, zone_results in results_dict.items():
        if horizon in zone_results:
            zones_with_data.append(zone)

    if not zones_with_data:
        print(f"Warning: No data available for {horizon}-min prediction. Skipping.")
        return None

    # Calculate number of rows and columns for subplots
    n_zones = len(zones_with_data)
    n_cols = min(3, n_zones)
    n_rows = math.ceil(n_zones / n_cols)

    # Visualize physical validity analysis results
    fig, axs = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 5), squeeze=False)
    axs = axs.flatten()

    for i, zone in enumerate(zones_with_data):
        results = results_dict[zone][horizon]
        y_test = results['y_test']
        y_pred = results['y_pred']
        ac_state = results['ac_state']
        ac_mode = results['ac_mode']
        zone_system = results['system']

        # Calculate temperature changes
        temp_change_true = y_test.diff()
        temp_change_pred = y_pred.diff()

        # Create masks for cooling, heating, and AC off states
        cooling_mask = (ac_state == 1) & (ac_mode == 0)
        heating_mask = (ac_state == 1) & (ac_mode == 1)
        off_mask = (ac_state == 0)

        # Create scatter plot
        axs[i].scatter(temp_change_true[cooling_mask], temp_change_pred[cooling_mask],
                      alpha=0.5, label='Cooling', color='blue')
        axs[i].scatter(temp_change_true[heating_mask], temp_change_pred[heating_mask],
                      alpha=0.5, label='Heating', color='red')
        axs[i].scatter(temp_change_true[off_mask], temp_change_pred[off_mask],
                      alpha=0.5, label='AC Off', color='gray')

        # Ideal prediction line (y=x)
        min_change = min(temp_change_true.min(), temp_change_pred.min())
        max_change = max(temp_change_true.max(), temp_change_pred.max())
        axs[i].plot([min_change, max_change], [min_change, max_change], 'k--', label='Ideal Prediction')

        # Expected change regions for cooling and heating
        axs[i].axhspan(min_change, 0, alpha=0.1, color='blue', label='Expected Cooling Region')
        axs[i].axhspan(0, max_change, alpha=0.1, color='red', label='Expected Heating Region')

        axs[i].set_title(f'Zone {zone} - {zone_system} System')
        axs[i].set_xlabel('Actual Temperature Change')
        axs[i].set_ylabel('Predicted Temperature Change')
        axs[i].grid(True)
        axs[i].legend()

    # Hide unused subplots
    for j in range(i+1, len(axs)):
        fig.delaxes(axs[j])

    fig.suptitle(f'Physical Validity Analysis for {horizon}-min Horizon', fontsize=16)
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])

    if save:
        output_path = os.path.join(OUTPUT_DIR, f'physical_validity_horizon_{horizon}.png')
        plt.savefig(output_path, dpi=150)
        print(f"Physical validity analysis graph saved for {horizon}-min horizon: {output_path}")

    return fig


def plot_response_delay_analysis(results_dict, horizon, save=True):
    """
    Analyze response delay in predictions

    Parameters:
    -----------
    results_dict : dict
        Dictionary containing results for each zone
    horizon : int
        Prediction horizon (minutes)
    save : bool, optional
        Whether to save the graph

    Returns:
    --------
    matplotlib.figure.Figure
        Figure object of the plot
    """
    # Collect zones with data for the prediction horizon
    zones_with_data = []
    for zone, zone_results in results_dict.items():
        if horizon in zone_results:
            zones_with_data.append(zone)

    if not zones_with_data:
        print(f"Warning: No data available for {horizon}-min prediction. Skipping.")
        return None

    # Calculate number of rows and columns for subplots
    n_zones = len(zones_with_data)
    n_cols = min(3, n_zones)
    n_rows = math.ceil(n_zones / n_cols)

    # Visualize response delay analysis results
    fig, axs = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 5), squeeze=False)
    axs = axs.flatten()

    for i, zone in enumerate(zones_with_data):
        results = results_dict[zone][horizon]
        y_test = results['y_test']
        y_pred = results['y_pred']
        ac_state = results['ac_state']
        zone_system = results['system']

        # Detect AC state changes
        ac_state_change = ac_state.diff().abs()
        change_indices = ac_state_change[ac_state_change == 1].index

        # Plot temperature changes after state changes
        for idx in change_indices[:5]:  # Only show first 5 state changes
            # Get data before and after state change
            start_idx = idx - pd.Timedelta(minutes=5)
            end_idx = idx + pd.Timedelta(minutes=horizon)
            mask = (y_test.index >= start_idx) & (y_test.index <= end_idx)

            # Convert to relative time (minutes)
            relative_time = (y_test.index[mask] - idx).total_seconds() / 60

            # Plot actual and predicted values
            axs[i].plot(relative_time, y_test[mask], 'b-', label='Actual' if idx == change_indices[0] else "")
            axs[i].plot(relative_time, y_pred[mask], 'r--', label='Predicted' if idx == change_indices[0] else "")

        axs[i].axvline(x=0, color='k', linestyle='--', label='State Change Point')
        axs[i].set_title(f'Zone {zone} - {zone_system} System')
        axs[i].set_xlabel('Time Since State Change (minutes)')
        axs[i].set_ylabel('Temperature (Â°C)')
        axs[i].grid(True)
        axs[i].legend()

    # Hide unused subplots
    for j in range(i+1, len(axs)):
        fig.delaxes(axs[j])

    fig.suptitle(f'Response Delay Analysis for {horizon}-min Horizon', fontsize=16)
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])

    if save:
        output_path = os.path.join(OUTPUT_DIR, f'response_delay_horizon_{horizon}.png')
        plt.savefig(output_path, dpi=150)
        print(f"Response delay analysis graph saved for {horizon}-min horizon: {output_path}")

    return fig


def plot_enhanced_detailed_time_series(timestamps, actual, predicted, zone, horizon,
                                      save_dir=None, time_scale='day', data_period_days=7,
                                      show_lag_analysis=True, lag_dependency=None, save=True):
    """
    æ”¹å–„ã•ã‚ŒãŸè©³ç´°æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆï¼ˆæ–‡å­—åŒ–ã‘ä¿®æ­£ãƒ»ç›´æ„Ÿçš„ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆï¼‰

    Parameters:
    -----------
    timestamps : array-like
        æ™‚ç³»åˆ—ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    actual : Series
        å®Ÿæ¸¬å€¤
    predicted : array-like
        äºˆæ¸¬å€¤
    zone : int
        ã‚¾ãƒ¼ãƒ³ç•ªå·
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰
    save_dir : str, optional
        ã‚°ãƒ©ãƒ•ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    time_scale : str, optional
        æ™‚é–“è»¸ã®ã‚¹ã‚±ãƒ¼ãƒ« ('hour', 'day', 'week')
    data_period_days : int, optional
        è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿æœŸé–“ï¼ˆæ—¥æ•°ï¼‰
    show_lag_analysis : bool, optional
        LAGä¾å­˜åº¦åˆ†æã‚’è¡¨ç¤ºã™ã‚‹ã‹
    lag_dependency : dict, optional
        LAGä¾å­˜åº¦æƒ…å ±
    save : bool, optional
        ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã™ã‚‹ã‹

    Returns:
    --------
    matplotlib.figure.Figure
        ãƒ—ãƒ­ãƒƒãƒˆã®Figureã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    # ãƒ•ã‚©ãƒ³ãƒˆãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’å®šç¾©
    font_prop = fm.FontProperties()
    try:
        # åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’å–å¾—
        japanese_fonts = ['Hiragino Sans', 'Hiragino Kaku Gothic Pro', 'Yu Gothic', 'Meiryo']
        available_fonts = [f.name for f in fm.fontManager.ttflist]
        selected_font = None
        for font in japanese_fonts:
            if font in available_fonts:
                selected_font = font
                break

        if selected_font:
            font_prop.set_family(selected_font)
        else:
            # macOSã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            font_prop.set_family('Hiragino Sans')
    except:
        pass

    # NaNå€¤ã‚’ãƒ•ã‚£ãƒ«ã‚¿
    valid_indices = ~(pd.isna(actual) | pd.isna(predicted))
    timestamps_valid = timestamps[valid_indices]
    actual_valid = actual[valid_indices]
    predicted_valid = predicted[valid_indices]

    if len(timestamps_valid) == 0:
        print(f"ã‚¾ãƒ¼ãƒ³ {zone}: æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return None

    # ãƒ‡ãƒ¼ã‚¿æœŸé–“ã®åˆ¶é™
    if len(timestamps_valid) > 0:
        end_time = timestamps_valid[-1]
        start_time = end_time - pd.Timedelta(days=data_period_days)

        period_mask = (timestamps_valid >= start_time) & (timestamps_valid <= end_time)
        timestamps_period = timestamps_valid[period_mask]
        actual_period = actual_valid[period_mask]
        predicted_period = predicted_valid[period_mask]

        if len(timestamps_period) == 0:
            timestamps_period = timestamps_valid
            actual_period = actual_valid
            predicted_period = predicted_valid
    else:
        timestamps_period = timestamps_valid
        actual_period = actual_valid
        predicted_period = predicted_valid

    # èª¤å·®ã®è¨ˆç®—
    error_period = actual_period - predicted_period
    abs_error_period = np.abs(error_period)

    # ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨­å®šï¼ˆäºˆæ¸¬èª¤å·®ãƒ—ãƒ­ãƒƒãƒˆã‚’å‰Šé™¤ã—ã€æ¨ªè»¸ã‚’æ‹¡å¤§ï¼‰
    if show_lag_analysis and lag_dependency:
        fig = plt.figure(figsize=(24, 10))  # æ¨ªå¹…ã‚’å¤§å¹…ã«æ‹¡å¤§
        gs = fig.add_gridspec(3, 4, height_ratios=[5, 1.5, 1.5], width_ratios=[3, 1, 1, 1], hspace=0.4, wspace=0.3)

        # ãƒ¡ã‚¤ãƒ³æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆï¼ˆä¸Šæ®µå…¨ä½“ï¼‰
        ax_main = fig.add_subplot(gs[0, :])
        # LAGä¾å­˜åº¦åˆ†æï¼ˆ2æ®µç›®å·¦ï¼‰
        ax_lag = fig.add_subplot(gs[1, 0])
        # æ•£å¸ƒå›³ï¼ˆ2æ®µç›®ä¸­å¤®ï¼‰
        ax_scatter = fig.add_subplot(gs[1, 1])
        # çµ±è¨ˆæƒ…å ±ï¼ˆ2æ®µç›®å³ï¼‰
        ax_stats = fig.add_subplot(gs[1, 2:])
        # æ™‚é–“é…ã‚Œåˆ†æï¼ˆ3æ®µç›®å…¨ä½“ï¼‰
        ax_delay = fig.add_subplot(gs[2, :])
    else:
        fig, ax_main = plt.subplots(figsize=(20, 8))  # æ¨ªå¹…ã‚’æ‹¡å¤§

    # ãƒ¡ã‚¤ãƒ³æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆï¼ˆæ”¹å–„ç‰ˆï¼‰
    # å®Ÿæ¸¬å€¤ã‚’å¤ªã„é’ç·šã§
    ax_main.plot(timestamps_period, actual_period, 'b-', linewidth=2.5,
                label='å®Ÿæ¸¬å€¤', alpha=0.9, zorder=3)
    # äºˆæ¸¬å€¤ã‚’èµ¤ã„ç ´ç·šã§
    ax_main.plot(timestamps_period, predicted_period, 'r--', linewidth=2.0,
                label='äºˆæ¸¬å€¤', alpha=0.8, zorder=2)

    # èª¤å·®ã®å¸¯ã‚°ãƒ©ãƒ•ï¼ˆè–„ã„ã‚°ãƒ¬ãƒ¼ï¼‰
    ax_main.fill_between(timestamps_period, actual_period, predicted_period,
                        alpha=0.3, color='gray', label='äºˆæ¸¬èª¤å·®', zorder=1)

    # Xè»¸ã®æ™‚é–“ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¨­å®šï¼ˆæ¨ªè»¸æ‹¡å¤§ã«å¯¾å¿œã—ã¦ã‚ˆã‚Šç´°ã‹ãï¼‰
    if time_scale == 'minute':
        ax_main.xaxis.set_major_locator(mdates.MinuteLocator(interval=15))  # 15åˆ†é–“éš”
        ax_main.xaxis.set_minor_locator(mdates.MinuteLocator(interval=5))  # 5åˆ†é–“éš”
        ax_main.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d\n%H:%M'))
    elif time_scale == 'hour':
        ax_main.xaxis.set_major_locator(mdates.HourLocator(interval=1))  # 1æ™‚é–“é–“éš”
        ax_main.xaxis.set_minor_locator(mdates.MinuteLocator(interval=30))  # 30åˆ†é–“éš”
        ax_main.xaxis.set_major_formatter(mdates.DateFormatter('%m-%d\n%H:%M'))
    elif time_scale == 'day':
        ax_main.xaxis.set_major_locator(mdates.HourLocator(interval=3))  # 3æ™‚é–“é–“éš”
        ax_main.xaxis.set_minor_locator(mdates.HourLocator(interval=1))  # 1æ™‚é–“é–“éš”
        ax_main.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d\n%H:%M'))
    elif time_scale == 'week':
        ax_main.xaxis.set_major_locator(mdates.HourLocator(interval=12))  # 12æ™‚é–“é–“éš”
        ax_main.xaxis.set_minor_locator(mdates.HourLocator(interval=6))  # 6æ™‚é–“é–“éš”
        ax_main.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d\n%H:%M'))

    ax_main.tick_params(axis='x', rotation=45, labelsize=10)
    ax_main.set_xlabel('æ—¥æ™‚', fontproperties=font_prop, fontsize=12, fontweight='bold')
    ax_main.set_ylabel('æ¸©åº¦ (Â°C)', fontproperties=font_prop, fontsize=12, fontweight='bold')

    # ã‚¿ã‚¤ãƒˆãƒ«ã®æ”¹å–„
    title = f'ã‚¾ãƒ¼ãƒ³ {zone} - {horizon}åˆ†å¾Œäºˆæ¸¬ã®è©³ç´°åˆ†æ\n'
    title += f'æœŸé–“: {data_period_days}æ—¥é–“ | æ™‚é–“è»¸: {time_scale} | ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°: {len(timestamps_period)}'
    ax_main.set_title(title, fontproperties=font_prop, fontsize=14, fontweight='bold', pad=20)

    ax_main.grid(True, linestyle='--', alpha=0.7)
    legend = ax_main.legend(fontsize=11, loc='upper right', framealpha=0.9)
    # å‡¡ä¾‹ã®ãƒ•ã‚©ãƒ³ãƒˆã‚‚è¨­å®š
    for text in legend.get_texts():
        text.set_fontproperties(font_prop)

    # è©³ç´°åˆ†æãƒ—ãƒ­ãƒƒãƒˆï¼ˆLAGåˆ†æãŒæœ‰åŠ¹ãªå ´åˆï¼‰
    if show_lag_analysis and lag_dependency:

        # çµ±è¨ˆæƒ…å ±ã®è¨ˆç®—
        mae = np.mean(abs_error_period)
        rmse = np.sqrt(np.mean(error_period**2))

        # 1. LAGä¾å­˜åº¦åˆ†æï¼ˆæ”¹å–„ç‰ˆï¼‰
        lag_categories = ['ç›´æ¥LAG\nç‰¹å¾´é‡', 'ç§»å‹•å¹³å‡\nç‰¹å¾´é‡', 'ç·LAG\nä¾å­˜åº¦']
        lag_values = [
            lag_dependency.get('lag_temp_percent', 0),
            lag_dependency.get('rolling_temp_percent', 0),
            lag_dependency.get('lag_temp_percent', 0) + lag_dependency.get('rolling_temp_percent', 0)
        ]

        colors = ['red' if val > 30 else 'orange' if val > 15 else 'green' for val in lag_values]
        bars = ax_lag.bar(lag_categories, lag_values, color=colors, alpha=0.8, edgecolor='black')

        # å€¤ã‚’ãƒãƒ¼ã®ä¸Šã«è¡¨ç¤º
        for bar, val in zip(bars, lag_values):
            ax_lag.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                       f'{val:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')

        # ãƒ©ãƒ™ãƒ«ã«ãƒ•ã‚©ãƒ³ãƒˆã‚’é©ç”¨
        for label in ax_lag.get_xticklabels():
            label.set_fontproperties(font_prop)

        ax_lag.set_ylabel('ä¾å­˜åº¦ (%)', fontproperties=font_prop, fontsize=10)
        ax_lag.set_title('LAGä¾å­˜åº¦åˆ†æ', fontproperties=font_prop, fontsize=11, fontweight='bold')
        ax_lag.set_ylim(0, max(50, max(lag_values) * 1.3))
        ax_lag.axhline(y=30, color='red', linestyle='--', alpha=0.7, label='è­¦å‘Šé–¾å€¤')
        ax_lag.axhline(y=15, color='orange', linestyle='--', alpha=0.7, label='æ³¨æ„é–¾å€¤')
        legend_lag = ax_lag.legend(fontsize=8)
        for text in legend_lag.get_texts():
            text.set_fontproperties(font_prop)
        ax_lag.grid(True, alpha=0.3)

        # 2. æ•£å¸ƒå›³ï¼ˆå®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤ï¼‰
        ax_scatter.scatter(actual_period, predicted_period, alpha=0.6, s=20, c='blue', edgecolors='black', linewidth=0.5)

        # ç†æƒ³ç·šï¼ˆy=xï¼‰
        min_val = min(actual_period.min(), predicted_period.min())
        max_val = max(actual_period.max(), predicted_period.max())
        ax_scatter.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='ç†æƒ³ç·š')

        ax_scatter.set_xlabel('å®Ÿæ¸¬å€¤ (Â°C)', fontproperties=font_prop, fontsize=10)
        ax_scatter.set_ylabel('äºˆæ¸¬å€¤ (Â°C)', fontproperties=font_prop, fontsize=10)
        ax_scatter.set_title('å®Ÿæ¸¬å€¤ vs äºˆæ¸¬å€¤', fontproperties=font_prop, fontsize=11, fontweight='bold')
        ax_scatter.grid(True, alpha=0.3)
        legend_scatter = ax_scatter.legend(fontsize=9)
        for text in legend_scatter.get_texts():
            text.set_fontproperties(font_prop)

        # RÂ²ã‚’è¡¨ç¤º
        r2 = r2_score(actual_period, predicted_period)
        ax_scatter.text(0.05, 0.95, f'RÂ² = {r2:.4f}', transform=ax_scatter.transAxes,
                       bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
                       fontsize=10, fontweight='bold')

        # 3. çµ±è¨ˆæƒ…å ±è¡¨ç¤º
        ax_stats.axis('off')
        stats_text = f"""çµ±è¨ˆæƒ…å ±:

ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°: {len(timestamps_period):,}
å¹³å‡çµ¶å¯¾èª¤å·®: {mae:.3f}Â°C
äºŒä¹—å¹³å‡å¹³æ–¹æ ¹èª¤å·®: {rmse:.3f}Â°C
æ±ºå®šä¿‚æ•°: {r2:.4f}

å®Ÿæ¸¬å€¤:
  å¹³å‡: {np.mean(actual_period):.2f}Â°C
  æ¨™æº–åå·®: {np.std(actual_period):.2f}Â°C

äºˆæ¸¬å€¤:
  å¹³å‡: {np.mean(predicted_period):.2f}Â°C
  æ¨™æº–åå·®: {np.std(predicted_period):.2f}Â°C"""

        ax_stats.text(0.05, 0.95, stats_text, transform=ax_stats.transAxes,
                     fontproperties=font_prop, fontsize=9, verticalalignment='top',
                     bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgray", alpha=0.8))

        # 4. æ™‚é–“é…ã‚Œåˆ†æï¼ˆæ”¹å–„ç‰ˆï¼‰
        _plot_enhanced_lag_analysis(timestamps_period, actual_period, predicted_period, ax_delay, horizon, font_prop)

    plt.tight_layout()

    # ã‚°ãƒ©ãƒ•ã®ä¿å­˜
    if save and save_dir:
        filename = f'enhanced_detailed_timeseries_zone_{zone}_horizon_{horizon}_{time_scale}_{data_period_days}days.png'
        output_path = os.path.join(save_dir, filename)
        plt.savefig(output_path, dpi=200, bbox_inches='tight', facecolor='white')
        print(f"æ”¹å–„ç‰ˆè©³ç´°æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆä¿å­˜: {output_path}")

    return fig


def _plot_enhanced_lag_analysis(timestamps, actual, predicted, ax, horizon, font_prop):
    """
    æ”¹å–„ã•ã‚ŒãŸæ™‚é–“é…ã‚Œåˆ†æã®ãƒ—ãƒ­ãƒƒãƒˆ

    Parameters:
    -----------
    timestamps : array-like
        ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    actual : array-like
        å®Ÿæ¸¬å€¤
    predicted : array-like
        äºˆæ¸¬å€¤
    ax : matplotlib.axes.Axes
        ãƒ—ãƒ­ãƒƒãƒˆç”¨ã®Axes
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰
    font_prop : matplotlib.font_manager.FontProperties
        ãƒ•ã‚©ãƒ³ãƒˆãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
    """
    if len(actual) > 100:
        # ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–
        actual_norm = (actual - np.mean(actual)) / (np.std(actual) + 1e-8)
        predicted_norm = (predicted - np.mean(predicted)) / (np.std(predicted) + 1e-8)

        # ç›¸äº’ç›¸é–¢ã®è¨ˆç®—
        max_lag = min(50, len(actual) // 4)
        correlations = []
        lags = range(-max_lag, max_lag + 1)

        for lag in lags:
            try:
                if lag < 0:
                    corr = np.corrcoef(actual_norm[-lag:], predicted_norm[:lag])[0, 1]
                elif lag > 0:
                    corr = np.corrcoef(actual_norm[:-lag], predicted_norm[lag:])[0, 1]
                else:
                    corr = np.corrcoef(actual_norm, predicted_norm)[0, 1]

                if not np.isnan(corr):
                    correlations.append(corr)
                else:
                    correlations.append(0)
            except:
                correlations.append(0)

        # ç›¸äº’ç›¸é–¢ã®ãƒ—ãƒ­ãƒƒãƒˆï¼ˆæ”¹å–„ç‰ˆï¼‰
        ax.plot(lags, correlations, 'b-', linewidth=2.5, alpha=0.8)
        ax.fill_between(lags, 0, correlations, alpha=0.3, color='blue')

        # é‡è¦ãªç·šã‚’è¿½åŠ 
        ax.axvline(x=0, color='red', linestyle='-', linewidth=2, alpha=0.8, label='é…ã‚Œãªã—')
        ax.axhline(y=0, color='black', linestyle='-', alpha=0.5)

        # æœ€å¤§ç›¸é–¢ã‚’æŒã¤é…ã‚Œã‚’æ¤œå‡º
        max_corr_idx = np.argmax(correlations)
        optimal_lag = lags[max_corr_idx]
        max_correlation = correlations[max_corr_idx]

        ax.axvline(x=optimal_lag, color='green', linestyle='--', linewidth=2, alpha=0.8,
                  label=f'æœ€é©é…ã‚Œ: {optimal_lag}ã‚¹ãƒ†ãƒƒãƒ—')

        # ãƒ©ãƒ™ãƒ«ã¨ã‚¿ã‚¤ãƒˆãƒ«
        ax.set_xlabel('é…ã‚Œï¼ˆãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆï¼‰', fontproperties=font_prop, fontsize=11, fontweight='bold')
        ax.set_ylabel('ç›¸äº’ç›¸é–¢ä¿‚æ•°', fontproperties=font_prop, fontsize=11, fontweight='bold')
        ax.set_title(f'æ™‚é–“é…ã‚Œåˆ†æ (æœ€å¤§ç›¸é–¢: {max_correlation:.3f}, æœ€é©é…ã‚Œ: {optimal_lag}ã‚¹ãƒ†ãƒƒãƒ—)',
                    fontproperties=font_prop, fontsize=12, fontweight='bold')
        ax.grid(True, alpha=0.3)
        legend_delay = ax.legend(fontsize=10)
        for text in legend_delay.get_texts():
            text.set_fontproperties(font_prop)

        # è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ”¹å–„
        if optimal_lag > 0:
            warning_text = f"âš ï¸ äºˆæ¸¬ãŒ{optimal_lag}ã‚¹ãƒ†ãƒƒãƒ—({optimal_lag*5}åˆ†)é…ã‚Œã¦ã„ã¾ã™"
            ax.text(0.02, 0.98, warning_text, transform=ax.transAxes,
                   fontproperties=font_prop,
                   bbox=dict(boxstyle="round,pad=0.5", facecolor="yellow", alpha=0.9),
                   verticalalignment='top', fontsize=10, fontweight='bold')
        elif optimal_lag < 0:
            warning_text = f"ğŸ“ˆ äºˆæ¸¬ãŒ{abs(optimal_lag)}ã‚¹ãƒ†ãƒƒãƒ—({abs(optimal_lag)*5}åˆ†)å…ˆè¡Œã—ã¦ã„ã¾ã™"
            ax.text(0.02, 0.98, warning_text, transform=ax.transAxes,
                   fontproperties=font_prop,
                   bbox=dict(boxstyle="round,pad=0.5", facecolor="lightblue", alpha=0.9),
                   verticalalignment='top', fontsize=10, fontweight='bold')
        else:
            success_text = "âœ… æ™‚é–“é…ã‚Œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ"
            ax.text(0.02, 0.98, success_text, transform=ax.transAxes,
                   fontproperties=font_prop,
                   bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgreen", alpha=0.9),
                   verticalalignment='top', fontsize=10, fontweight='bold')
    else:
        ax.text(0.5, 0.5, 'ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚åˆ†æä¸å¯\n(æœ€ä½100ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆå¿…è¦)',
               ha='center', va='center', transform=ax.transAxes,
               fontproperties=font_prop, fontsize=12, fontweight='bold',
               bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgray", alpha=0.8))


def plot_enhanced_detailed_time_series_by_horizon(results_dict, horizon, save_dir=None,
                                                 time_scale='day', data_period_days=7,
                                                 show_lag_analysis=True, save=True):
    """
    æ”¹å–„ã•ã‚ŒãŸå…¨ã‚¾ãƒ¼ãƒ³ã®è©³ç´°æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆ

    Parameters:
    -----------
    results_dict : dict
        å„ã‚¾ãƒ¼ãƒ³ã®çµæœã‚’å«ã‚€è¾æ›¸
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰
    save_dir : str, optional
        ã‚°ãƒ©ãƒ•ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    time_scale : str, optional
        æ™‚é–“è»¸ã®ã‚¹ã‚±ãƒ¼ãƒ« ('hour', 'day', 'week')
    data_period_days : int, optional
        è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿æœŸé–“ï¼ˆæ—¥æ•°ï¼‰
    show_lag_analysis : bool, optional
        LAGä¾å­˜åº¦åˆ†æã‚’è¡¨ç¤ºã™ã‚‹ã‹
    save : bool, optional
        ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã™ã‚‹ã‹

    Returns:
    --------
    matplotlib.figure.Figure
        ãƒ—ãƒ­ãƒƒãƒˆã®Figureã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    # ãƒ•ã‚©ãƒ³ãƒˆãƒ—ãƒ­ãƒ‘ãƒ†ã‚£ã‚’å®šç¾©
    font_prop = fm.FontProperties()
    try:
        # åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’å–å¾—
        japanese_fonts = ['Hiragino Sans', 'Hiragino Kaku Gothic Pro', 'Yu Gothic', 'Meiryo']
        available_fonts = [f.name for f in fm.fontManager.ttflist]
        selected_font = None
        for font in japanese_fonts:
            if font in available_fonts:
                selected_font = font
                break

        if selected_font:
            font_prop.set_family(selected_font)
        else:
            # macOSã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            font_prop.set_family('Hiragino Sans')
    except:
        pass

    # ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨å¯èƒ½ãªã‚¾ãƒ¼ãƒ³ã‚’åé›†
    zones_with_data = []
    for zone, zone_results in results_dict.items():
        if horizon in zone_results:
            zones_with_data.append(zone)

    if not zones_with_data:
        print(f"è­¦å‘Š: {horizon}åˆ†äºˆæ¸¬ã®ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return None

    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨ˆç®—ï¼ˆæ”¹å–„ç‰ˆãƒ»æ¨ªè»¸æ‹¡å¤§ï¼‰
    n_zones = len(zones_with_data)
    if n_zones == 1:
        n_cols, n_rows = 1, 1
        fig_size = (24, 10)  # æ¨ªè»¸æ‹¡å¤§
    elif n_zones <= 2:
        n_cols, n_rows = 2, 1
        fig_size = (28, 10)  # æ¨ªè»¸æ‹¡å¤§
    elif n_zones <= 4:
        n_cols, n_rows = 2, 2
        fig_size = (28, 16)  # æ¨ªè»¸æ‹¡å¤§
    else:
        n_cols = 3
        n_rows = math.ceil(n_zones / n_cols)
        fig_size = (32, n_rows * 8)  # æ¨ªè»¸æ‹¡å¤§

    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
    fig, axs = plt.subplots(n_rows, n_cols, figsize=fig_size, squeeze=False)
    axs = axs.flatten()

    for i, zone in enumerate(sorted(zones_with_data)):
        zone_results = results_dict.get(zone, {})
        horizon_results = zone_results.get(horizon, {})

        # ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        timestamps = None
        actual = None
        predicted = None
        lag_dependency = horizon_results.get('lag_dependency', {})

        # ãƒ‡ãƒ¼ã‚¿å–å¾—ã®è©¦è¡Œ
        if all(k in horizon_results for k in ['test_data', 'test_y', 'test_predictions']):
            test_df = horizon_results['test_data']
            if isinstance(test_df, pd.DataFrame) and hasattr(test_df, 'index'):
                timestamps = test_df.index
                actual = horizon_results['test_y']
                predicted = horizon_results['test_predictions']
                print(f"Zone {zone}: ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ - timestamps: {len(timestamps)}, actual: {len(actual)}, predicted: {len(predicted)}")

        if timestamps is None or actual is None or predicted is None:
            print(f"ã‚¾ãƒ¼ãƒ³ {zone} ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            axs[i].text(0.5, 0.5, 'ãƒ‡ãƒ¼ã‚¿ãªã—', ha='center', va='center',
                       transform=axs[i].transAxes, fontproperties=font_prop,
                       fontsize=14, fontweight='bold')
            continue

        # æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        try:
            valid_indices = ~(pd.isna(actual) | pd.isna(predicted) |
                             np.isinf(actual) | np.isinf(predicted))

            timestamps_valid = timestamps[valid_indices]
            actual_valid = actual[valid_indices]
            predicted_valid = predicted[valid_indices]
        except Exception as e:
            print(f"ã‚¾ãƒ¼ãƒ³ {zone} ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            axs[i].text(0.5, 0.5, 'ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼', ha='center', va='center',
                       transform=axs[i].transAxes, fontproperties=font_prop,
                       fontsize=14, fontweight='bold')
            continue

        if len(actual_valid) == 0:
            axs[i].text(0.5, 0.5, 'æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ãªã—', ha='center', va='center',
                       transform=axs[i].transAxes, fontproperties=font_prop,
                       fontsize=14, fontweight='bold')
            continue

        # ãƒ‡ãƒ¼ã‚¿æœŸé–“ã®åˆ¶é™
        if len(timestamps_valid) > 0:
            end_time = timestamps_valid[-1]
            start_time = end_time - pd.Timedelta(days=data_period_days)

            period_mask = (timestamps_valid >= start_time) & (timestamps_valid <= end_time)
            timestamps_period = timestamps_valid[period_mask]
            actual_period = actual_valid[period_mask]
            predicted_period = predicted_valid[period_mask]

            if len(timestamps_period) == 0:
                timestamps_period = timestamps_valid
                actual_period = actual_valid
                predicted_period = predicted_valid

        # æ”¹å–„ã•ã‚ŒãŸæ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆ
        try:
            # å®Ÿæ¸¬å€¤ï¼ˆå¤ªã„é’ç·šï¼‰
            axs[i].plot(timestamps_period, actual_period, 'b-', linewidth=2.5,
                       label='å®Ÿæ¸¬å€¤', alpha=0.9, zorder=3)
            # äºˆæ¸¬å€¤ï¼ˆèµ¤ã„ç ´ç·šï¼‰
            axs[i].plot(timestamps_period, predicted_period, 'r--', linewidth=2.0,
                       label='äºˆæ¸¬å€¤', alpha=0.8, zorder=2)

            # èª¤å·®ã®å¸¯ã‚°ãƒ©ãƒ•
            axs[i].fill_between(timestamps_period, actual_period, predicted_period,
                               alpha=0.3, color='gray', label='äºˆæ¸¬èª¤å·®', zorder=1)

            # Xè»¸ã®æ™‚é–“ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¨­å®šï¼ˆæ¨ªè»¸æ‹¡å¤§ã«å¯¾å¿œã—ã¦ã‚ˆã‚Šç´°ã‹ãï¼‰
            if time_scale == 'minute':
                axs[i].xaxis.set_major_locator(mdates.MinuteLocator(interval=15))  # 15åˆ†é–“éš”
                axs[i].xaxis.set_minor_locator(mdates.MinuteLocator(interval=5))  # 5åˆ†é–“éš”
                axs[i].xaxis.set_major_formatter(mdates.DateFormatter('%m-%d\n%H:%M'))
            elif time_scale == 'hour':
                axs[i].xaxis.set_major_locator(mdates.HourLocator(interval=1))  # 1æ™‚é–“é–“éš”
                axs[i].xaxis.set_minor_locator(mdates.MinuteLocator(interval=30))  # 30åˆ†é–“éš”
                axs[i].xaxis.set_major_formatter(mdates.DateFormatter('%m-%d\n%H:%M'))
            elif time_scale == 'day':
                axs[i].xaxis.set_major_locator(mdates.HourLocator(interval=4))  # 4æ™‚é–“é–“éš”
                axs[i].xaxis.set_minor_locator(mdates.HourLocator(interval=2))  # 2æ™‚é–“é–“éš”
                axs[i].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d\n%H:%M'))
            elif time_scale == 'week':
                axs[i].xaxis.set_major_locator(mdates.HourLocator(interval=12))  # 12æ™‚é–“é–“éš”
                axs[i].xaxis.set_minor_locator(mdates.HourLocator(interval=6))  # 6æ™‚é–“é–“éš”
                axs[i].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d\n%H:%M'))

            axs[i].tick_params(axis='x', rotation=45, labelsize=9)
        except Exception as e:
            print(f"ã‚¾ãƒ¼ãƒ³ {zone} ã®ãƒ—ãƒ­ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            axs[i].text(0.5, 0.5, 'ãƒ—ãƒ­ãƒƒãƒˆã‚¨ãƒ©ãƒ¼', ha='center', va='center',
                       transform=axs[i].transAxes, fontproperties=font_prop,
                       fontsize=14, fontweight='bold')
            continue

        # ã‚¿ã‚¤ãƒˆãƒ«ã¨ã‚°ãƒªãƒƒãƒ‰ï¼ˆæ”¹å–„ç‰ˆï¼‰
        title = f'ã‚¾ãƒ¼ãƒ³ {zone}'
        if show_lag_analysis and lag_dependency:
            total_lag = lag_dependency.get('lag_temp_percent', 0) + lag_dependency.get('rolling_temp_percent', 0)
            if total_lag > 30:
                title += f'LAGä¾å­˜åº¦é«˜: {total_lag:.1f}%'
                title_color = 'red'
            elif total_lag > 15:
                title += f'LAGä¾å­˜åº¦ä¸­: {total_lag:.1f}%'
                title_color = 'orange'
            else:
                title += f'LAGä¾å­˜åº¦ä½: {total_lag:.1f}%'
                title_color = 'green'
        else:
            title_color = 'black'

        axs[i].set_title(title, fontproperties=font_prop, fontsize=12, fontweight='bold', color=title_color)
        axs[i].set_ylabel('æ¸©åº¦ (Â°C)', fontproperties=font_prop, fontsize=11, fontweight='bold')
        axs[i].grid(True, linestyle='--', alpha=0.7)
        legend = axs[i].legend(loc='upper right', fontsize=10, framealpha=0.9)
        for text in legend.get_texts():
            text.set_fontproperties(font_prop)

        # çµ±è¨ˆæƒ…å ±ã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã§è¡¨ç¤º
        mae = np.mean(np.abs(actual_period - predicted_period))
        r2 = r2_score(actual_period, predicted_period)
        stats_text = f'MAE: {mae:.3f}Â°C\nRÂ²: {r2:.3f}'
        axs[i].text(0.02, 0.98, stats_text, transform=axs[i].transAxes,
                   fontproperties=font_prop,
                   bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
                   verticalalignment='top', fontsize=9, fontweight='bold')

    # æœªä½¿ç”¨ã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã‚’éè¡¨ç¤º
    for j in range(n_zones, len(axs)):
        fig.delaxes(axs[j])

    # å…¨ä½“ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆæ”¹å–„ç‰ˆï¼‰
    main_title = f'{horizon}åˆ†å¾Œäºˆæ¸¬ã®è©³ç´°æ™‚ç³»åˆ—åˆ†æ\n'
    main_title += f'æ™‚é–“è»¸: {time_scale} | è¡¨ç¤ºæœŸé–“: {data_period_days}æ—¥é–“ | å¯¾è±¡ã‚¾ãƒ¼ãƒ³: {len(zones_with_data)}å€‹'
    fig.suptitle(main_title, fontproperties=font_prop, fontsize=16, fontweight='bold', y=0.98)

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])

    # ã‚°ãƒ©ãƒ•ã®ä¿å­˜
    if save and save_dir:
        filename = f'enhanced_detailed_timeseries_all_zones_horizon_{horizon}_{time_scale}_{data_period_days}days.png'
        output_path = os.path.join(save_dir, filename)
        plt.savefig(output_path, dpi=200, bbox_inches='tight', facecolor='white')
        print(f"æ”¹å–„ç‰ˆè©³ç´°æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆï¼ˆå…¨ã‚¾ãƒ¼ãƒ³ï¼‰ä¿å­˜: {output_path}")

    return fig


def create_detailed_analysis_for_zone(results_dict, zone, horizon, save_dir=None,
                                    time_scales=['hour', 'day'], data_periods=[3, 7]):
    """
    æŒ‡å®šã•ã‚ŒãŸã‚¾ãƒ¼ãƒ³ã¨ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã®è©³ç´°åˆ†æã‚’è¤‡æ•°ã®æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«ã§å®Ÿè¡Œ

    Parameters:
    -----------
    results_dict : dict
        å„ã‚¾ãƒ¼ãƒ³ã®çµæœã‚’å«ã‚€è¾æ›¸
    zone : int
        åˆ†æå¯¾è±¡ã®ã‚¾ãƒ¼ãƒ³ç•ªå·
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰
    save_dir : str, optional
        ã‚°ãƒ©ãƒ•ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    time_scales : list, optional
        æ™‚é–“è»¸ã®ã‚¹ã‚±ãƒ¼ãƒ«ãƒªã‚¹ãƒˆ
    data_periods : list, optional
        è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿æœŸé–“ãƒªã‚¹ãƒˆï¼ˆæ—¥æ•°ï¼‰

    Returns:
    --------
    dict
        ç”Ÿæˆã•ã‚ŒãŸå›³ã®ãƒ‘ã‚¹ã¨åˆ†æçµæœ
    """
    if zone not in results_dict or horizon not in results_dict[zone]:
        print(f"ã‚¾ãƒ¼ãƒ³ {zone}, ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ {horizon}åˆ† ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return None

    zone_results = results_dict[zone][horizon]

    # ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
    if not all(k in zone_results for k in ['test_data', 'test_y', 'test_predictions']):
        print(f"å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {list(zone_results.keys())}")
        return None

    test_df = zone_results['test_data']
    test_y = zone_results['test_y']
    test_predictions = zone_results['test_predictions']
    lag_dependency = zone_results.get('lag_dependency', {})

    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®å–å¾—
    if isinstance(test_df, pd.DataFrame) and hasattr(test_df, 'index'):
        timestamps = test_df.index
    else:
        print("ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return None

    generated_files = {}
    analysis_summary = {}

    # å„æ™‚é–“ã‚¹ã‚±ãƒ¼ãƒ«ã§ã®è©³ç´°åˆ†æ
    for time_scale, data_period in zip(time_scales, data_periods):
        print(f"\n### ã‚¾ãƒ¼ãƒ³ {zone}, {horizon}åˆ†å¾Œäºˆæ¸¬ - {time_scale}è»¸åˆ†æï¼ˆ{data_period}æ—¥é–“ï¼‰")

        # è©³ç´°æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆ
        fig = plot_enhanced_detailed_time_series(
            timestamps=timestamps,
            actual=test_y,
            predicted=test_predictions,
            zone=zone,
            horizon=horizon,
            save_dir=save_dir,
            time_scale=time_scale,
            data_period_days=data_period,
            show_lag_analysis=True,
            lag_dependency=lag_dependency,
            save=True
        )

        if fig:
            filename = f'enhanced_detailed_timeseries_zone_{zone}_horizon_{horizon}_{time_scale}_{data_period}days.png'
            if save_dir:
                file_path = os.path.join(save_dir, filename)
                generated_files[f'{time_scale}_{data_period}days'] = file_path

            print(f"âœ“ è©³ç´°åˆ†æå®Œäº†: {time_scale}è»¸, {data_period}æ—¥é–“")

            # åˆ†æçµæœã®è¦ç´„
            valid_mask = ~(pd.isna(test_y) | pd.isna(test_predictions))
            if valid_mask.sum() > 0:
                actual_valid = test_y[valid_mask]
                pred_valid = test_predictions[valid_mask]

                mae = np.mean(np.abs(actual_valid - pred_valid))
                rmse = np.sqrt(np.mean((actual_valid - pred_valid)**2))
                r2 = r2_score(actual_valid, pred_valid)

                analysis_summary[f'{time_scale}_{data_period}days'] = {
                    'mae': mae,
                    'rmse': rmse,
                    'r2': r2,
                    'data_points': valid_mask.sum()
                }
        else:
            print(f"âœ— è©³ç´°åˆ†æå¤±æ•—: {time_scale}è»¸, {data_period}æ—¥é–“")

    # LAGä¾å­˜åº¦ã®è©³ç´°åˆ†æ
    print(f"\n### LAGä¾å­˜åº¦è©³ç´°åˆ†æ:")
    total_lag = lag_dependency.get('lag_temp_percent', 0) + lag_dependency.get('rolling_temp_percent', 0)
    direct_lag = lag_dependency.get('lag_temp_percent', 0)
    rolling_lag = lag_dependency.get('rolling_temp_percent', 0)

    print(f"  ç·LAGä¾å­˜åº¦: {total_lag:.1f}%")
    print(f"  ç›´æ¥LAGç‰¹å¾´é‡ä¾å­˜åº¦: {direct_lag:.1f}%")
    print(f"  ç§»å‹•å¹³å‡ç‰¹å¾´é‡ä¾å­˜åº¦: {rolling_lag:.1f}%")

    if total_lag > 30:
        print("è­¦å‘Š: LAGä¾å­˜åº¦ãŒé«˜ã™ãã¾ã™ï¼ˆ30%è¶…ï¼‰")
        print("    â†’ äºˆæ¸¬ãŒéå»ãƒ‡ãƒ¼ã‚¿ã«éåº¦ã«ä¾å­˜ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
    elif total_lag > 15:
        print("æ³¨æ„: LAGä¾å­˜åº¦ãŒä¸­ç¨‹åº¦ã§ã™ï¼ˆ15-30%ï¼‰")
        print("    â†’ é©åº¦ãªéå»æƒ…å ±ã®åˆ©ç”¨ã§ã™ãŒã€ç›£è¦–ãŒå¿…è¦ã§ã™")
    else:
        print("è‰¯å¥½: LAGä¾å­˜åº¦ã¯ä½ã„ãƒ¬ãƒ™ãƒ«ã§ã™ï¼ˆ15%æœªæº€ï¼‰")

    return {
        'generated_files': generated_files,
        'analysis_summary': analysis_summary,
        'lag_dependency': lag_dependency,
        'zone': zone,
        'horizon': horizon
    }


def generate_comprehensive_time_series_report(results_dict, save_dir=None,
                                             focus_zones=None, focus_horizons=None):
    """
    æ™‚ç³»åˆ—äºˆæ¸¬ã®åŒ…æ‹¬çš„ãªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

    Parameters:
    -----------
    results_dict : dict
        å„ã‚¾ãƒ¼ãƒ³ã®çµæœã‚’å«ã‚€è¾æ›¸
    save_dir : str, optional
        ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    focus_zones : list, optional
        é‡ç‚¹çš„ã«åˆ†æã™ã‚‹ã‚¾ãƒ¼ãƒ³ã®ãƒªã‚¹ãƒˆ
    focus_horizons : list, optional
        é‡ç‚¹çš„ã«åˆ†æã™ã‚‹ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã®ãƒªã‚¹ãƒˆ

    Returns:
    --------
    dict
        ãƒ¬ãƒãƒ¼ãƒˆã®è¦ç´„ã¨ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±
    """
    print("\n" + "="*60)
    print("ğŸ• æ™‚ç³»åˆ—äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«åŒ…æ‹¬ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹")
    print("="*60)

    report_summary = {
        'total_zones': 0,
        'total_horizons': 0,
        'high_lag_dependency': [],
        'best_performance': {},
        'generated_files': []
    }

    # å¯¾è±¡ã‚¾ãƒ¼ãƒ³ã¨ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã®æ±ºå®š
    all_zones = list(results_dict.keys())
    all_horizons = []
    for zone_results in results_dict.values():
        all_horizons.extend(zone_results.keys())
    all_horizons = sorted(list(set(all_horizons)))

    target_zones = focus_zones if focus_zones else all_zones
    target_horizons = focus_horizons if focus_horizons else all_horizons

    report_summary['total_zones'] = len(target_zones)
    report_summary['total_horizons'] = len(target_horizons)

    print(f"ğŸ“Š åˆ†æå¯¾è±¡: {len(target_zones)}ã‚¾ãƒ¼ãƒ³ Ã— {len(target_horizons)}ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³")
    print(f"å¯¾è±¡ã‚¾ãƒ¼ãƒ³: {target_zones}")
    print(f"å¯¾è±¡ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³: {target_horizons}")

    # å„ã‚¾ãƒ¼ãƒ³ãƒ»ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã®è©³ç´°åˆ†æ
    for zone in target_zones:
        if zone not in results_dict:
            continue

        print(f"\nğŸ” ã‚¾ãƒ¼ãƒ³ {zone} ã®è©³ç´°åˆ†æ:")

        for horizon in target_horizons:
            if horizon not in results_dict[zone]:
                continue

            # è©³ç´°åˆ†æã®å®Ÿè¡Œ
            analysis_result = create_detailed_analysis_for_zone(
                results_dict, zone, horizon, save_dir
            )

            if analysis_result:
                # LAGä¾å­˜åº¦ãƒã‚§ãƒƒã‚¯
                lag_dep = analysis_result['lag_dependency'].get('lag_temp_percent', 0) + analysis_result['lag_dependency'].get('rolling_temp_percent', 0)
                if lag_dep > 30:
                    report_summary['high_lag_dependency'].append({
                        'zone': zone,
                        'horizon': horizon,
                        'lag_dependency': lag_dep
                    })

                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡
                if 'analysis_summary' in analysis_result:
                    for analysis_key, metrics in analysis_result['analysis_summary'].items():
                        perf_key = f"zone_{zone}_horizon_{horizon}_{analysis_key}"
                        report_summary['best_performance'][perf_key] = metrics

                # ãƒ•ã‚¡ã‚¤ãƒ«è¨˜éŒ²
                report_summary['generated_files'].extend(
                    list(analysis_result['generated_files'].values())
                )

    # ãƒ¬ãƒãƒ¼ãƒˆè¦ç´„ã®è¡¨ç¤º
    print(f"\n" + "="*60)
    print("ğŸ“‹ ãƒ¬ãƒãƒ¼ãƒˆè¦ç´„")
    print("="*60)

    print(f"âœ… ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(report_summary['generated_files'])}")

    if report_summary['high_lag_dependency']:
        print(f"é«˜LAGä¾å­˜åº¦ãƒ¢ãƒ‡ãƒ« ({len(report_summary['high_lag_dependency'])}å€‹):")
        for item in report_summary['high_lag_dependency']:
            print(f"  - ã‚¾ãƒ¼ãƒ³ {item['zone']}, {item['horizon']}åˆ†: {item['lag_dependency']:.1f}%")
    else:
        print("âœ“ å…¨ãƒ¢ãƒ‡ãƒ«ã®LAGä¾å­˜åº¦ã¯é©åˆ‡ãªç¯„å›²å†…ã§ã™")

    # æœ€é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å®š
    if report_summary['best_performance']:
        best_r2 = max(report_summary['best_performance'].values(), key=lambda x: x.get('r2', 0))
        best_model_key = [k for k, v in report_summary['best_performance'].items() if v == best_r2][0]
        print(f"ğŸ† æœ€é«˜æ€§èƒ½ãƒ¢ãƒ‡ãƒ«: {best_model_key}")
        print(f"   RÂ²: {best_r2['r2']:.4f}, RMSE: {best_r2['rmse']:.3f}Â°C")

    print(f"\nğŸ“ ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ {save_dir} ã«ä¿å­˜ã•ã‚Œã¦ã„ã¾ã™")

    return report_summary


def create_correct_prediction_timestamps(input_timestamps, horizon_minutes):
    """
    äºˆæ¸¬å€¤ã‚’æ­£ã—ã„æœªæ¥ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã§è¡¨ç¤ºã™ã‚‹ãŸã‚ã®é–¢æ•°

    Parameters:
    -----------
    input_timestamps : pd.DatetimeIndex or array-like
        å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    horizon_minutes : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰

    Returns:
    --------
    pd.DatetimeIndex
        äºˆæ¸¬å€¤ç”¨ã®æ­£ã—ã„ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆå…¥åŠ›æ™‚åˆ» + horizon_minutesï¼‰
    """
    if isinstance(input_timestamps, pd.DatetimeIndex):
        return input_timestamps + pd.Timedelta(minutes=horizon_minutes)
    else:
        # array-likeã®å ´åˆã¯pd.DatetimeIndexã«å¤‰æ›
        timestamps_index = pd.DatetimeIndex(input_timestamps)
        return timestamps_index + pd.Timedelta(minutes=horizon_minutes)


def validate_prediction_timing(input_timestamps, actual_values, predicted_values, horizon_minutes, zone):
    """
    äºˆæ¸¬ã®æ™‚é–“è»¸ãŒæ­£ã—ã„ã‹ã‚’æ¤œè¨¼ã™ã‚‹é–¢æ•°

    Parameters:
    -----------
    input_timestamps : pd.DatetimeIndex
        å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    actual_values : array-like
        å®Ÿæ¸¬å€¤ï¼ˆç›®çš„å¤‰æ•°ï¼‰
    predicted_values : array-like
        äºˆæ¸¬å€¤
    horizon_minutes : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰
    zone : int
        ã‚¾ãƒ¼ãƒ³ç•ªå·

    Returns:
    --------
    dict
        æ¤œè¨¼çµæœ
    """
    validation_results = {
        'is_correct_timing': True,
        'issues': [],
        'recommendations': []
    }

    # 1. äºˆæ¸¬å€¤ãŒéå»ã®å®Ÿæ¸¬å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å˜ç´”ã«ã‚³ãƒ”ãƒ¼ã—ã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯
    if len(actual_values) > horizon_minutes // 5:  # ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ
        # å®Ÿæ¸¬å€¤ã¨äºˆæ¸¬å€¤ã®ç›¸é–¢ã‚’æ™‚é–“é…ã‚Œåˆ¥ã«è¨ˆç®—
        correlations = []
        max_lag = min(20, len(actual_values) // 4)  # æœ€å¤§20ã‚¹ãƒ†ãƒƒãƒ—ã¾ã§

        for lag in range(-max_lag, max_lag + 1):
            try:
                if lag < 0:
                    # äºˆæ¸¬å€¤ãŒå®Ÿæ¸¬å€¤ã‚ˆã‚Šå…ˆè¡Œã—ã¦ã„ã‚‹å ´åˆ
                    corr = np.corrcoef(actual_values[-lag:], predicted_values[:lag])[0, 1]
                elif lag > 0:
                    # äºˆæ¸¬å€¤ãŒå®Ÿæ¸¬å€¤ã‚ˆã‚Šé…ã‚Œã¦ã„ã‚‹å ´åˆ
                    corr = np.corrcoef(actual_values[:-lag], predicted_values[lag:])[0, 1]
                else:
                    # åŒæ™‚åˆ»ã®ç›¸é–¢
                    corr = np.corrcoef(actual_values, predicted_values)[0, 1]

                if not np.isnan(corr):
                    correlations.append((lag, corr))
            except:
                continue

        if correlations:
            # æœ€å¤§ç›¸é–¢ã¨ãã®é…ã‚Œã‚’ç‰¹å®š
            max_corr_lag, max_corr_value = max(correlations, key=lambda x: abs(x[1]))

            # å•é¡Œã®æ¤œå‡º
            if max_corr_lag > 0:
                validation_results['is_correct_timing'] = False
                validation_results['issues'].append(
                    f"äºˆæ¸¬å€¤ãŒå®Ÿæ¸¬å€¤ã‚ˆã‚Š{max_corr_lag}ã‚¹ãƒ†ãƒƒãƒ—({max_corr_lag*5}åˆ†)é…ã‚Œã¦ã„ã¾ã™"
                )
                validation_results['recommendations'].append(
                    "äºˆæ¸¬å€¤ã®æ™‚é–“è»¸ã‚’ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚äºˆæ¸¬å€¤ã¯å…¥åŠ›æ™‚åˆ»+äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã§è¡¨ç¤ºã•ã‚Œã‚‹ã¹ãã§ã™ã€‚"
                )

            if abs(max_corr_value) > 0.95 and max_corr_lag != 0:
                validation_results['issues'].append(
                    f"äºˆæ¸¬å€¤ãŒéå»ã®å®Ÿæ¸¬å€¤ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å˜ç´”ã«ã‚³ãƒ”ãƒ¼ã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼ˆç›¸é–¢={max_corr_value:.3f}ï¼‰"
                )
                validation_results['recommendations'].append(
                    "LAGç‰¹å¾´é‡ã¸ã®ä¾å­˜åº¦ã‚’ç¢ºèªã—ã€æœªæ¥æƒ…å ±ã®æ´»ç”¨ã‚’å¼·åŒ–ã—ã¦ãã ã•ã„ã€‚"
                )

    return validation_results


def plot_corrected_time_series(timestamps, actual, predicted, zone, horizon, save_dir=None,
                              points=100, save=True, validate_timing=True):
    """
    æ™‚é–“è»¸ã‚’ä¿®æ­£ã—ãŸæ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆ

    Parameters:
    -----------
    timestamps : array-like
        å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    actual : Series
        å®Ÿæ¸¬å€¤ï¼ˆç›®çš„å¤‰æ•°ï¼‰
    predicted : array-like
        äºˆæ¸¬å€¤
    zone : int
        ã‚¾ãƒ¼ãƒ³ç•ªå·
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰
    save_dir : str, optional
        ã‚°ãƒ©ãƒ•ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    points : int, optional
        æœ€å¤§è¡¨ç¤ºãƒ‡ãƒ¼ã‚¿ç‚¹æ•°
    save : bool, optional
        ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã™ã‚‹ã‹
    validate_timing : bool, optional
        æ™‚é–“è»¸ã®æ¤œè¨¼ã‚’è¡Œã†ã‹

    Returns:
    --------
    matplotlib.figure.Figure
        ãƒ—ãƒ­ãƒƒãƒˆã®Figureã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    # NaNå€¤ã‚’ãƒ•ã‚£ãƒ«ã‚¿
    valid_indices = ~(pd.isna(actual) | pd.isna(predicted))
    timestamps_valid = timestamps[valid_indices]
    actual_valid = actual[valid_indices]
    predicted_valid = predicted[valid_indices]

    if len(timestamps_valid) == 0:
        print(f"ã‚¾ãƒ¼ãƒ³ {zone}: æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return None

    # äºˆæ¸¬å€¤ç”¨ã®æ­£ã—ã„ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä½œæˆ
    prediction_timestamps = create_correct_prediction_timestamps(timestamps_valid, horizon)

    # æ™‚é–“è»¸ã®æ¤œè¨¼
    if validate_timing:
        validation_results = validate_prediction_timing(
            timestamps_valid, actual_valid, predicted_valid, horizon, zone
        )

        if not validation_results['is_correct_timing']:
            print(f"\nâš ï¸ ã‚¾ãƒ¼ãƒ³ {zone} ã®æ™‚é–“è»¸ã«å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ:")
            for issue in validation_results['issues']:
                print(f"  - {issue}")
            print("æ¨å¥¨äº‹é …:")
            for rec in validation_results['recommendations']:
                print(f"  - {rec}")

    # ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    sample_size = min(len(timestamps_valid), points)
    if len(timestamps_valid) > sample_size:
        indices = np.linspace(0, len(timestamps_valid) - 1, sample_size, dtype=int)
        timestamps_sample = timestamps_valid[indices]
        actual_sample = actual_valid[indices]
        predicted_sample = predicted_valid[indices]
        prediction_timestamps_sample = prediction_timestamps[indices]
    else:
        timestamps_sample = timestamps_valid
        actual_sample = actual_valid
        predicted_sample = predicted_valid
        prediction_timestamps_sample = prediction_timestamps

    # ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 10))

    # ä¸Šæ®µ: å¾“æ¥ã®è¡¨ç¤ºæ–¹æ³•ï¼ˆå•é¡Œã®ã‚ã‚‹è¡¨ç¤ºï¼‰
    ax1.plot(timestamps_sample, actual_sample, 'b-', linewidth=2, label='å®Ÿæ¸¬å€¤', alpha=0.8)
    ax1.plot(timestamps_sample, predicted_sample, 'r--', linewidth=2, label='äºˆæ¸¬å€¤ï¼ˆé–“é•ã£ãŸæ™‚é–“è»¸ï¼‰', alpha=0.8)
    ax1.set_title(f'ã‚¾ãƒ¼ãƒ³ {zone} - å¾“æ¥ã®è¡¨ç¤ºæ–¹æ³•ï¼ˆå•é¡Œã‚ã‚Šï¼‰: äºˆæ¸¬å€¤ãŒå…¥åŠ›ã¨åŒã˜æ™‚åˆ»ã«è¡¨ç¤º',
                 fontsize=14, color='red', fontweight='bold')
    ax1.set_ylabel('æ¸©åº¦ (Â°C)', fontsize=12)
    ax1.grid(True, alpha=0.3)
    ax1.legend()
    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d\n%H:%M'))

    # ä¸‹æ®µ: ä¿®æ­£ã•ã‚ŒãŸè¡¨ç¤ºæ–¹æ³•ï¼ˆæ­£ã—ã„è¡¨ç¤ºï¼‰
    ax2.plot(timestamps_sample, actual_sample, 'b-', linewidth=2, label='å®Ÿæ¸¬å€¤', alpha=0.8)
    ax2.plot(prediction_timestamps_sample, predicted_sample, 'r--', linewidth=2,
            label=f'äºˆæ¸¬å€¤ï¼ˆæ­£ã—ã„æ™‚é–“è»¸: +{horizon}åˆ†ï¼‰', alpha=0.8)
    ax2.set_title(f'ã‚¾ãƒ¼ãƒ³ {zone} - ä¿®æ­£ã•ã‚ŒãŸè¡¨ç¤ºæ–¹æ³•ï¼ˆæ­£ã—ã„ï¼‰: äºˆæ¸¬å€¤ãŒæœªæ¥ã®æ™‚åˆ»ã«è¡¨ç¤º',
                 fontsize=14, color='green', fontweight='bold')
    ax2.set_xlabel('æ—¥æ™‚', fontsize=12)
    ax2.set_ylabel('æ¸©åº¦ (Â°C)', fontsize=12)
    ax2.grid(True, alpha=0.3)
    ax2.legend()
    ax2.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d\n%H:%M'))

    # Xè»¸ã®å›è»¢
    for ax in [ax1, ax2]:
        ax.tick_params(axis='x', rotation=45)

    plt.tight_layout()

    # ä¿å­˜
    if save and save_dir:
        output_path = os.path.join(save_dir, f'corrected_timeseries_zone_{zone}_horizon_{horizon}.png')
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"ä¿®æ­£ã•ã‚ŒãŸæ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆä¿å­˜: {output_path}")

    return fig


def plot_corrected_time_series_by_horizon(results_dict, horizon, save_dir=None,
                                         points=100, save=True, validate_timing=True):
    """
    å…¨ã‚¾ãƒ¼ãƒ³ã®æ™‚é–“è»¸ä¿®æ­£æ¸ˆã¿æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆ

    Parameters:
    -----------
    results_dict : dict
        å„ã‚¾ãƒ¼ãƒ³ã®çµæœã‚’å«ã‚€è¾æ›¸
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰
    save_dir : str, optional
        ã‚°ãƒ©ãƒ•ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    points : int, optional
        æœ€å¤§è¡¨ç¤ºãƒ‡ãƒ¼ã‚¿ç‚¹æ•°
    save : bool, optional
        ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜ã™ã‚‹ã‹
    validate_timing : bool, optional
        æ™‚é–“è»¸ã®æ¤œè¨¼ã‚’è¡Œã†ã‹

    Returns:
    --------
    matplotlib.figure.Figure
        ãƒ—ãƒ­ãƒƒãƒˆã®Figureã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    """
    # ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨å¯èƒ½ãªã‚¾ãƒ¼ãƒ³ã‚’åé›†
    zones_with_data = []
    for zone, zone_results in results_dict.items():
        if horizon in zone_results:
            zones_with_data.append(zone)

    if not zones_with_data:
        print(f"è­¦å‘Š: {horizon}åˆ†äºˆæ¸¬ã®ãƒ‡ãƒ¼ã‚¿ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
        return None

    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆè¨ˆç®—
    n_zones = len(zones_with_data)
    n_cols = min(3, n_zones)
    n_rows = math.ceil(n_zones / n_cols)

    # ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
    fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 6, n_rows * 4), squeeze=False)
    axs = axs.flatten()

    validation_summary = []

    for i, zone in enumerate(sorted(zones_with_data)):
        zone_results = results_dict.get(zone, {})
        horizon_results = zone_results.get(horizon, {})

        # ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        timestamps = None
        actual = None
        predicted = None

        if all(k in horizon_results for k in ['test_data', 'test_y', 'test_predictions']):
            test_df = horizon_results['test_data']
            if isinstance(test_df, pd.DataFrame) and hasattr(test_df, 'index'):
                timestamps = test_df.index
                actual = horizon_results['test_y']
                predicted = horizon_results['test_predictions']
                print(f"Zone {zone}: ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ - timestamps: {len(timestamps)}, actual: {len(actual)}, predicted: {len(predicted)}")

        if timestamps is None or actual is None or predicted is None:
            axs[i].text(0.5, 0.5, 'ãƒ‡ãƒ¼ã‚¿ãªã—', ha='center', va='center',
                       transform=axs[i].transAxes, fontsize=12)
            continue

        # æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        try:
            valid_indices = ~(pd.isna(actual) | pd.isna(predicted))
            timestamps_valid = timestamps[valid_indices]
            actual_valid = actual[valid_indices]
            predicted_valid = predicted[valid_indices]
        except Exception as e:
            axs[i].text(0.5, 0.5, 'ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼', ha='center', va='center',
                       transform=axs[i].transAxes, fontsize=12)
            continue

        if len(actual_valid) == 0:
            axs[i].text(0.5, 0.5, 'æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ãªã—', ha='center', va='center',
                       transform=axs[i].transAxes, fontsize=12)
            continue

        # äºˆæ¸¬å€¤ç”¨ã®æ­£ã—ã„ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä½œæˆ
        prediction_timestamps = create_correct_prediction_timestamps(timestamps_valid, horizon)

        # æ™‚é–“è»¸ã®æ¤œè¨¼
        if validate_timing:
            validation_results = validate_prediction_timing(
                timestamps_valid, actual_valid, predicted_valid, horizon, zone
            )
            validation_summary.append({
                'zone': zone,
                'horizon': horizon,
                'is_correct': validation_results['is_correct_timing'],
                'issues': validation_results['issues']
            })

        # ãƒ‡ãƒ¼ã‚¿ã®ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        sample_size = min(len(timestamps_valid), points)
        if len(timestamps_valid) > sample_size:
            indices = np.linspace(0, len(timestamps_valid) - 1, sample_size, dtype=int)
            timestamps_sample = timestamps_valid[indices]
            actual_sample = actual_valid[indices]
            predicted_sample = predicted_valid[indices]
            prediction_timestamps_sample = prediction_timestamps[indices]
        else:
            timestamps_sample = timestamps_valid
            actual_sample = actual_valid
            predicted_sample = predicted_valid
            prediction_timestamps_sample = prediction_timestamps

        # ãƒ—ãƒ­ãƒƒãƒˆ
        try:
            axs[i].plot(timestamps_sample, actual_sample, 'b-', linewidth=2,
                       label='å®Ÿæ¸¬å€¤', alpha=0.8)
            axs[i].plot(prediction_timestamps_sample, predicted_sample, 'r--', linewidth=2,
                       label=f'äºˆæ¸¬å€¤ï¼ˆ+{horizon}åˆ†ï¼‰', alpha=0.8)

            # ã‚¿ã‚¤ãƒˆãƒ«ã«æ¤œè¨¼çµæœã‚’åæ˜ 
            title_color = 'green' if validate_timing and validation_results['is_correct_timing'] else 'red'
            status = 'âœ“' if validate_timing and validation_results['is_correct_timing'] else 'âš '
            axs[i].set_title(f'{status} ã‚¾ãƒ¼ãƒ³ {zone}', color=title_color, fontweight='bold')

            axs[i].set_ylabel('æ¸©åº¦ (Â°C)')
            axs[i].grid(True, alpha=0.3)
            axs[i].legend(fontsize=9)
            axs[i].xaxis.set_major_formatter(mdates.DateFormatter('%m/%d\n%H:%M'))
            axs[i].tick_params(axis='x', rotation=45, labelsize=8)

        except Exception as e:
            axs[i].text(0.5, 0.5, f'ãƒ—ãƒ­ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {str(e)[:20]}...',
                       ha='center', va='center', transform=axs[i].transAxes, fontsize=10)

    # æœªä½¿ç”¨ã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆã‚’éè¡¨ç¤º
    for j in range(n_zones, len(axs)):
        fig.delaxes(axs[j])

    # å…¨ä½“ã‚¿ã‚¤ãƒˆãƒ«
    fig.suptitle(f'{horizon}åˆ†å¾Œäºˆæ¸¬ã®æ™‚é–“è»¸ä¿®æ­£æ¸ˆã¿æ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆ', fontsize=16, fontweight='bold')
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])

    # æ¤œè¨¼çµæœã®è¡¨ç¤º
    if validate_timing and validation_summary:
        print(f"\nğŸ“Š {horizon}åˆ†äºˆæ¸¬ã®æ™‚é–“è»¸æ¤œè¨¼çµæœ:")
        correct_count = sum(1 for v in validation_summary if v['is_correct'])
        total_count = len(validation_summary)
        print(f"  æ­£ã—ã„æ™‚é–“è»¸: {correct_count}/{total_count} ã‚¾ãƒ¼ãƒ³")

        for v in validation_summary:
            if not v['is_correct']:
                print(f"  âš ï¸ ã‚¾ãƒ¼ãƒ³ {v['zone']}: {', '.join(v['issues'])}")

    # ä¿å­˜
    if save and save_dir:
        output_path = os.path.join(save_dir, f'corrected_timeseries_all_zones_horizon_{horizon}.png')
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"ä¿®æ­£ã•ã‚ŒãŸæ™‚ç³»åˆ—ãƒ—ãƒ­ãƒƒãƒˆï¼ˆå…¨ã‚¾ãƒ¼ãƒ³ï¼‰ä¿å­˜: {output_path}")

    return fig


def analyze_feature_patterns(feature_importance, zone, horizon):
    """
    ç‰¹å¾´é‡ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è©³ç´°åˆ†æ

    Parameters:
    -----------
    feature_importance : DataFrame
        ç‰¹å¾´é‡é‡è¦åº¦ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    zone : int
        ã‚¾ãƒ¼ãƒ³ç•ªå·
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰

    Returns:
    --------
    dict
        åˆ†æçµæœ
    """
    analysis_results = {
        'zone': zone,
        'horizon': horizon,
        'lag_features': [],
        'future_features': [],
        'current_features': [],
        'poly_features': [],
        'suspicious_patterns': []
    }

    # ç‰¹å¾´é‡ã‚’åˆ†é¡
    for _, row in feature_importance.iterrows():
        feature_name = row['feature']
        importance = row['importance']

        if '_lag_' in feature_name:
            analysis_results['lag_features'].append({
                'name': feature_name,
                'importance': importance
            })
        elif '_future_' in feature_name:
            analysis_results['future_features'].append({
                'name': feature_name,
                'importance': importance
            })
        elif 'poly_' in feature_name:
            analysis_results['poly_features'].append({
                'name': feature_name,
                'importance': importance
            })
        else:
            analysis_results['current_features'].append({
                'name': feature_name,
                'importance': importance
            })

    # ç–‘ã‚ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
    total_importance = feature_importance['importance'].sum()

    # LAGç‰¹å¾´é‡ã¸ã®éåº¦ãªä¾å­˜
    lag_importance = sum([f['importance'] for f in analysis_results['lag_features']])
    lag_percentage = (lag_importance / total_importance * 100) if total_importance > 0 else 0

    if lag_percentage > 30:
        analysis_results['suspicious_patterns'].append({
            'type': 'high_lag_dependency',
            'description': f'LAGç‰¹å¾´é‡ã¸ã®ä¾å­˜åº¦ãŒé«˜ã™ãã¾ã™ ({lag_percentage:.1f}%)',
            'severity': 'high'
        })

    # å˜ä¸€ç‰¹å¾´é‡ã¸ã®éåº¦ãªä¾å­˜
    max_importance = feature_importance['importance'].max()
    max_percentage = (max_importance / total_importance * 100) if total_importance > 0 else 0

    if max_percentage > 80:
        max_feature = feature_importance.loc[feature_importance['importance'].idxmax(), 'feature']
        analysis_results['suspicious_patterns'].append({
            'type': 'single_feature_dominance',
            'description': f'å˜ä¸€ç‰¹å¾´é‡ "{max_feature}" ã¸ã®ä¾å­˜åº¦ãŒæ¥µç«¯ã«é«˜ã„ã§ã™ ({max_percentage:.1f}%)',
            'severity': 'high'
        })

    # æœªæ¥æƒ…å ±ã®ä¸è¶³
    future_importance = sum([f['importance'] for f in analysis_results['future_features']])
    future_percentage = (future_importance / total_importance * 100) if total_importance > 0 else 0

    if future_percentage < 50:
        analysis_results['suspicious_patterns'].append({
            'type': 'insufficient_future_info',
            'description': f'æœªæ¥æƒ…å ±ã®æ´»ç”¨ãŒä¸è¶³ã—ã¦ã„ã¾ã™ ({future_percentage:.1f}%)',
            'severity': 'medium'
        })

    return analysis_results


def detect_lag_following_pattern(timestamps, actual, predicted, horizon):
    """
    LAGç‰¹å¾´é‡ã«ã‚ˆã‚‹å¾Œè¿½ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º

    Parameters:
    -----------
    timestamps : array-like
        ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    actual : array-like
        å®Ÿæ¸¬å€¤
    predicted : array-like
        äºˆæ¸¬å€¤
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰

    Returns:
    --------
    dict
        æ¤œå‡ºçµæœ
    """
    detection_results = {
        'is_lag_following': False,
        'lag_correlation': 0.0,
        'optimal_lag_steps': 0,
        'confidence': 'low',
        'recommendations': []
    }

    if len(actual) < 100:
        return detection_results

    # æ­£è¦åŒ–
    actual_norm = (actual - np.mean(actual)) / (np.std(actual) + 1e-8)
    predicted_norm = (predicted - np.mean(predicted)) / (np.std(predicted) + 1e-8)

    # ç›¸äº’ç›¸é–¢ã®è¨ˆç®—
    max_lag = min(horizon // 5 + 10, len(actual) // 4)  # äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã«åŸºã¥ãæœ€å¤§é…ã‚Œ
    correlations = []
    lags = range(0, max_lag + 1)

    for lag in lags:
        try:
            if lag == 0:
                corr = np.corrcoef(actual_norm, predicted_norm)[0, 1]
            else:
                corr = np.corrcoef(actual_norm[:-lag], predicted_norm[lag:])[0, 1]

            if not np.isnan(corr):
                correlations.append((lag, corr))
        except:
            continue

    if correlations:
        # æœ€å¤§ç›¸é–¢ã¨ãã®é…ã‚Œã‚’ç‰¹å®š
        max_corr_lag, max_corr_value = max(correlations, key=lambda x: abs(x[1]))
        detection_results['lag_correlation'] = max_corr_value
        detection_results['optimal_lag_steps'] = max_corr_lag

        # å¾Œè¿½ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ¤å®š
        if max_corr_lag > 0 and abs(max_corr_value) > 0.8:
            detection_results['is_lag_following'] = True
            detection_results['confidence'] = 'high' if abs(max_corr_value) > 0.9 else 'medium'

            detection_results['recommendations'].extend([
                f"äºˆæ¸¬ãŒå®Ÿæ¸¬å€¤ã‚ˆã‚Š{max_corr_lag}ã‚¹ãƒ†ãƒƒãƒ—({max_corr_lag*5}åˆ†)é…ã‚Œã¦ã„ã¾ã™",
                "LAGç‰¹å¾´é‡ã¸ã®ä¾å­˜åº¦ã‚’ä¸‹ã’ã¦ãã ã•ã„",
                "æœªæ¥æƒ…å ±ï¼ˆåˆ¶å¾¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ç’°å¢ƒãƒ‡ãƒ¼ã‚¿ï¼‰ã®æ´»ç”¨ã‚’å¼·åŒ–ã—ã¦ãã ã•ã„",
                "ç‰©ç†æ³•å‰‡ãƒ™ãƒ¼ã‚¹ã®ç‰¹å¾´é‡ã‚’è¿½åŠ ã—ã¦ãã ã•ã„"
            ])
        elif max_corr_lag == 0 and abs(max_corr_value) > 0.95:
            detection_results['recommendations'].append(
                "äºˆæ¸¬ç²¾åº¦ã¯é«˜ã„ã§ã™ãŒã€éå­¦ç¿’ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½ã‚’ç¢ºèªã—ã¦ãã ã•ã„"
            )

    return detection_results
