#!/usr/bin/env python
# coding: utf-8

"""
å®Œç’§ãªæ™‚é–“è»¸ä¿®æ­£å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ 
äºˆæ¸¬å€¤ã¨åŒã˜æ™‚åˆ»ï¼ˆäºˆæ¸¬å¯¾è±¡æ™‚åˆ»ï¼‰ã®å®Ÿæ¸¬å€¤ã‚’æ­£ã—ãæ¯”è¼ƒ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
from typing import Dict, Any, Optional, Tuple, List
import os
import math
from .font_config import setup_japanese_font


def get_future_actual_values(original_data: pd.Series,
                           input_timestamps: pd.DatetimeIndex,
                           horizon: int) -> Tuple[pd.DatetimeIndex, np.ndarray]:
    """
    äºˆæ¸¬å¯¾è±¡æ™‚åˆ»ã®å®Ÿæ¸¬å€¤ã‚’å–å¾—

    Parameters:
    -----------
    original_data : pd.Series
        å…ƒã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿
    input_timestamps : pd.DatetimeIndex
        å…¥åŠ›æ™‚åˆ»ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰

    Returns:
    --------
    tuple
        (äºˆæ¸¬å¯¾è±¡æ™‚åˆ», äºˆæ¸¬å¯¾è±¡æ™‚åˆ»ã®å®Ÿæ¸¬å€¤)
    """
    # äºˆæ¸¬å¯¾è±¡æ™‚åˆ»ã®è¨ˆç®—
    future_timestamps = input_timestamps + pd.Timedelta(minutes=horizon)

    # äºˆæ¸¬å¯¾è±¡æ™‚åˆ»ã®å®Ÿæ¸¬å€¤ã‚’å–å¾—
    future_actual_values = []
    for ts in future_timestamps:
        if ts in original_data.index:
            future_actual_values.append(original_data.loc[ts])
        else:
            future_actual_values.append(np.nan)

    return future_timestamps, np.array(future_actual_values)


def plot_perfect_time_axis_comparison(input_timestamps: pd.DatetimeIndex,
                                    input_actual_values: np.ndarray,
                                    predicted_values: np.ndarray,
                                    future_actual_values: np.ndarray,
                                    horizon: int,
                                    zone: int = None,
                                    title: str = None,
                                    save_path: str = None) -> plt.Figure:
    """
    å®Œç’§ãªæ™‚é–“è»¸æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ

    Parameters:
    -----------
    input_timestamps : pd.DatetimeIndex
        å…¥åŠ›æ™‚åˆ»
    input_actual_values : np.ndarray
        å…¥åŠ›æ™‚åˆ»ã®å®Ÿæ¸¬å€¤
    predicted_values : np.ndarray
        äºˆæ¸¬å€¤
    future_actual_values : np.ndarray
        äºˆæ¸¬å¯¾è±¡æ™‚åˆ»ã®å®Ÿæ¸¬å€¤
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰
    zone : int, optional
        ã‚¾ãƒ¼ãƒ³ç•ªå·
    title : str, optional
        ãƒ—ãƒ­ãƒƒãƒˆã‚¿ã‚¤ãƒˆãƒ«
    save_path : str, optional
        ä¿å­˜ãƒ‘ã‚¹

    Returns:
    --------
    plt.Figure
        ä½œæˆã•ã‚ŒãŸãƒ•ã‚£ã‚®ãƒ¥ã‚¢
    """

    # ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆç°¡ç´ åŒ–ï¼‰
    try:
        setup_japanese_font()
    except:
        # ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šã«å¤±æ•—ã—ãŸå ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨
        plt.rcParams['font.family'] = 'DejaVu Sans'
        plt.rcParams['axes.unicode_minus'] = False

    # äºˆæ¸¬å¯¾è±¡æ™‚åˆ»ã®è¨ˆç®—
    future_timestamps = input_timestamps + pd.Timedelta(minutes=horizon)

    # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®ãƒã‚¹ã‚¯
    valid_future_mask = ~np.isnan(future_actual_values)
    valid_input_mask = ~np.isnan(input_actual_values)
    valid_pred_mask = ~np.isnan(predicted_values)

    # 3ã¤ã®ã‚µãƒ–ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ
    fig, axes = plt.subplots(3, 1, figsize=(16, 14))

    # 1. å¾“æ¥ã®é–“é•ã£ãŸæ–¹æ³•
    axes[0].plot(input_timestamps[valid_input_mask],
                input_actual_values[valid_input_mask],
                'b-', linewidth=2, label='å®Ÿæ¸¬å€¤ï¼ˆå…¥åŠ›æ™‚åˆ»ï¼‰', alpha=0.8)
    axes[0].plot(input_timestamps[valid_pred_mask],
                predicted_values[valid_pred_mask],
                'r--', linewidth=2, label='äºˆæ¸¬å€¤ï¼ˆé–“é•ã£ãŸæ™‚é–“è»¸ï¼‰', alpha=0.8)

    axes[0].set_title('âŒ å¾“æ¥ã®é–“é•ã£ãŸæ–¹æ³•: äºˆæ¸¬å€¤ãŒå…¥åŠ›æ™‚åˆ»ã«è¡¨ç¤º',
                     fontsize=14, color='red', fontweight='bold')
    axes[0].set_ylabel('æ¸©åº¦ (Â°C)')
    axes[0].legend()
    axes[0].grid(True, alpha=0.3)

    # 2. ä¿®æ­£ã•ã‚ŒãŸæ–¹æ³•ï¼ˆäºˆæ¸¬å€¤ã®æ™‚é–“è»¸ã®ã¿ä¿®æ­£ï¼‰
    axes[1].plot(input_timestamps[valid_input_mask],
                input_actual_values[valid_input_mask],
                'b-', linewidth=2, label='å®Ÿæ¸¬å€¤ï¼ˆå…¥åŠ›æ™‚åˆ»ï¼‰', alpha=0.8)
    axes[1].plot(future_timestamps[valid_pred_mask],
                predicted_values[valid_pred_mask],
                'r--', linewidth=2, label=f'äºˆæ¸¬å€¤ï¼ˆ+{horizon}åˆ†å¾Œï¼‰', alpha=0.8)

    axes[1].set_title('âš ï¸ éƒ¨åˆ†ä¿®æ­£: äºˆæ¸¬å€¤ã®æ™‚é–“è»¸ã¯ä¿®æ­£ã•ã‚ŒãŸãŒã€æ¯”è¼ƒå¯¾è±¡ãŒä¸é©åˆ‡',
                     fontsize=14, color='orange', fontweight='bold')
    axes[1].set_ylabel('æ¸©åº¦ (Â°C)')
    axes[1].legend()
    axes[1].grid(True, alpha=0.3)

    # 3. å®Œç’§ãªæ–¹æ³•ï¼ˆäºˆæ¸¬å€¤ã¨åŒã˜æ™‚åˆ»ã®å®Ÿæ¸¬å€¤ã§æ¯”è¼ƒï¼‰
    if np.sum(valid_future_mask) > 0:
        # äºˆæ¸¬å¯¾è±¡æ™‚åˆ»ã®å®Ÿæ¸¬å€¤ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
        axes[2].plot(future_timestamps[valid_future_mask],
                    future_actual_values[valid_future_mask],
                    'g-', linewidth=2, label=f'å®Ÿæ¸¬å€¤ï¼ˆ+{horizon}åˆ†å¾Œï¼‰', alpha=0.8)

        # äºˆæ¸¬å€¤ã‚’åŒã˜æ™‚åˆ»ã§ãƒ—ãƒ­ãƒƒãƒˆ
        axes[2].plot(future_timestamps[valid_pred_mask],
                    predicted_values[valid_pred_mask],
                    'r--', linewidth=2, label=f'äºˆæ¸¬å€¤ï¼ˆ+{horizon}åˆ†å¾Œï¼‰', alpha=0.8)

        # æ€§èƒ½æŒ‡æ¨™ã®è¨ˆç®—
        common_indices = valid_future_mask & valid_pred_mask
        if np.sum(common_indices) > 0:
            mae = np.mean(np.abs(future_actual_values[common_indices] - predicted_values[common_indices]))
            rmse = np.sqrt(np.mean((future_actual_values[common_indices] - predicted_values[common_indices]) ** 2))
            corr = np.corrcoef(future_actual_values[common_indices], predicted_values[common_indices])[0, 1]

            # æ€§èƒ½æŒ‡æ¨™ã‚’è¡¨ç¤º
            axes[2].text(0.02, 0.98,
                        f'MAE: {mae:.3f}Â°C\nRMSE: {rmse:.3f}Â°C\nç›¸é–¢: {corr:.3f}',
                        transform=axes[2].transAxes, verticalalignment='top',
                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8),
                        fontsize=10)

        axes[2].set_title('âœ… å®Œç’§ãªæ–¹æ³•: äºˆæ¸¬å€¤ã¨åŒã˜æ™‚åˆ»ã®å®Ÿæ¸¬å€¤ã§æ¯”è¼ƒ',
                         fontsize=14, color='green', fontweight='bold')
    else:
        axes[2].text(0.5, 0.5, f'{horizon}åˆ†å¾Œã®å®Ÿæ¸¬å€¤ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³',
                    transform=axes[2].transAxes, ha='center', va='center', fontsize=12)
        axes[2].set_title('âŒ ãƒ‡ãƒ¼ã‚¿ä¸è¶³: äºˆæ¸¬å¯¾è±¡æ™‚åˆ»ã®å®Ÿæ¸¬å€¤ãªã—',
                         fontsize=14, color='red', fontweight='bold')

    axes[2].set_ylabel('æ¸©åº¦ (Â°C)')
    axes[2].set_xlabel('æ—¥æ™‚')
    axes[2].legend()
    axes[2].grid(True, alpha=0.3)

    # Xè»¸ã®æ›¸å¼è¨­å®š
    for ax in axes:
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d\n%H:%M'))
        ax.tick_params(axis='x', rotation=45)

    # å…¨ä½“ã‚¿ã‚¤ãƒˆãƒ«
    if title:
        fig.suptitle(title, fontsize=16, fontweight='bold')
    else:
        zone_str = f'ã‚¾ãƒ¼ãƒ³ {zone} ' if zone is not None else ''
        fig.suptitle(f'{zone_str}å®Œç’§ãªæ™‚é–“è»¸ä¿®æ­£æ¯”è¼ƒï¼ˆ{horizon}åˆ†äºˆæ¸¬ï¼‰',
                    fontsize=16, fontweight='bold')

    plt.tight_layout(rect=[0, 0.03, 1, 0.95])

    # ä¿å­˜
    if save_path:
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"å®Œç’§ãªæ™‚é–“è»¸æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆä¿å­˜: {save_path}")

    return fig


def create_perfect_visualization_for_zone(results_dict: Dict,
                                        original_df: pd.DataFrame,
                                        zone: int,
                                        horizon: int,
                                        save_dir: str = None,
                                        sample_size: int = 200) -> Dict[str, Any]:
    """
    ç‰¹å®šã‚¾ãƒ¼ãƒ³ã®å®Œç’§ãªå¯è¦–åŒ–ã‚’ä½œæˆ

    Parameters:
    -----------
    results_dict : dict
        ãƒ¢ãƒ‡ãƒ«çµæœè¾æ›¸
    original_df : pd.DataFrame
        å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    zone : int
        ã‚¾ãƒ¼ãƒ³ç•ªå·
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰
    save_dir : str, optional
        ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    sample_size : int
        ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º

    Returns:
    --------
    dict
        å¯è¦–åŒ–çµæœ
    """

    result = {
        'zone': zone,
        'horizon': horizon,
        'success': False,
        'error_message': None,
        'file_paths': [],
        'metrics': {}
    }

    try:
        # ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        zone_results = results_dict.get(zone, {})
        horizon_results = zone_results.get(horizon, {})

        if not horizon_results:
            result['error_message'] = f"ã‚¾ãƒ¼ãƒ³ {zone}, ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ {horizon} ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"
            return result

        # å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
        required_keys = ['test_data', 'test_y', 'test_predictions']
        if not all(k in horizon_results for k in required_keys):
            result['error_message'] = f"å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³: {[k for k in required_keys if k not in horizon_results]}"
            return result

        test_data = horizon_results['test_data']
        test_y = horizon_results['test_y']
        test_predictions = horizon_results['test_predictions']

        # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        valid_indices = test_y.dropna().index
        if len(valid_indices) < 10:
            result['error_message'] = f"æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³: {len(valid_indices)}ãƒã‚¤ãƒ³ãƒˆ"
            return result

        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®é¸æŠ
        actual_sample_size = min(sample_size, len(valid_indices))
        sample_indices = valid_indices[-actual_sample_size:]

        # å…¥åŠ›æ™‚åˆ»ã®å®Ÿæ¸¬å€¤ã‚’å–å¾—
        temp_col = f'sens_temp_{zone}'
        if temp_col not in test_data.columns:
            result['error_message'] = f"æ¸©åº¦ãƒ‡ãƒ¼ã‚¿åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {temp_col}"
            return result

        if temp_col not in original_df.columns:
            result['error_message'] = f"å…ƒãƒ‡ãƒ¼ã‚¿ã«æ¸©åº¦åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {temp_col}"
            return result

        # ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
        input_actual_values = test_data.loc[sample_indices, temp_col].values
        sample_predictions = test_predictions[-actual_sample_size:] if len(test_predictions) >= actual_sample_size else test_predictions

        # äºˆæ¸¬å¯¾è±¡æ™‚åˆ»ã®å®Ÿæ¸¬å€¤ã‚’å–å¾—
        future_timestamps, future_actual_values = get_future_actual_values(
            original_df[temp_col], sample_indices, horizon
        )

        # å®Œç’§ãªæ™‚é–“è»¸æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆã®ä½œæˆ
        if save_dir:
            save_path = os.path.join(save_dir, f'perfect_time_axis_zone_{zone}_horizon_{horizon}.png')
        else:
            save_path = None

        fig = plot_perfect_time_axis_comparison(
            input_timestamps=sample_indices,
            input_actual_values=input_actual_values,
            predicted_values=sample_predictions,
            future_actual_values=future_actual_values,
            horizon=horizon,
            zone=zone,
            save_path=save_path
        )

        if save_path:
            result['file_paths'].append(save_path)

        # æ€§èƒ½æŒ‡æ¨™ã®è¨ˆç®—
        valid_future_mask = ~np.isnan(future_actual_values)
        valid_pred_mask = ~np.isnan(sample_predictions)
        common_mask = valid_future_mask & valid_pred_mask

        if np.sum(common_mask) > 0:
            mae = np.mean(np.abs(future_actual_values[common_mask] - sample_predictions[common_mask]))
            rmse = np.sqrt(np.mean((future_actual_values[common_mask] - sample_predictions[common_mask]) ** 2))
            corr = np.corrcoef(future_actual_values[common_mask], sample_predictions[common_mask])[0, 1]

            result['metrics'] = {
                'mae': mae,
                'rmse': rmse,
                'correlation': corr,
                'valid_points': np.sum(common_mask),
                'total_points': len(sample_predictions)
            }

        plt.close(fig)
        result['success'] = True

    except Exception as e:
        result['error_message'] = f"å¯è¦–åŒ–ä½œæˆã‚¨ãƒ©ãƒ¼: {str(e)}"

    return result


def create_perfect_visualization_for_all_zones(results_dict: Dict,
                                             original_df: pd.DataFrame,
                                             horizon: int,
                                             save_dir: str = None,
                                             sample_size: int = 200) -> Dict[str, Any]:
    """
    å…¨ã‚¾ãƒ¼ãƒ³ã®å®Œç’§ãªå¯è¦–åŒ–ã‚’ä½œæˆ

    Parameters:
    -----------
    results_dict : dict
        ãƒ¢ãƒ‡ãƒ«çµæœè¾æ›¸
    original_df : pd.DataFrame
        å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰
    save_dir : str, optional
        ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    sample_size : int
        ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º

    Returns:
    --------
    dict
        å…¨ä½“ã®å¯è¦–åŒ–çµæœ
    """

    print(f"\n{'='*80}")
    print(f"ğŸ¯ {horizon}åˆ†äºˆæ¸¬ã®å®Œç’§ãªæ™‚é–“è»¸ä¿®æ­£å¯è¦–åŒ–")
    print(f"{'='*80}")

    overall_result = {
        'horizon': horizon,
        'total_zones': 0,
        'successful_zones': 0,
        'failed_zones': 0,
        'zone_results': {},
        'summary_metrics': {},
        'file_paths': []
    }

    if save_dir:
        os.makedirs(save_dir, exist_ok=True)

    # å„ã‚¾ãƒ¼ãƒ³ã®å‡¦ç†
    for zone in sorted(results_dict.keys()):
        print(f"\n--- ã‚¾ãƒ¼ãƒ³ {zone} ã®å®Œç’§ãªå¯è¦–åŒ–ä½œæˆ ---")

        zone_result = create_perfect_visualization_for_zone(
            results_dict=results_dict,
            original_df=original_df,
            zone=zone,
            horizon=horizon,
            save_dir=save_dir,
            sample_size=sample_size
        )

        overall_result['zone_results'][zone] = zone_result
        overall_result['total_zones'] += 1

        if zone_result['success']:
            overall_result['successful_zones'] += 1
            overall_result['file_paths'].extend(zone_result['file_paths'])

            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¡¨ç¤º
            if zone_result['metrics']:
                metrics = zone_result['metrics']
                print(f"âœ… æˆåŠŸ - MAE: {metrics['mae']:.3f}Â°C, "
                      f"RMSE: {metrics['rmse']:.3f}Â°C, "
                      f"ç›¸é–¢: {metrics['correlation']:.3f}")
        else:
            overall_result['failed_zones'] += 1
            print(f"âŒ å¤±æ•— - {zone_result['error_message']}")

    # ã‚µãƒãƒªãƒ¼ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—
    successful_metrics = [r['metrics'] for r in overall_result['zone_results'].values()
                         if r['success'] and r['metrics']]

    if successful_metrics:
        overall_result['summary_metrics'] = {
            'average_mae': np.mean([m['mae'] for m in successful_metrics]),
            'average_rmse': np.mean([m['rmse'] for m in successful_metrics]),
            'average_correlation': np.mean([m['correlation'] for m in successful_metrics]),
            'total_valid_points': sum([m['valid_points'] for m in successful_metrics])
        }

    # çµæœã‚µãƒãƒªãƒ¼ã®è¡¨ç¤º
    print(f"\nğŸ“Š {horizon}åˆ†äºˆæ¸¬ã®å®Œç’§ãªå¯è¦–åŒ–çµæœã‚µãƒãƒªãƒ¼:")
    print(f"  ç·ã‚¾ãƒ¼ãƒ³æ•°: {overall_result['total_zones']}")
    print(f"  æˆåŠŸã‚¾ãƒ¼ãƒ³: {overall_result['successful_zones']}")
    print(f"  å¤±æ•—ã‚¾ãƒ¼ãƒ³: {overall_result['failed_zones']}")

    if overall_result['summary_metrics']:
        metrics = overall_result['summary_metrics']
        print(f"  å¹³å‡MAE: {metrics['average_mae']:.3f}Â°C")
        print(f"  å¹³å‡RMSE: {metrics['average_rmse']:.3f}Â°C")
        print(f"  å¹³å‡ç›¸é–¢: {metrics['average_correlation']:.3f}")

    if save_dir:
        print(f"  ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {save_dir}")
        print(f"  ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(overall_result['file_paths'])}")

    return overall_result


def create_comprehensive_perfect_visualization(results_dict: Dict,
                                             original_df: pd.DataFrame,
                                             horizons: List[int],
                                             save_dir: str = None) -> Dict[str, Any]:
    """
    å…¨ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã®åŒ…æ‹¬çš„ãªå®Œç’§å¯è¦–åŒ–

    Parameters:
    -----------
    results_dict : dict
        ãƒ¢ãƒ‡ãƒ«çµæœè¾æ›¸
    original_df : pd.DataFrame
        å…ƒã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
    horizons : list
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã®ãƒªã‚¹ãƒˆ
    save_dir : str, optional
        ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

    Returns:
    --------
    dict
        åŒ…æ‹¬çš„å¯è¦–åŒ–çµæœ
    """

    print(f"\n{'='*100}")
    print(f"ğŸš€ åŒ…æ‹¬çš„å®Œç’§æ™‚é–“è»¸ä¿®æ­£å¯è¦–åŒ–ã‚·ã‚¹ãƒ†ãƒ ")
    print(f"{'='*100}")

    comprehensive_result = {
        'horizons_processed': [],
        'total_visualizations': 0,
        'successful_visualizations': 0,
        'horizon_results': {},
        'overall_summary': {}
    }

    if save_dir:
        os.makedirs(save_dir, exist_ok=True)

    # å„ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ã®å‡¦ç†
    for horizon in horizons:
        horizon_save_dir = os.path.join(save_dir, f'horizon_{horizon}') if save_dir else None

        horizon_result = create_perfect_visualization_for_all_zones(
            results_dict=results_dict,
            original_df=original_df,
            horizon=horizon,
            save_dir=horizon_save_dir
        )

        comprehensive_result['horizon_results'][horizon] = horizon_result
        comprehensive_result['horizons_processed'].append(horizon)
        comprehensive_result['total_visualizations'] += horizon_result['total_zones']
        comprehensive_result['successful_visualizations'] += horizon_result['successful_zones']

    # å…¨ä½“ã‚µãƒãƒªãƒ¼ã®è¨ˆç®—
    all_metrics = []
    for horizon_result in comprehensive_result['horizon_results'].values():
        if horizon_result['summary_metrics']:
            all_metrics.append(horizon_result['summary_metrics'])

    if all_metrics:
        comprehensive_result['overall_summary'] = {
            'overall_average_mae': np.mean([m['average_mae'] for m in all_metrics]),
            'overall_average_rmse': np.mean([m['average_rmse'] for m in all_metrics]),
            'overall_average_correlation': np.mean([m['average_correlation'] for m in all_metrics]),
            'total_data_points': sum([m['total_valid_points'] for m in all_metrics])
        }

    # æœ€çµ‚çµæœã®è¡¨ç¤º
    print(f"\nğŸ‰ åŒ…æ‹¬çš„å®Œç’§å¯è¦–åŒ–å®Œäº†:")
    print(f"  å‡¦ç†ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³: {comprehensive_result['horizons_processed']}")
    print(f"  ç·å¯è¦–åŒ–æ•°: {comprehensive_result['total_visualizations']}")
    print(f"  æˆåŠŸå¯è¦–åŒ–æ•°: {comprehensive_result['successful_visualizations']}")
    print(f"  æˆåŠŸç‡: {comprehensive_result['successful_visualizations']/comprehensive_result['total_visualizations']*100:.1f}%")

    if comprehensive_result['overall_summary']:
        summary = comprehensive_result['overall_summary']
        print(f"  å…¨ä½“å¹³å‡MAE: {summary['overall_average_mae']:.3f}Â°C")
        print(f"  å…¨ä½“å¹³å‡RMSE: {summary['overall_average_rmse']:.3f}Â°C")
        print(f"  å…¨ä½“å¹³å‡ç›¸é–¢: {summary['overall_average_correlation']:.3f}")

    return comprehensive_result
