#!/usr/bin/env python
# coding: utf-8

"""
ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
ç‰©ç†æ³•å‰‡ã‚’è€ƒæ…®ã—ãŸLightGBMãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–¢æ•°ã‚’æä¾›
"""

import pandas as pd
import numpy as np
import lightgbm as lgb
import pickle
import os
from src.config import LGBM_PARAMS, MODELS_DIR


def train_physics_guided_model(X_train, y_train, params=None):
    """
    ç‰©ç†æ³•å‰‡ã‚’è€ƒæ…®ã—ãŸãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
    ä¿®æ­£: ç‰¹å¾´é‡ã®é‡è¤‡ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€é‡è¤‡ã‚’æ’é™¤

    Parameters:
    -----------
    X_train : DataFrame
        è¨“ç·´ç”¨ç‰¹å¾´é‡
    y_train : Series
        è¨“ç·´ç”¨ç›®çš„å¤‰æ•°
    params : dict
        LightGBMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆNoneã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼‰

    Returns:
    --------
    LGBMRegressor
        ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
    """
    print("ç‰©ç†æ³•å‰‡ã‚¬ã‚¤ãƒ‰ä»˜ããƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...")

    # åˆ—åã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
    if len(X_train.columns) != len(set(X_train.columns)):
        print("è­¦å‘Š: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®åˆ—åã«é‡è¤‡ãŒã‚ã‚Šã¾ã™ã€‚é‡è¤‡ã‚’æ’é™¤ã—ã¾ã™ã€‚")
        # é‡è¤‡ã‚’æ’é™¤ã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
        unique_cols = []
        seen_cols = set()
        for col in X_train.columns:
            if col not in seen_cols:
                unique_cols.append(col)
                seen_cols.add(col)

        # é‡è¤‡ã‚’æ’é™¤ã—ãŸç‰¹å¾´é‡ã®ã¿ã‚’ä½¿ç”¨
        duplicate_count = len(X_train.columns) - len(unique_cols)
        X_train = X_train[unique_cols]
        print(f"{duplicate_count}å€‹ã®é‡è¤‡ç‰¹å¾´é‡ã‚’æ’é™¤ã—ã¾ã—ãŸã€‚æ®‹ã‚Šç‰¹å¾´é‡æ•°: {len(unique_cols)}")

    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
    if params is None:
        params = LGBM_PARAMS.copy()  # ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã¦å…ƒã®è¨­å®šã‚’å¤‰æ›´ã—ãªã„ã‚ˆã†ã«ã™ã‚‹

    # è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŠ‘åˆ¶ã™ã‚‹ãŸã‚ã€verboseã‚’-1ã«è¨­å®š
    params['verbose'] = -1

    # ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã«é©ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
    lgb_model = lgb.LGBMRegressor(**params)

    try:
        # Pythonã®æ¨™æº–è­¦å‘Šã‚’ä¸€æ™‚çš„ã«æŠ‘åˆ¶
        import warnings
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")

            # ã‚¯ãƒ©ã‚¹é‡ã¿ä»˜ã‘ï¼šæ€¥æ¿€ãªæ¸©åº¦å¤‰åŒ–ã‚’é‡è¦–
            if 'weight' in y_train.index.names:
                print("ã‚µãƒ³ãƒ—ãƒ«é‡ã¿ä»˜ã‘ã‚’ä½¿ç”¨ã—ã¾ã™")
                lgb_model.fit(X_train, y_train)
            else:
                # æ€¥æ¿€ãªæ¸©åº¦å¤‰åŒ–ã«å¯¾ã™ã‚‹é‡ã¿ä»˜ã‘
                temp_changes = y_train.diff().abs().fillna(0)
                weights = 1 + temp_changes / temp_changes.mean()

                # ã‚¹ãƒ‘ã‚¤ã‚¯ã®å½±éŸ¿ã‚’åˆ¶é™
                max_weight = 3.0  # æœ€å¤§ã‚¦ã‚§ã‚¤ãƒˆå€¤ã‚’åˆ¶é™
                weights = weights.clip(upper=max_weight)

                lgb_model.fit(X_train, y_train, sample_weight=weights)

        return lgb_model

    except Exception as e:
        print(f"ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print("ç·Šæ€¥å¯¾å‡¦ãƒ¢ãƒ¼ãƒ‰ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è©¦ã¿ã¾ã™...")

        # æœ€å°é™ã®ç‰¹å¾´é‡ã ã‘ã‚’ä½¿ç”¨ã—ã¦å†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
        # åŸºæœ¬çš„ãªç‰¹å¾´é‡ã®ã¿ã‚’é¸æŠï¼ˆæ¸©åº¦ã€è¨­å®šå€¤ã€åˆ¶å¾¡çŠ¶æ…‹ãªã©ï¼‰
        basic_features = [col for col in X_train.columns if any(key in col for key in [
            'sens_temp', 'thermo_state', 'AC_valid', 'AC_mode', 'atmospheric', 'solar'
        ])]

        if len(basic_features) > 0:
            print(f"åŸºæœ¬ç‰¹å¾´é‡{len(basic_features)}å€‹ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™")
            simple_model = lgb.LGBMRegressor(
                n_estimators=100,
                learning_rate=0.05,
                max_depth=5,
                random_state=42,
                verbose=-1  # è­¦å‘Šã‚’æŠ‘åˆ¶
            )
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                simple_model.fit(X_train[basic_features], y_train)
            return simple_model
        else:
            # ã™ã¹ã¦ã®å¯¾å‡¦ãŒå¤±æ•—ã—ãŸå ´åˆã¯ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’è¿”ã™
            print("ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¾ã™ï¼ˆå¹³å‡å€¤äºˆæ¸¬ï¼‰")
            from sklearn.dummy import DummyRegressor
            dummy_model = DummyRegressor(strategy='mean')
            dummy_model.fit(X_train.iloc[:, 0].values.reshape(-1, 1), y_train)
            return dummy_model


def save_model_and_features(model, feature_list, zone, horizon, poly_config=None):
    """
    ãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å¾´é‡æƒ…å ±ã‚’ä¿å­˜ã™ã‚‹é–¢æ•°

    Parameters:
    -----------
    model : å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
        ä¿å­˜ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
    feature_list : list
        ç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆ
    zone : int
        ã‚¾ãƒ¼ãƒ³ç•ªå·
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰
    poly_config : dict, optional
        å¤šé …å¼ç‰¹å¾´é‡ã®è¨­å®šæƒ…å ±

    Returns:
    --------
    tuple
        (ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹, ç‰¹å¾´é‡æƒ…å ±ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹)
    """
    # ãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å¾´é‡æƒ…å ±ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    model_filename = os.path.join(MODELS_DIR, f"lgbm_model_zone_{zone}_horizon_{horizon}.pkl")
    features_filename = os.path.join(MODELS_DIR, f"features_zone_{zone}_horizon_{horizon}.pkl")

    try:
        # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        with open(model_filename, 'wb') as f:
            pickle.dump(model, f)
        print(f"ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {model_filename}")

        # ç‰¹å¾´é‡æƒ…å ±ã®ä¿å­˜
        feature_info = {
            'feature_cols': feature_list,
            'poly_config': poly_config if poly_config else {
                'use_poly': False,
                'poly_features': []
            }
        }
        with open(features_filename, 'wb') as f:
            pickle.dump(feature_info, f)
        print(f"ç‰¹å¾´é‡æƒ…å ±ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {features_filename}")

        return model_filename, features_filename
    except Exception as e:
        print(f"ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ç‰¹å¾´é‡æƒ…å ±ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None, None


def load_model_and_features(zone, horizon):
    """
    ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å¾´é‡æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°

    Parameters:
    -----------
    zone : int
        ã‚¾ãƒ¼ãƒ³ç•ªå·
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰

    Returns:
    --------
    tuple
        (ãƒ¢ãƒ‡ãƒ«, ç‰¹å¾´é‡æƒ…å ±)
    """
    model_filename = os.path.join(MODELS_DIR, f"lgbm_model_zone_{zone}_horizon_{horizon}.pkl")
    features_filename = os.path.join(MODELS_DIR, f"features_zone_{zone}_horizon_{horizon}.pkl")

    try:
        # ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        with open(model_filename, 'rb') as f:
            model = pickle.load(f)

        # ç‰¹å¾´é‡æƒ…å ±ã®èª­ã¿è¾¼ã¿
        with open(features_filename, 'rb') as f:
            feature_info = pickle.load(f)

        print(f"ãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å¾´é‡æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: ã‚¾ãƒ¼ãƒ³{zone}, {horizon}åˆ†å¾Œ")
        return model, feature_info
    except Exception as e:
        print(f"ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ç‰¹å¾´é‡æƒ…å ±ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None, None


def train_temperature_difference_model(X_train, y_train, params=None):
    """
    æ¸©åº¦å·®åˆ†äºˆæ¸¬å°‚ç”¨ã®ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–¢æ•°

    æ¸©åº¦ã®å¤‰åŒ–é‡ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã€å¾“æ¥ã®æ¸©åº¦äºˆæ¸¬ã¨ã¯ç•°ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã‚’è¡Œã†ï¼š
    - ã‚ˆã‚Šé«˜ã„å­¦ç¿’ç‡ã§å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰ãˆã‚‹
    - å°ã•ãªå·®åˆ†å€¤ã«å¯¾ã™ã‚‹æ„Ÿåº¦ã‚’å‘ä¸Š
    - å¤‰åŒ–ã®æ¿€ã—ã„æœŸé–“ã¸ã®é‡ã¿ä»˜ã‘å¼·åŒ–
    - ç‰¹å¾´é‡é‡è¦åº¦ã«åŸºã¥ãå‹•çš„èª¿æ•´

    Parameters:
    -----------
    X_train : DataFrame
        è¨“ç·´ç”¨ç‰¹å¾´é‡
    y_train : Series
        è¨“ç·´ç”¨ç›®çš„å¤‰æ•°ï¼ˆæ¸©åº¦å·®åˆ†ï¼‰
    params : dict
        LightGBMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆNoneã®å ´åˆã¯å·®åˆ†äºˆæ¸¬ç”¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼‰

    Returns:
    --------
    LGBMRegressor
        ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
    """
    print("ğŸ”¥ é«˜ç²¾åº¦æ¸©åº¦å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...")

    # åˆ—åã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
    if len(X_train.columns) != len(set(X_train.columns)):
        print("è­¦å‘Š: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®åˆ—åã«é‡è¤‡ãŒã‚ã‚Šã¾ã™ã€‚é‡è¤‡ã‚’æ’é™¤ã—ã¾ã™ã€‚")
        unique_cols = []
        seen_cols = set()
        for col in X_train.columns:
            if col not in seen_cols:
                unique_cols.append(col)
                seen_cols.add(col)

        duplicate_count = len(X_train.columns) - len(unique_cols)
        X_train = X_train[unique_cols]
        print(f"{duplicate_count}å€‹ã®é‡è¤‡ç‰¹å¾´é‡ã‚’æ’é™¤ã—ã¾ã—ãŸã€‚æ®‹ã‚Šç‰¹å¾´é‡æ•°: {len(unique_cols)}")

    # é«˜ç²¾åº¦å·®åˆ†äºˆæ¸¬ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    if params is None:
        params = {
            'objective': 'regression',
            'metric': 'mae',  # æ¸©åº¦å·®åˆ†ã§ã¯å¹³å‡çµ¶å¯¾èª¤å·®ãŒé©åˆ‡
            'boosting_type': 'gbdt',
            'num_leaves': 255,  # ã‚ˆã‚Šè¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰ãˆã‚‹
            'learning_rate': 0.05,  # ã‚ˆã‚Šæ…é‡ãªå­¦ç¿’
            'feature_fraction': 0.85,  # ç‰¹å¾´é‡ã®å¤šæ§˜æ€§ã‚’ä¿æŒ
            'bagging_fraction': 0.75,  # ã‚ˆã‚Šå³æ ¼ãªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            'bagging_freq': 3,
            'max_depth': 10,  # ã‚ˆã‚Šæ·±ã„æ±ºå®šæœ¨
            'min_data_in_leaf': 8,  # å°ã•ãªå·®åˆ†å€¤ã‚’æ‰ãˆã‚‹ãŸã‚å°ã•ã‚ã«è¨­å®š
            'lambda_l1': 0.05,  # L1æ­£å‰‡åŒ–ã‚’å¼·åŒ–
            'lambda_l2': 0.15,  # L2æ­£å‰‡åŒ–ã‚’å¼·åŒ–
            'min_gain_to_split': 0.01,  # ã‚ˆã‚Šç´°ã‹ã„åˆ†å‰²ã‚’è¨±å¯
            'max_bin': 512,  # ã‚ˆã‚Šç´°ã‹ã„ãƒ“ãƒ‹ãƒ³ã‚°
            'random_state': 42,
            'n_estimators': 1500,  # ã‚ˆã‚Šå¤šãã®æœ¨
            'verbose': -1,
            'early_stopping_rounds': 100,
            'force_col_wise': True  # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®æ”¹å–„
        }

    lgb_model = lgb.LGBMRegressor(**params)

    try:
        import warnings
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")

            # é«˜åº¦ãªå·®åˆ†äºˆæ¸¬å°‚ç”¨é‡ã¿ä»˜ã‘æˆ¦ç•¥
            print("ğŸ¯ é«˜åº¦ãªé‡ã¿ä»˜ã‘æˆ¦ç•¥ã‚’é©ç”¨ä¸­...")

            # 1. å¤§ããªå¤‰åŒ–é‡ã¸ã®é‡ã¿ä»˜ã‘ï¼ˆéç·šå½¢ï¼‰
            abs_diff = y_train.abs()
            abs_diff_std = abs_diff.std()
            abs_diff_mean = abs_diff.mean()

            # éç·šå½¢é‡ã¿ä»˜ã‘ï¼ˆæŒ‡æ•°é–¢æ•°çš„ï¼‰
            change_weights = 1 + np.exp((abs_diff - abs_diff_mean) / abs_diff_std) * 0.3
            change_weights = change_weights.clip(upper=4.0)  # æœ€å¤§é‡ã¿ã‚’åˆ¶é™

            # 2. æ¥µå°å¤‰åŒ–ã®é‡è¦æ€§å¼·åŒ–ï¼ˆãƒã‚¤ã‚ºé™¤å»åŠ¹æœï¼‰
            very_small_changes = abs_diff < abs_diff.quantile(0.1)
            small_change_bonus = np.where(very_small_changes, 1.5, 1.0)

            # 3. å¤‰åŒ–æ–¹å‘ã®å¤šæ§˜æ€§ã‚’é‡è¦–ï¼ˆæ–¹å‘è»¢æ›ç‚¹ã®é‡è¦æ€§ï¼‰
            direction_changes = np.abs(np.sign(y_train).diff()).fillna(0)
            direction_weights = 1 + direction_changes * 0.5

            # 4. æ™‚ç³»åˆ—ãƒ‘ã‚¿ãƒ¼ãƒ³ã«åŸºã¥ãé‡ã¿ä»˜ã‘
            # é€£ç¶šã™ã‚‹å¤§ããªå¤‰åŒ–ã®é‡è¦æ€§ã‚’å¼·åŒ–
            rolling_abs_diff = abs_diff.rolling(window=3, center=True).mean().fillna(abs_diff)
            pattern_weights = 1 + (rolling_abs_diff / abs_diff_mean - 1) * 0.2
            pattern_weights = pattern_weights.clip(lower=0.5, upper=2.0)

            # 5. å¤–ã‚Œå€¤çš„ãªå¤§å¤‰åŒ–ã¸ã®ç‰¹åˆ¥é‡ã¿ä»˜ã‘
            outlier_threshold = abs_diff.quantile(0.95)
            outlier_weights = np.where(abs_diff > outlier_threshold, 2.0, 1.0)

            # æœ€çµ‚çš„ãªé‡ã¿ï¼ˆè¤‡æ•°ã®é‡ã¿ä»˜ã‘æˆ¦ç•¥ã®çµ„ã¿åˆã‚ã›ï¼‰
            final_weights = (change_weights * small_change_bonus * direction_weights *
                           pattern_weights * outlier_weights)
            final_weights = final_weights.clip(upper=5.0)  # æœ€å¤§é‡ã¿ã‚’åˆ¶é™

            print(f"é‡ã¿ä»˜ã‘çµ±è¨ˆ:")
            print(f"  å¹³å‡é‡ã¿: {final_weights.mean():.3f}")
            print(f"  é‡ã¿ç¯„å›²: {final_weights.min():.3f} - {final_weights.max():.3f}")
            print(f"  é«˜é‡ã¿(>2.0)ãƒ‡ãƒ¼ã‚¿: {(final_weights > 2.0).sum()}è¡Œ ({(final_weights > 2.0).mean()*100:.1f}%)")

            # æ¤œè¨¼ç”¨åˆ†å‰²ã§early stoppingã‚’ä½¿ç”¨
            from sklearn.model_selection import train_test_split
            X_train_split, X_val_split, y_train_split, y_val_split, weights_train, weights_val = train_test_split(
                X_train, y_train, final_weights, test_size=0.15, random_state=42
            )

            lgb_model.fit(
                X_train_split, y_train_split,
                sample_weight=weights_train,
                eval_set=[(X_val_split, y_val_split)],
                eval_sample_weight=[weights_val],
                callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]
            )

            print(f"âœ… é«˜ç²¾åº¦å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº† (æœ€çµ‚ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: {lgb_model.best_iteration_})")

        return lgb_model

    except Exception as e:
        print(f"é«˜ç²¾åº¦å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print("ã‚·ãƒ³ãƒ—ãƒ«ãªå·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã§å†è©¦è¡Œ...")

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        simple_model = lgb.LGBMRegressor(
            n_estimators=500,
            learning_rate=0.05,
            max_depth=8,
            random_state=42,
            verbose=-1
        )

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            simple_model.fit(X_train, y_train)

        return simple_model


def save_difference_model_and_features(model, feature_list, zone, horizon, poly_config=None):
    """
    å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å¾´é‡æƒ…å ±ã‚’ä¿å­˜ã™ã‚‹é–¢æ•°

    Parameters:
    -----------
    model : å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
        ä¿å­˜ã™ã‚‹å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
    feature_list : list
        ç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆ
    zone : int
        ã‚¾ãƒ¼ãƒ³ç•ªå·
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰
    poly_config : dict, optional
        å¤šé …å¼ç‰¹å¾´é‡ã®è¨­å®šæƒ…å ±

    Returns:
    --------
    tuple
        (ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹, ç‰¹å¾´é‡æƒ…å ±ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹)
    """
    # å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«å°‚ç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«å
    model_filename = os.path.join(MODELS_DIR, f"diff_model_zone_{zone}_horizon_{horizon}.pkl")
    features_filename = os.path.join(MODELS_DIR, f"diff_features_zone_{zone}_horizon_{horizon}.pkl")

    try:
        # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        with open(model_filename, 'wb') as f:
            pickle.dump(model, f)
        print(f"å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {model_filename}")

        # ç‰¹å¾´é‡æƒ…å ±ã®ä¿å­˜
        feature_info = {
            'feature_cols': feature_list,
            'model_type': 'temperature_difference',
            'poly_config': poly_config if poly_config else {
                'use_poly': False,
                'poly_features': []
            }
        }
        with open(features_filename, 'wb') as f:
            pickle.dump(feature_info, f)
        print(f"å·®åˆ†äºˆæ¸¬ç‰¹å¾´é‡æƒ…å ±ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {features_filename}")

        return model_filename, features_filename
    except Exception as e:
        print(f"å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ç‰¹å¾´é‡æƒ…å ±ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None, None
