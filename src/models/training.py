#!/usr/bin/env python
# coding: utf-8

"""
ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
ç‰©ç†æ³•å‰‡ã‚’è€ƒæ…®ã—ãŸLightGBMãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–¢æ•°ã‚’æä¾›
"""

import pandas as pd
import numpy as np
import lightgbm as lgb
import pickle
import os
from src.config import LGBM_PARAMS, MODELS_DIR


class PhysicsConstrainedLGBM:
    """
    ç‰©ç†åˆ¶ç´„ã‚’è€ƒæ…®ã—ãŸLightGBMãƒ¢ãƒ‡ãƒ«
    
    åˆ¶å¾¡å¤‰æ•°ã¸ã®æ„Ÿåº¦ã¨ç‰©ç†çš„å¦¥å½“æ€§ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã«ï¼š
    1. åˆ¶å¾¡å¤‰æ•°ï¼ˆAC_valid, AC_mode, AC_setï¼‰ã®é‡è¦åº¦ã‚’å¼·åˆ¶çš„ã«é«˜ã‚ã‚‹
    2. ç‰©ç†åˆ¶ç´„é•åæ™‚ã®ãƒšãƒŠãƒ«ãƒ†ã‚£ã‚’èª²ã™
    3. é©å¿œçš„é‡ã¿ä»˜ã‘ã«ã‚ˆã‚‹å­¦ç¿’åŠ¹æœã®å‘ä¸Š
    """
    
    def __init__(self, control_sensitivity=0.5, physics_penalty=0.2, 
                 adaptive_weight_start=0.1, adaptive_weight_end=0.7, **lgb_params):
        """
        Parameters:
        -----------
        control_sensitivity : float
            åˆ¶å¾¡å¤‰æ•°ã¸ã®æ„Ÿåº¦ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ0.0-1.0ï¼‰
        physics_penalty : float
            ç‰©ç†åˆ¶ç´„é•åæ™‚ã®ãƒšãƒŠãƒ«ãƒ†ã‚£ä¿‚æ•°
        adaptive_weight_start : float
            é©å¿œçš„é‡ã¿ä»˜ã‘ã®é–‹å§‹å€¤
        adaptive_weight_end : float
            é©å¿œçš„é‡ã¿ä»˜ã‘ã®çµ‚äº†å€¤
        lgb_params : dict
            LightGBMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        """
        self.control_sensitivity = control_sensitivity
        self.physics_penalty = physics_penalty
        self.adaptive_weight_start = adaptive_weight_start
        self.adaptive_weight_end = adaptive_weight_end
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ãƒãƒ¼ã‚¸
        default_params = LGBM_PARAMS.copy()
        default_params.update(lgb_params)
        default_params['verbose'] = -1
        
        self.lgb_params = default_params
        self.model = None
        self.feature_names = None
        self.control_features = []
        
    def _identify_control_features(self, feature_names):
        """åˆ¶å¾¡å¤‰æ•°é–¢é€£ã®ç‰¹å¾´é‡ã‚’ç‰¹å®š"""
        control_keywords = ['AC_valid', 'AC_mode', 'AC_set', 'thermo_state']
        self.control_features = [feat for feat in feature_names 
                               if any(keyword in feat for keyword in control_keywords)]
        print(f"åˆ¶å¾¡é–¢é€£ç‰¹å¾´é‡ã‚’ç‰¹å®š: {len(self.control_features)}å€‹")
        return self.control_features
    
    def _create_adaptive_weights(self, y_train, iteration_ratio):
        """
        é©å¿œçš„é‡ã¿ä»˜ã‘ã®ä½œæˆ
        å­¦ç¿’ã®é€²è¡Œã«å¿œã˜ã¦åˆ¶å¾¡åŠ¹æœã‚’æ®µéšçš„ã«å¼·åŒ–
        """
        # åŸºæœ¬é‡ã¿ï¼šæ¸©åº¦å¤‰åŒ–ã®å¤§ãã•ã«å¿œã˜ã¦
        temp_changes = np.abs(y_train)
        basic_weights = 1 + temp_changes / (temp_changes.mean() + 1e-6)
        
        # é©å¿œçš„é‡ã¿ï¼šå­¦ç¿’é€²è¡Œã«å¿œã˜ã¦åˆ¶å¾¡åŠ¹æœã‚’é‡è¦–
        current_adaptive_weight = (self.adaptive_weight_start + 
                                 (self.adaptive_weight_end - self.adaptive_weight_start) * iteration_ratio)
        
        # åˆ¶å¾¡å¤‰æ•°ã®å½±éŸ¿ã‚’å¼·åŒ–ã™ã‚‹é‡ã¿
        control_weight = 1 + current_adaptive_weight
        
        # æœ€çµ‚é‡ã¿
        final_weights = basic_weights * control_weight
        
        # é‡ã¿ã®æ­£è¦åŒ–ã¨ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°
        final_weights = np.clip(final_weights, 0.5, 5.0)
        
        return final_weights
    
    def _apply_physics_constraints(self, pred, X_test):
        """
        ç‰©ç†åˆ¶ç´„ã®é©ç”¨
        åˆ¶å¾¡å¤‰æ•°ã®å¤‰åŒ–ã«å¯¾ã—ã¦äºˆæ¸¬ãŒé©åˆ‡ã«åå¿œã™ã‚‹ã‚ˆã†èª¿æ•´
        """
        adjusted_pred = pred.copy()
        
        if len(self.control_features) == 0:
            return adjusted_pred
            
        # åˆ¶å¾¡åŠ¹æœã®å¼·åˆ¶çš„ãªèª¿æ•´
        for feat in self.control_features:
            if feat in X_test.columns:
                feat_values = X_test[feat].values
                
                if 'AC_valid' in feat:
                    # ã‚µãƒ¼ãƒ¢ONæ™‚ã¯æ¸©åº¦åˆ¶å¾¡åŠ¹æœã‚’å¼·åŒ–
                    thermo_on_mask = feat_values == 1
                    adjusted_pred[thermo_on_mask] += self.control_sensitivity * 0.1
                    
                elif 'AC_mode' in feat:
                    # æš–æˆ¿æ™‚ã¯æ­£ã®èª¿æ•´ã€å†·æˆ¿æ™‚ã¯è² ã®èª¿æ•´
                    heat_mask = feat_values == 1
                    cool_mask = feat_values == 0
                    adjusted_pred[heat_mask] += self.control_sensitivity * 0.15
                    adjusted_pred[cool_mask] -= self.control_sensitivity * 0.15
                    
                elif 'AC_set' in feat:
                    # è¨­å®šæ¸©åº¦ã®å½±éŸ¿ã‚’å¼·åŒ– - çµ¶å¯¾å€¤ãƒ™ãƒ¼ã‚¹ã§åˆ¶å¾¡åŠ¹æœã‚’é©ç”¨
                    # é«˜è¨­å®šæ¸©åº¦ã¯æ­£ã®èª¿æ•´ã€ä½è¨­å®šæ¸©åº¦ã¯è² ã®èª¿æ•´
                    baseline_temp = 24.0  # åŸºæº–æ¸©åº¦ï¼ˆÂ°Cï¼‰
                    temp_adjustment = (feat_values - baseline_temp) * self.control_sensitivity * 0.15
                    adjusted_pred += temp_adjustment
        
        return adjusted_pred
    
    def fit(self, X_train, y_train, X_val=None, y_val=None):
        """ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’"""
        print("ğŸš€ PhysicsConstrainedLGBMå­¦ç¿’é–‹å§‹...")
        
        self.feature_names = list(X_train.columns)
        self._identify_control_features(self.feature_names)
        
        # æ®µéšçš„å­¦ç¿’ã«ã‚ˆã‚‹åˆ¶å¾¡æ„Ÿåº¦ã®å‘ä¸Š
        n_stages = 3
        models = []
        
        for stage in range(n_stages):
            iteration_ratio = stage / (n_stages - 1)
            print(f"  ğŸ“Š å­¦ç¿’ã‚¹ãƒ†ãƒ¼ã‚¸ {stage + 1}/{n_stages} (é©å¿œé‡ã¿: {iteration_ratio:.1f})")
            
            # é©å¿œçš„é‡ã¿ä½œæˆ
            weights = self._create_adaptive_weights(y_train, iteration_ratio)
            
            # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
            stage_model = lgb.LGBMRegressor(**self.lgb_params)
            
            if X_val is not None and y_val is not None:
                val_weights = self._create_adaptive_weights(y_val, iteration_ratio)
                stage_model.fit(
                    X_train, y_train, 
                    sample_weight=weights,
                    eval_set=[(X_val, y_val)],
                    eval_sample_weight=[val_weights],
                    callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]
                )
            else:
                stage_model.fit(X_train, y_train, sample_weight=weights)
            
            models.append(stage_model)
        
        # æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠï¼ˆæœ€å¾Œã®ã‚¹ãƒ†ãƒ¼ã‚¸ï¼‰
        self.model = models[-1]
        
        # åˆ¶å¾¡ç‰¹å¾´é‡ã®é‡è¦åº¦ãƒã‚§ãƒƒã‚¯
        if hasattr(self.model, 'feature_importances_'):
            importance_df = pd.DataFrame({
                'feature': self.feature_names,
                'importance': self.model.feature_importances_
            }).sort_values('importance', ascending=False)
            
            control_importance = importance_df[
                importance_df['feature'].isin(self.control_features)
            ]
            
            print(f"  ğŸ“ˆ åˆ¶å¾¡ç‰¹å¾´é‡é‡è¦åº¦ãƒˆãƒƒãƒ—5:")
            for _, row in control_importance.head(5).iterrows():
                print(f"    {row['feature']}: {row['importance']:.3f}")
        
        print("âœ… PhysicsConstrainedLGBMå­¦ç¿’å®Œäº†")
        return self
    
    def predict(self, X_test):
        """ç‰©ç†åˆ¶ç´„ã‚’è€ƒæ…®ã—ãŸäºˆæ¸¬"""
        if self.model is None:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã«fit()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        
        # åŸºæœ¬äºˆæ¸¬
        base_pred = self.model.predict(X_test)
        
        # ç‰©ç†åˆ¶ç´„ã®é©ç”¨
        constrained_pred = self._apply_physics_constraints(base_pred, X_test)
        
        return constrained_pred
    
    @property
    def feature_importances_(self):
        """ç‰¹å¾´é‡é‡è¦åº¦ã®å–å¾—"""
        if self.model is None:
            return None
        return self.model.feature_importances_
    
    @property
    def best_iteration_(self):
        """æœ€é©ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°ã®å–å¾—"""
        if self.model is None:
            return None
        return getattr(self.model, 'best_iteration_', None)


def train_physics_guided_model(X_train, y_train, params=None):
    """
    ç‰©ç†æ³•å‰‡ã‚’è€ƒæ…®ã—ãŸãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
    ä¿®æ­£: ç‰¹å¾´é‡ã®é‡è¤‡ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€é‡è¤‡ã‚’æ’é™¤

    Parameters:
    -----------
    X_train : DataFrame
        è¨“ç·´ç”¨ç‰¹å¾´é‡
    y_train : Series
        è¨“ç·´ç”¨ç›®çš„å¤‰æ•°
    params : dict
        LightGBMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆNoneã®å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼‰

    Returns:
    --------
    LGBMRegressor
        ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
    """
    print("ç‰©ç†æ³•å‰‡ã‚¬ã‚¤ãƒ‰ä»˜ããƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...")

    # åˆ—åã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
    if len(X_train.columns) != len(set(X_train.columns)):
        print("è­¦å‘Š: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®åˆ—åã«é‡è¤‡ãŒã‚ã‚Šã¾ã™ã€‚é‡è¤‡ã‚’æ’é™¤ã—ã¾ã™ã€‚")
        # é‡è¤‡ã‚’æ’é™¤ã—ãŸãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
        unique_cols = []
        seen_cols = set()
        for col in X_train.columns:
            if col not in seen_cols:
                unique_cols.append(col)
                seen_cols.add(col)

        # é‡è¤‡ã‚’æ’é™¤ã—ãŸç‰¹å¾´é‡ã®ã¿ã‚’ä½¿ç”¨
        duplicate_count = len(X_train.columns) - len(unique_cols)
        X_train = X_train[unique_cols]
        print(f"{duplicate_count}å€‹ã®é‡è¤‡ç‰¹å¾´é‡ã‚’æ’é™¤ã—ã¾ã—ãŸã€‚æ®‹ã‚Šç‰¹å¾´é‡æ•°: {len(unique_cols)}")

    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
    if params is None:
        params = LGBM_PARAMS.copy()  # ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã¦å…ƒã®è¨­å®šã‚’å¤‰æ›´ã—ãªã„ã‚ˆã†ã«ã™ã‚‹

    # è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŠ‘åˆ¶ã™ã‚‹ãŸã‚ã€verboseã‚’-1ã«è¨­å®š
    params['verbose'] = -1

    # ç‰©ç†ãƒ¢ãƒ‡ãƒ«ã«é©ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
    lgb_model = lgb.LGBMRegressor(**params)

    try:
        # Pythonã®æ¨™æº–è­¦å‘Šã‚’ä¸€æ™‚çš„ã«æŠ‘åˆ¶
        import warnings
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")

            # ã‚¯ãƒ©ã‚¹é‡ã¿ä»˜ã‘ï¼šæ€¥æ¿€ãªæ¸©åº¦å¤‰åŒ–ã‚’é‡è¦–
            if 'weight' in y_train.index.names:
                print("ã‚µãƒ³ãƒ—ãƒ«é‡ã¿ä»˜ã‘ã‚’ä½¿ç”¨ã—ã¾ã™")
                lgb_model.fit(X_train, y_train)
            else:
                # æ€¥æ¿€ãªæ¸©åº¦å¤‰åŒ–ã«å¯¾ã™ã‚‹é‡ã¿ä»˜ã‘
                temp_changes = y_train.diff().abs().fillna(0)
                weights = 1 + temp_changes / temp_changes.mean()

                # ã‚¹ãƒ‘ã‚¤ã‚¯ã®å½±éŸ¿ã‚’åˆ¶é™
                max_weight = 3.0  # æœ€å¤§ã‚¦ã‚§ã‚¤ãƒˆå€¤ã‚’åˆ¶é™
                weights = weights.clip(upper=max_weight)

                lgb_model.fit(X_train, y_train, sample_weight=weights)

        return lgb_model

    except Exception as e:
        print(f"ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print("ç·Šæ€¥å¯¾å‡¦ãƒ¢ãƒ¼ãƒ‰ã§ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è©¦ã¿ã¾ã™...")

        # æœ€å°é™ã®ç‰¹å¾´é‡ã ã‘ã‚’ä½¿ç”¨ã—ã¦å†ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
        # åŸºæœ¬çš„ãªç‰¹å¾´é‡ã®ã¿ã‚’é¸æŠï¼ˆæ¸©åº¦ã€è¨­å®šå€¤ã€åˆ¶å¾¡çŠ¶æ…‹ãªã©ï¼‰
        basic_features = [col for col in X_train.columns if any(key in col for key in [
            'sens_temp', 'thermo_state', 'AC_valid', 'AC_mode', 'atmospheric', 'solar'
        ])]

        if len(basic_features) > 0:
            print(f"åŸºæœ¬ç‰¹å¾´é‡{len(basic_features)}å€‹ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¾ã™")
            simple_model = lgb.LGBMRegressor(
                n_estimators=100,
                learning_rate=0.05,
                max_depth=5,
                random_state=42,
                verbose=-1  # è­¦å‘Šã‚’æŠ‘åˆ¶
            )
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                simple_model.fit(X_train[basic_features], y_train)
            return simple_model
        else:
            # ã™ã¹ã¦ã®å¯¾å‡¦ãŒå¤±æ•—ã—ãŸå ´åˆã¯ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’è¿”ã™
            print("ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã—ã¾ã™ï¼ˆå¹³å‡å€¤äºˆæ¸¬ï¼‰")
            from sklearn.dummy import DummyRegressor
            dummy_model = DummyRegressor(strategy='mean')
            dummy_model.fit(X_train.iloc[:, 0].values.reshape(-1, 1), y_train)
            return dummy_model


def save_model_and_features(model, feature_list, zone, horizon, poly_config=None):
    """
    ãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å¾´é‡æƒ…å ±ã‚’ä¿å­˜ã™ã‚‹é–¢æ•°

    Parameters:
    -----------
    model : å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
        ä¿å­˜ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
    feature_list : list
        ç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆ
    zone : int
        ã‚¾ãƒ¼ãƒ³ç•ªå·
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰
    poly_config : dict, optional
        å¤šé …å¼ç‰¹å¾´é‡ã®è¨­å®šæƒ…å ±

    Returns:
    --------
    tuple
        (ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹, ç‰¹å¾´é‡æƒ…å ±ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹)
    """
    # ãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å¾´é‡æƒ…å ±ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    model_filename = os.path.join(MODELS_DIR, f"lgbm_model_zone_{zone}_horizon_{horizon}.pkl")
    features_filename = os.path.join(MODELS_DIR, f"features_zone_{zone}_horizon_{horizon}.pkl")

    try:
        # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        with open(model_filename, 'wb') as f:
            pickle.dump(model, f)
        print(f"ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {model_filename}")

        # ç‰¹å¾´é‡æƒ…å ±ã®ä¿å­˜
        feature_info = {
            'feature_cols': feature_list,
            'poly_config': poly_config if poly_config else {
                'use_poly': False,
                'poly_features': []
            }
        }
        with open(features_filename, 'wb') as f:
            pickle.dump(feature_info, f)
        print(f"ç‰¹å¾´é‡æƒ…å ±ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {features_filename}")

        return model_filename, features_filename
    except Exception as e:
        print(f"ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ç‰¹å¾´é‡æƒ…å ±ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None, None


def load_model_and_features(zone, horizon):
    """
    ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å¾´é‡æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°

    Parameters:
    -----------
    zone : int
        ã‚¾ãƒ¼ãƒ³ç•ªå·
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰

    Returns:
    --------
    tuple
        (ãƒ¢ãƒ‡ãƒ«, ç‰¹å¾´é‡æƒ…å ±)
    """
    model_filename = os.path.join(MODELS_DIR, f"lgbm_model_zone_{zone}_horizon_{horizon}.pkl")
    features_filename = os.path.join(MODELS_DIR, f"features_zone_{zone}_horizon_{horizon}.pkl")

    try:
        # ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        with open(model_filename, 'rb') as f:
            model = pickle.load(f)

        # ç‰¹å¾´é‡æƒ…å ±ã®èª­ã¿è¾¼ã¿
        with open(features_filename, 'rb') as f:
            feature_info = pickle.load(f)

        print(f"ãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å¾´é‡æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: ã‚¾ãƒ¼ãƒ³{zone}, {horizon}åˆ†å¾Œ")
        return model, feature_info
    except Exception as e:
        print(f"ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ç‰¹å¾´é‡æƒ…å ±ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None, None


def train_temperature_difference_model(X_train, y_train, params=None):
    """
    æ¸©åº¦å·®åˆ†äºˆæ¸¬å°‚ç”¨ã®ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°é–¢æ•°
    PhysicsConstrainedLGBMã‚’ä½¿ç”¨ã—ã¦ç‰©ç†çš„å¦¥å½“æ€§ã‚’ç¢ºä¿

    æ¸©åº¦ã®å¤‰åŒ–é‡ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã€å¾“æ¥ã®æ¸©åº¦äºˆæ¸¬ã¨ã¯ç•°ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ã‚’è¡Œã†ï¼š
    - ã‚ˆã‚Šé«˜ã„å­¦ç¿’ç‡ã§å¤‰åŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰ãˆã‚‹
    - å°ã•ãªå·®åˆ†å€¤ã«å¯¾ã™ã‚‹æ„Ÿåº¦ã‚’å‘ä¸Š
    - å¤‰åŒ–ã®æ¿€ã—ã„æœŸé–“ã¸ã®é‡ã¿ä»˜ã‘å¼·åŒ–
    - ç‰¹å¾´é‡é‡è¦åº¦ã«åŸºã¥ãå‹•çš„èª¿æ•´
    - ç‰©ç†åˆ¶ç´„ã«ã‚ˆã‚‹åˆ¶å¾¡å¤‰æ•°ã¸ã®æ„Ÿåº¦å‘ä¸Š

    Parameters:
    -----------
    X_train : DataFrame
        è¨“ç·´ç”¨ç‰¹å¾´é‡
    y_train : Series
        è¨“ç·´ç”¨ç›®çš„å¤‰æ•°ï¼ˆæ¸©åº¦å·®åˆ†ï¼‰
    params : dict
        LightGBMã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆNoneã®å ´åˆã¯å·®åˆ†äºˆæ¸¬ç”¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨ï¼‰

    Returns:
    --------
    PhysicsConstrainedLGBM
        ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ç‰©ç†åˆ¶ç´„å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
    """
    print("ğŸ”¥ é«˜ç²¾åº¦æ¸©åº¦å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­...")

    # åˆ—åã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
    if len(X_train.columns) != len(set(X_train.columns)):
        print("è­¦å‘Š: ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®åˆ—åã«é‡è¤‡ãŒã‚ã‚Šã¾ã™ã€‚é‡è¤‡ã‚’æ’é™¤ã—ã¾ã™ã€‚")
        unique_cols = []
        seen_cols = set()
        for col in X_train.columns:
            if col not in seen_cols:
                unique_cols.append(col)
                seen_cols.add(col)

        duplicate_count = len(X_train.columns) - len(unique_cols)
        X_train = X_train[unique_cols]
        print(f"{duplicate_count}å€‹ã®é‡è¤‡ç‰¹å¾´é‡ã‚’æ’é™¤ã—ã¾ã—ãŸã€‚æ®‹ã‚Šç‰¹å¾´é‡æ•°: {len(unique_cols)}")

    # é«˜ç²¾åº¦å·®åˆ†äºˆæ¸¬ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    if params is None:
        params = {
            'objective': 'regression',
            'metric': 'mae',  # æ¸©åº¦å·®åˆ†ã§ã¯å¹³å‡çµ¶å¯¾èª¤å·®ãŒé©åˆ‡
            'boosting_type': 'gbdt',
            'num_leaves': 255,  # ã‚ˆã‚Šè¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰ãˆã‚‹
            'learning_rate': 0.05,  # ã‚ˆã‚Šæ…é‡ãªå­¦ç¿’
            'feature_fraction': 0.85,  # ç‰¹å¾´é‡ã®å¤šæ§˜æ€§ã‚’ä¿æŒ
            'bagging_fraction': 0.75,  # ã‚ˆã‚Šå³æ ¼ãªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
            'bagging_freq': 3,
            'max_depth': 10,  # ã‚ˆã‚Šæ·±ã„æ±ºå®šæœ¨
            'min_data_in_leaf': 8,  # å°ã•ãªå·®åˆ†å€¤ã‚’æ‰ãˆã‚‹ãŸã‚å°ã•ã‚ã«è¨­å®š
            'lambda_l1': 0.05,  # L1æ­£å‰‡åŒ–ã‚’å¼·åŒ–
            'lambda_l2': 0.15,  # L2æ­£å‰‡åŒ–ã‚’å¼·åŒ–
            'min_gain_to_split': 0.01,  # ã‚ˆã‚Šç´°ã‹ã„åˆ†å‰²ã‚’è¨±å¯
            'max_bin': 512,  # ã‚ˆã‚Šç´°ã‹ã„ãƒ“ãƒ‹ãƒ³ã‚°
            'random_state': 42,
            'n_estimators': 1000,  # èª¿æ•´æ¸ˆã¿
            'verbose': -1,
            'force_col_wise': True  # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã®æ”¹å–„
        }

    try:
        import warnings
        with warnings.catch_warnings():
            warnings.simplefilter("ignore")

            print("ğŸ¯ é«˜åº¦ãªé‡ã¿ä»˜ã‘æˆ¦ç•¥ã‚’é©ç”¨ä¸­...")
            
            # PhysicsConstrainedLGBMã‚’ä½¿ç”¨
            physics_model = PhysicsConstrainedLGBM(
                control_sensitivity=0.9,  # åˆ¶å¾¡å¤‰æ•°ã¸ã®æ„Ÿåº¦ã‚’0.7â†’0.9ã«å¼·åŒ–
                physics_penalty=0.3,
                adaptive_weight_start=0.1,
                adaptive_weight_end=0.7,
                **params
            )

            # æ¤œè¨¼ç”¨åˆ†å‰²ã§early stoppingã‚’ä½¿ç”¨
            from sklearn.model_selection import train_test_split
            X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(
                X_train, y_train, test_size=0.15, random_state=42
            )

            # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
            physics_model.fit(
                X_train_split, y_train_split,
                X_val=X_val_split, y_val=y_val_split
            )

            print(f"âœ… é«˜ç²¾åº¦å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº†")

        return physics_model

    except Exception as e:
        print(f"PhysicsConstrainedLGBMå­¦ç¿’ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        print("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã§å†è©¦è¡Œ...")

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®LightGBMãƒ¢ãƒ‡ãƒ«
        lgb_model = lgb.LGBMRegressor(**params)

        try:
            # æ€¥æ¿€ãªæ¸©åº¦å¤‰åŒ–ã«å¯¾ã™ã‚‹é‡ã¿ä»˜ã‘
            temp_changes = y_train.diff().abs().fillna(0)
            base_weights = 1 + temp_changes / (temp_changes.mean() + 1e-6)

            # åˆ¶å¾¡åŠ¹æœã®é‡ã¿èª¿æ•´ï¼ˆã‚ˆã‚Šå¼·ã„é‡ã¿ä»˜ã‘ï¼‰
            control_features = [col for col in X_train.columns 
                              if any(keyword in col for keyword in ['AC_valid', 'AC_mode', 'AC_set', 'thermo_state'])]
            
            if control_features:
                print(f"åˆ¶å¾¡ç‰¹å¾´é‡ {len(control_features)}å€‹ã‚’ç‰¹å®šã—ã€é‡ã¿ä»˜ã‘ã‚’å¼·åŒ–ã—ã¾ã™")
                control_weights = np.ones(len(y_train))
                
                # åˆ¶å¾¡å¤‰æ•°ã®å¤‰åŒ–æ™‚ã«é‡ã¿ã‚’å¢—åŠ 
                for feat in control_features:
                    if feat in X_train.columns:
                        feat_changes = X_train[feat].diff().abs().fillna(0)
                        control_weights += feat_changes * 2.0  # åˆ¶å¾¡å¤‰æ›´æ™‚ã®é‡ã¿ã‚’å¼·åŒ–
                
                final_weights = base_weights * control_weights
            else:
                final_weights = base_weights

            # æœ€å¤§é‡ã¿ã‚’åˆ¶é™
            final_weights = np.clip(final_weights, 0.5, 5.0)

            print(f"é‡ã¿ä»˜ã‘çµ±è¨ˆ:")
            print(f"  å¹³å‡é‡ã¿: {final_weights.mean():.3f}")
            print(f"  é‡ã¿ç¯„å›²: {final_weights.min():.3f} - {final_weights.max():.3f}")
            print(f"  é«˜é‡ã¿(>2.0)ãƒ‡ãƒ¼ã‚¿: {(final_weights > 2.0).sum()}è¡Œ ({(final_weights > 2.0).mean()*100:.1f}%)")

            # æ¤œè¨¼ç”¨åˆ†å‰²ã§early stoppingã‚’ä½¿ç”¨
            from sklearn.model_selection import train_test_split
            X_train_split, X_val_split, y_train_split, y_val_split, weights_train, weights_val = train_test_split(
                X_train, y_train, final_weights, test_size=0.15, random_state=42
            )

            lgb_model.fit(
                X_train_split, y_train_split,
                sample_weight=weights_train,
                eval_set=[(X_val_split, y_val_split)],
                eval_sample_weight=[weights_val],
                callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]
            )

            print(f"âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«è¨“ç·´å®Œäº† (æœ€çµ‚ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: {lgb_model.best_iteration_})")

            return lgb_model

        except Exception as fallback_error:
            print(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ä¸­ã«ã‚‚ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {fallback_error}")
            print("ã‚·ãƒ³ãƒ—ãƒ«ãªå·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã§å†è©¦è¡Œ...")

            # æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
            simple_model = lgb.LGBMRegressor(
                n_estimators=500,
                learning_rate=0.05,
                max_depth=8,
                random_state=42,
                verbose=-1
            )

            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                simple_model.fit(X_train, y_train)

            return simple_model


def save_difference_model_and_features(model, feature_list, zone, horizon, poly_config=None):
    """
    å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã¨ç‰¹å¾´é‡æƒ…å ±ã‚’ä¿å­˜ã™ã‚‹é–¢æ•°

    Parameters:
    -----------
    model : å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
        ä¿å­˜ã™ã‚‹å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«
    feature_list : list
        ç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆ
    zone : int
        ã‚¾ãƒ¼ãƒ³ç•ªå·
    horizon : int
        äºˆæ¸¬ãƒ›ãƒ©ã‚¤ã‚¾ãƒ³ï¼ˆåˆ†ï¼‰
    poly_config : dict, optional
        å¤šé …å¼ç‰¹å¾´é‡ã®è¨­å®šæƒ…å ±

    Returns:
    --------
    tuple
        (ãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹, ç‰¹å¾´é‡æƒ…å ±ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹)
    """
    # å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«å°‚ç”¨ã®ãƒ•ã‚¡ã‚¤ãƒ«å
    model_filename = os.path.join(MODELS_DIR, f"diff_model_zone_{zone}_horizon_{horizon}.pkl")
    features_filename = os.path.join(MODELS_DIR, f"diff_features_zone_{zone}_horizon_{horizon}.pkl")

    try:
        # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
        with open(model_filename, 'wb') as f:
            pickle.dump(model, f)
        print(f"å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {model_filename}")

        # ç‰¹å¾´é‡æƒ…å ±ã®ä¿å­˜
        feature_info = {
            'feature_cols': feature_list,
            'model_type': 'temperature_difference',
            'poly_config': poly_config if poly_config else {
                'use_poly': False,
                'poly_features': []
            }
        }
        with open(features_filename, 'wb') as f:
            pickle.dump(feature_info, f)
        print(f"å·®åˆ†äºˆæ¸¬ç‰¹å¾´é‡æƒ…å ±ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {features_filename}")

        return model_filename, features_filename
    except Exception as e:
        print(f"å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ç‰¹å¾´é‡æƒ…å ±ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None, None


def train_physics_constrained_difference_model(X_train, y_train, params=None):
    """
    ç‰©ç†åˆ¶ç´„ä»˜ãæ¸©åº¦å·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°
    
    Parameters:
    -----------
    X_train : DataFrame
        è¨“ç·´ç”¨ç‰¹å¾´é‡
    y_train : Series
        è¨“ç·´ç”¨ç›®çš„å¤‰æ•°ï¼ˆæ¸©åº¦å·®åˆ†ï¼‰
    params : dict
        ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        
    Returns:
    --------
    PhysicsConstrainedLGBM
        ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ç‰©ç†åˆ¶ç´„ãƒ¢ãƒ‡ãƒ«
    """
    print("ğŸš€ ç‰©ç†åˆ¶ç´„ä»˜ãå·®åˆ†äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹...")
    
    # åˆ—åã®é‡è¤‡ãƒã‚§ãƒƒã‚¯
    if len(X_train.columns) != len(set(X_train.columns)):
        print("è­¦å‘Š: é‡è¤‡ç‰¹å¾´é‡ã‚’æ’é™¤ã—ã¾ã™")
        unique_cols = []
        seen_cols = set()
        for col in X_train.columns:
            if col not in seen_cols:
                unique_cols.append(col)
                seen_cols.add(col)
        X_train = X_train[unique_cols]
        print(f"é‡è¤‡æ’é™¤å¾Œã®ç‰¹å¾´é‡æ•°: {len(unique_cols)}")
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    if params is None:
        params = {
            'n_estimators': 1000,
            'learning_rate': 0.05,
            'max_depth': 10,
            'random_state': 42
        }
    
    try:
        # ç‰©ç†åˆ¶ç´„ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        physics_model = PhysicsConstrainedLGBM(
            control_sensitivity=0.9,
            physics_penalty=0.3,
            adaptive_weight_start=0.1,
            adaptive_weight_end=0.7,
            **params
        )
        
        # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
        from sklearn.model_selection import train_test_split
        X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(
            X_train, y_train, test_size=0.15, random_state=42
        )
        
        # ãƒ¢ãƒ‡ãƒ«å­¦ç¿’
        physics_model.fit(
            X_train_split, y_train_split,
            X_val=X_val_split, y_val=y_val_split
        )
        
        print("âœ… ç‰©ç†åˆ¶ç´„ä»˜ããƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†")
        return physics_model
        
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: {e}")
        print("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: é€šå¸¸ã®LightGBMã‚’ä½¿ç”¨")
        
        import lightgbm as lgb
        lgb_model = lgb.LGBMRegressor(**params)
        lgb_model.fit(X_train, y_train)
        return lgb_model
